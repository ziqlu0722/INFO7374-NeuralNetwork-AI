{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfGW21kwqdMx"
   },
   "source": [
    "### 1. IMPORT LIBRARIES AND CIFAR 10, PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9wtwTQ8yqdMy",
    "outputId": "0e1f582d-7dee-4587-be68-4d39c932c483"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# dataset\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# modeling tools\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adadelta, Adagrad\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqhQUniOqdM2"
   },
   "source": [
    "Check and Prepare Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "eqkPHyXuqdM3",
    "outputId": "37228438-b783-42fe-e169-b4d70fd8f4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 132s 1us/step\n",
      "training data shape: (50000, 32, 32, 3)\n",
      "test data shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# check data dimension\n",
    "print('training data shape: {}'.format(x_train.shape))\n",
    "print('test data shape: {}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FRLmK4OOqdM8",
    "outputId": "6f364128-8c89-412c-979b-767ea5869ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training labels are: [6, 9, 4, 1, 2, 7, 8, 3, 5, 0]\n",
      "# labels: 10\n"
     ]
    }
   ],
   "source": [
    "# check labels\n",
    "labels = []\n",
    "for y in y_train.flatten():\n",
    "    if y not in labels:\n",
    "        labels.append(y)\n",
    "print('training labels are: {}'.format(labels))\n",
    "print('# labels: {}'.format(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qczgnAtgqdM_"
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to one-hot encoded vectors.\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAycOUVDqdNB"
   },
   "outputs": [],
   "source": [
    "# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n",
    "\n",
    "x_train = np.reshape(x_train,(50000,3072))\n",
    "x_test = np.reshape(x_test,(10000,3072))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalization of pixel values (to [0-1] range)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dl_HOdX_qdNF"
   },
   "source": [
    "### 2. HELP FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGtAwp4lqdNF"
   },
   "outputs": [],
   "source": [
    "def plotAcc(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model_accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc = 'lower right')\n",
    "    \n",
    "def plotLoss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model_loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRSeLnxQgYHY"
   },
   "outputs": [],
   "source": [
    "# get the best accuracy result\n",
    "\n",
    "def getBest(record):\n",
    "    max_acc = 0\n",
    "    experiment = None\n",
    "    for value in record.values():\n",
    "        max_acc = max(max_acc, value[1])\n",
    "\n",
    "    for key in record.keys():\n",
    "        if record[key][1] == max_acc:\n",
    "            experiment = key\n",
    "      \n",
    "    return max_acc, experiment, record[experiment][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbWr1lnRy9nD"
   },
   "outputs": [],
   "source": [
    "# get the summary of all experiments\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_allResult(record):\n",
    "    df_result = pd.DataFrame()\n",
    "    length = len(list(record.keys()))\n",
    "    df_result['Experiment'] = list(record.keys())\n",
    "    df_result['Loss'] = [list(record.values())[i][0] for i in range(length)]\n",
    "    df_result['Accuracy'] = [list(record.values())[i][1] for i in range(length)]\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BI6BP3DMqdNM"
   },
   "source": [
    "### 3. EXPERIMENTS - TEST WITH OPTIMIZER & LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7x2KUFAjqdNO"
   },
   "source": [
    "#### 1. Set up hyperparameters for batchsize and epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FcjteQjqdNQ"
   },
   "outputs": [],
   "source": [
    "list_batchSize = [32, 64, 128, 256, 512]\n",
    "\n",
    "# set a big epoch to observe what performs the best\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJ7fAF3_qdNT"
   },
   "source": [
    "#### 2. Control other conditions and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "990ZhE20qdNV"
   },
   "outputs": [],
   "source": [
    "# set conditions\n",
    "n_class = 10\n",
    "input_dimension = 32*32*3\n",
    "\n",
    "\n",
    "# use the best combo of optimizer and lr from optimizer experiment\n",
    "optimizer = keras.optimizers.Adam(lr = 0.0003)\n",
    "\n",
    "# use the best activation function from activation experiment\n",
    "activation = 'relu'\n",
    "\n",
    "# use the best configuration from config experiment\n",
    "n_neuron = 256\n",
    "\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# record hyper parameter information in dictionary                 \n",
    "param_dict = {\n",
    "        'num_neurons': 256,\n",
    "        'num_layers': 2,\n",
    "        'batch_size': 128,\n",
    "        'dropout_rate': 0.2,\n",
    "        'epochs': 20,\n",
    "        'optimizer':'Adam with 0.0001 lr'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_mhevTwqdNY"
   },
   "source": [
    "#### 3. Set up experiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNQ4OINvqdNY"
   },
   "outputs": [],
   "source": [
    "def experiment_batchSize(list_batchSize):\n",
    "    \n",
    "    record = {}    \n",
    "    for i, batch_size in enumerate(list_batchSize):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(n_neuron, activation = activation, input_dim = input_dimension))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(n_neuron, activation = activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(n_class, activation = 'softmax'))\n",
    "\n",
    "        model.compile(optimizer = optimizer,\n",
    "                      loss = 'categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        start = time.clock()\n",
    "        exp_batchSize = model.fit(x_train, \n",
    "                                  y_train, \n",
    "                                  epochs = epochs, \n",
    "                                  batch_size = batch_size,\n",
    "                                  verbose = 2,\n",
    "                                  validation_data = (x_test, y_test))\n",
    "        elapsed = (time.clock() - start)\n",
    "        scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "        \n",
    "        # record experiment information:\n",
    "        record[str(list_batchSize[i])] = [scores[0], scores[1], elapsed, exp_batchSize]\n",
    "        \n",
    "        # print experiment name:\n",
    "        print('*******************************************************')\n",
    "        print('=======================================================')\n",
    "        print('Experiment' + str(i) + ':'  + '\\t' + str(list_batchSize[i]))\n",
    "        print('=======================================================')\n",
    "        # print all used parameters for this model\n",
    "#         for i,j in param_dict.items():\n",
    "#             print(str(i) + '\\t' + str(j)) \n",
    "#             print('-------------------------------------------------------')\n",
    "            \n",
    "        # print running time used\n",
    "        print('Time Used: {}'.format(elapsed))\n",
    "        print('-------------------------------------------------------')\n",
    "        \n",
    "        # print best loss and accuracy result\n",
    "        print('Test loss:', scores[0])\n",
    "        print('-------------------------------------------------------')\n",
    "        print('Test accuracy:', scores[1])\n",
    "        \n",
    "        print('*******************************************************')\n",
    "        \n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91Gx78kSqdNc"
   },
   "source": [
    "#### 4. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 18037
    },
    "colab_type": "code",
    "id": "dqee8E75qdNc",
    "outputId": "161d48c2-80be-40fe-e77f-9d5df698aaca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.9583 - acc: 0.2810 - val_loss: 1.8170 - val_acc: 0.3410\n",
      "Epoch 2/100\n",
      " - 9s - loss: 1.7996 - acc: 0.3493 - val_loss: 1.6881 - val_acc: 0.3887\n",
      "Epoch 3/100\n",
      " - 9s - loss: 1.7341 - acc: 0.3792 - val_loss: 1.6390 - val_acc: 0.4242\n",
      "Epoch 4/100\n",
      " - 9s - loss: 1.6932 - acc: 0.3931 - val_loss: 1.5791 - val_acc: 0.4346\n",
      "Epoch 5/100\n",
      " - 9s - loss: 1.6651 - acc: 0.4029 - val_loss: 1.5975 - val_acc: 0.4340\n",
      "Epoch 6/100\n",
      " - 9s - loss: 1.6361 - acc: 0.4120 - val_loss: 1.5767 - val_acc: 0.4373\n",
      "Epoch 7/100\n",
      " - 9s - loss: 1.6211 - acc: 0.4159 - val_loss: 1.5510 - val_acc: 0.4534\n",
      "Epoch 8/100\n",
      " - 9s - loss: 1.6006 - acc: 0.4250 - val_loss: 1.5028 - val_acc: 0.4666\n",
      "Epoch 9/100\n",
      " - 9s - loss: 1.5846 - acc: 0.4311 - val_loss: 1.5192 - val_acc: 0.4594\n",
      "Epoch 10/100\n",
      " - 9s - loss: 1.5695 - acc: 0.4365 - val_loss: 1.5182 - val_acc: 0.4629\n",
      "Epoch 11/100\n",
      " - 9s - loss: 1.5624 - acc: 0.4408 - val_loss: 1.4913 - val_acc: 0.4695\n",
      "Epoch 12/100\n",
      " - 9s - loss: 1.5474 - acc: 0.4456 - val_loss: 1.4689 - val_acc: 0.4830\n",
      "Epoch 13/100\n",
      " - 9s - loss: 1.5318 - acc: 0.4486 - val_loss: 1.4812 - val_acc: 0.4798\n",
      "Epoch 14/100\n",
      " - 9s - loss: 1.5262 - acc: 0.4513 - val_loss: 1.4772 - val_acc: 0.4753\n",
      "Epoch 15/100\n",
      " - 9s - loss: 1.5177 - acc: 0.4565 - val_loss: 1.4696 - val_acc: 0.4772\n",
      "Epoch 16/100\n",
      " - 9s - loss: 1.5057 - acc: 0.4601 - val_loss: 1.4563 - val_acc: 0.4843\n",
      "Epoch 17/100\n",
      " - 9s - loss: 1.4961 - acc: 0.4622 - val_loss: 1.4553 - val_acc: 0.4843\n",
      "Epoch 18/100\n",
      " - 9s - loss: 1.4929 - acc: 0.4644 - val_loss: 1.4457 - val_acc: 0.4904\n",
      "Epoch 19/100\n",
      " - 9s - loss: 1.4846 - acc: 0.4661 - val_loss: 1.4397 - val_acc: 0.4868\n",
      "Epoch 20/100\n",
      " - 9s - loss: 1.4794 - acc: 0.4684 - val_loss: 1.4746 - val_acc: 0.4704\n",
      "Epoch 21/100\n",
      " - 9s - loss: 1.4714 - acc: 0.4731 - val_loss: 1.4523 - val_acc: 0.4886\n",
      "Epoch 22/100\n",
      " - 9s - loss: 1.4639 - acc: 0.4767 - val_loss: 1.4396 - val_acc: 0.4911\n",
      "Epoch 23/100\n",
      " - 9s - loss: 1.4603 - acc: 0.4778 - val_loss: 1.4455 - val_acc: 0.4865\n",
      "Epoch 24/100\n",
      " - 9s - loss: 1.4522 - acc: 0.4761 - val_loss: 1.4301 - val_acc: 0.4972\n",
      "Epoch 25/100\n",
      " - 9s - loss: 1.4428 - acc: 0.4817 - val_loss: 1.4464 - val_acc: 0.4861\n",
      "Epoch 26/100\n",
      " - 9s - loss: 1.4433 - acc: 0.4816 - val_loss: 1.4206 - val_acc: 0.4978\n",
      "Epoch 27/100\n",
      " - 9s - loss: 1.4415 - acc: 0.4832 - val_loss: 1.4199 - val_acc: 0.4991\n",
      "Epoch 28/100\n",
      " - 9s - loss: 1.4318 - acc: 0.4856 - val_loss: 1.4172 - val_acc: 0.4995\n",
      "Epoch 29/100\n",
      " - 9s - loss: 1.4276 - acc: 0.4892 - val_loss: 1.4304 - val_acc: 0.4879\n",
      "Epoch 30/100\n",
      " - 9s - loss: 1.4216 - acc: 0.4888 - val_loss: 1.4092 - val_acc: 0.5033\n",
      "Epoch 31/100\n",
      " - 9s - loss: 1.4196 - acc: 0.4865 - val_loss: 1.4047 - val_acc: 0.5037\n",
      "Epoch 32/100\n",
      " - 9s - loss: 1.4178 - acc: 0.4885 - val_loss: 1.4169 - val_acc: 0.4956\n",
      "Epoch 33/100\n",
      " - 9s - loss: 1.4103 - acc: 0.4933 - val_loss: 1.4017 - val_acc: 0.5062\n",
      "Epoch 34/100\n",
      " - 9s - loss: 1.4065 - acc: 0.4943 - val_loss: 1.3881 - val_acc: 0.5127\n",
      "Epoch 35/100\n",
      " - 9s - loss: 1.4073 - acc: 0.4950 - val_loss: 1.3993 - val_acc: 0.5103\n",
      "Epoch 36/100\n",
      " - 9s - loss: 1.4011 - acc: 0.4967 - val_loss: 1.4199 - val_acc: 0.5028\n",
      "Epoch 37/100\n",
      " - 9s - loss: 1.3982 - acc: 0.4966 - val_loss: 1.4255 - val_acc: 0.4919\n",
      "Epoch 38/100\n",
      " - 9s - loss: 1.3904 - acc: 0.5011 - val_loss: 1.3945 - val_acc: 0.5073\n",
      "Epoch 39/100\n",
      " - 9s - loss: 1.3954 - acc: 0.5015 - val_loss: 1.4270 - val_acc: 0.4986\n",
      "Epoch 40/100\n",
      " - 9s - loss: 1.3859 - acc: 0.5036 - val_loss: 1.3999 - val_acc: 0.5087\n",
      "Epoch 41/100\n",
      " - 9s - loss: 1.3815 - acc: 0.5065 - val_loss: 1.3834 - val_acc: 0.5194\n",
      "Epoch 42/100\n",
      " - 9s - loss: 1.3769 - acc: 0.5048 - val_loss: 1.3831 - val_acc: 0.5087\n",
      "Epoch 43/100\n",
      " - 9s - loss: 1.3745 - acc: 0.5063 - val_loss: 1.3808 - val_acc: 0.5183\n",
      "Epoch 44/100\n",
      " - 9s - loss: 1.3696 - acc: 0.5082 - val_loss: 1.3821 - val_acc: 0.5129\n",
      "Epoch 45/100\n",
      " - 9s - loss: 1.3740 - acc: 0.5070 - val_loss: 1.4104 - val_acc: 0.4938\n",
      "Epoch 46/100\n",
      " - 9s - loss: 1.3691 - acc: 0.5108 - val_loss: 1.4060 - val_acc: 0.5077\n",
      "Epoch 47/100\n",
      " - 9s - loss: 1.3663 - acc: 0.5115 - val_loss: 1.4021 - val_acc: 0.5060\n",
      "Epoch 48/100\n",
      " - 9s - loss: 1.3615 - acc: 0.5124 - val_loss: 1.3829 - val_acc: 0.5117\n",
      "Epoch 49/100\n",
      " - 9s - loss: 1.3634 - acc: 0.5105 - val_loss: 1.3721 - val_acc: 0.5148\n",
      "Epoch 50/100\n",
      " - 9s - loss: 1.3586 - acc: 0.5104 - val_loss: 1.3994 - val_acc: 0.5095\n",
      "Epoch 51/100\n",
      " - 9s - loss: 1.3534 - acc: 0.5126 - val_loss: 1.3796 - val_acc: 0.5136\n",
      "Epoch 52/100\n",
      " - 9s - loss: 1.3559 - acc: 0.5131 - val_loss: 1.3868 - val_acc: 0.5137\n",
      "Epoch 53/100\n",
      " - 9s - loss: 1.3493 - acc: 0.5166 - val_loss: 1.3855 - val_acc: 0.5122\n",
      "Epoch 54/100\n",
      " - 9s - loss: 1.3447 - acc: 0.5189 - val_loss: 1.3875 - val_acc: 0.5100\n",
      "Epoch 55/100\n",
      " - 9s - loss: 1.3454 - acc: 0.5167 - val_loss: 1.3683 - val_acc: 0.5204\n",
      "Epoch 56/100\n",
      " - 9s - loss: 1.3471 - acc: 0.5166 - val_loss: 1.3682 - val_acc: 0.5219\n",
      "Epoch 57/100\n",
      " - 9s - loss: 1.3385 - acc: 0.5217 - val_loss: 1.3869 - val_acc: 0.5145\n",
      "Epoch 58/100\n",
      " - 9s - loss: 1.3364 - acc: 0.5200 - val_loss: 1.3807 - val_acc: 0.5160\n",
      "Epoch 59/100\n",
      " - 9s - loss: 1.3357 - acc: 0.5197 - val_loss: 1.3732 - val_acc: 0.5155\n",
      "Epoch 60/100\n",
      " - 9s - loss: 1.3298 - acc: 0.5222 - val_loss: 1.4149 - val_acc: 0.5022\n",
      "Epoch 61/100\n",
      " - 9s - loss: 1.3358 - acc: 0.5186 - val_loss: 1.3717 - val_acc: 0.5140\n",
      "Epoch 62/100\n",
      " - 9s - loss: 1.3320 - acc: 0.5251 - val_loss: 1.3687 - val_acc: 0.5145\n",
      "Epoch 63/100\n",
      " - 9s - loss: 1.3269 - acc: 0.5226 - val_loss: 1.3898 - val_acc: 0.5074\n",
      "Epoch 64/100\n",
      " - 9s - loss: 1.3261 - acc: 0.5221 - val_loss: 1.3952 - val_acc: 0.5113\n",
      "Epoch 65/100\n",
      " - 9s - loss: 1.3288 - acc: 0.5228 - val_loss: 1.3787 - val_acc: 0.5145\n",
      "Epoch 66/100\n",
      " - 9s - loss: 1.3207 - acc: 0.5245 - val_loss: 1.3693 - val_acc: 0.5214\n",
      "Epoch 67/100\n",
      " - 9s - loss: 1.3224 - acc: 0.5254 - val_loss: 1.3906 - val_acc: 0.5083\n",
      "Epoch 68/100\n",
      " - 9s - loss: 1.3231 - acc: 0.5276 - val_loss: 1.3936 - val_acc: 0.5141\n",
      "Epoch 69/100\n",
      " - 9s - loss: 1.3186 - acc: 0.5286 - val_loss: 1.3707 - val_acc: 0.5148\n",
      "Epoch 70/100\n",
      " - 9s - loss: 1.3171 - acc: 0.5267 - val_loss: 1.3707 - val_acc: 0.5173\n",
      "Epoch 71/100\n",
      " - 9s - loss: 1.3100 - acc: 0.5306 - val_loss: 1.3747 - val_acc: 0.5211\n",
      "Epoch 72/100\n",
      " - 9s - loss: 1.3156 - acc: 0.5259 - val_loss: 1.3734 - val_acc: 0.5139\n",
      "Epoch 73/100\n",
      " - 9s - loss: 1.3131 - acc: 0.5298 - val_loss: 1.3823 - val_acc: 0.5103\n",
      "Epoch 74/100\n",
      " - 9s - loss: 1.3127 - acc: 0.5286 - val_loss: 1.3864 - val_acc: 0.5152\n",
      "Epoch 75/100\n",
      " - 9s - loss: 1.3056 - acc: 0.5290 - val_loss: 1.3766 - val_acc: 0.5120\n",
      "Epoch 76/100\n",
      " - 9s - loss: 1.3117 - acc: 0.5293 - val_loss: 1.3677 - val_acc: 0.5228\n",
      "Epoch 77/100\n",
      " - 9s - loss: 1.3064 - acc: 0.5331 - val_loss: 1.3683 - val_acc: 0.5229\n",
      "Epoch 78/100\n",
      " - 9s - loss: 1.3030 - acc: 0.5330 - val_loss: 1.3701 - val_acc: 0.5236\n",
      "Epoch 79/100\n",
      " - 9s - loss: 1.3018 - acc: 0.5321 - val_loss: 1.3602 - val_acc: 0.5233\n",
      "Epoch 80/100\n",
      " - 9s - loss: 1.3016 - acc: 0.5352 - val_loss: 1.3784 - val_acc: 0.5097\n",
      "Epoch 81/100\n",
      " - 9s - loss: 1.3054 - acc: 0.5316 - val_loss: 1.3743 - val_acc: 0.5145\n",
      "Epoch 82/100\n",
      " - 9s - loss: 1.2945 - acc: 0.5361 - val_loss: 1.3628 - val_acc: 0.5196\n",
      "Epoch 83/100\n",
      " - 9s - loss: 1.3003 - acc: 0.5328 - val_loss: 1.3741 - val_acc: 0.5180\n",
      "Epoch 84/100\n",
      " - 9s - loss: 1.2986 - acc: 0.5332 - val_loss: 1.3754 - val_acc: 0.5140\n",
      "Epoch 85/100\n",
      " - 9s - loss: 1.2979 - acc: 0.5347 - val_loss: 1.3704 - val_acc: 0.5182\n",
      "Epoch 86/100\n",
      " - 9s - loss: 1.2949 - acc: 0.5342 - val_loss: 1.3877 - val_acc: 0.5117\n",
      "Epoch 87/100\n",
      " - 9s - loss: 1.2925 - acc: 0.5351 - val_loss: 1.3920 - val_acc: 0.5069\n",
      "Epoch 88/100\n",
      " - 9s - loss: 1.2880 - acc: 0.5365 - val_loss: 1.3767 - val_acc: 0.5119\n",
      "Epoch 89/100\n",
      " - 9s - loss: 1.2915 - acc: 0.5365 - val_loss: 1.4132 - val_acc: 0.5008\n",
      "Epoch 90/100\n",
      " - 9s - loss: 1.2894 - acc: 0.5374 - val_loss: 1.3662 - val_acc: 0.5162\n",
      "Epoch 91/100\n",
      " - 9s - loss: 1.2847 - acc: 0.5378 - val_loss: 1.3781 - val_acc: 0.5147\n",
      "Epoch 92/100\n",
      " - 9s - loss: 1.2825 - acc: 0.5377 - val_loss: 1.3880 - val_acc: 0.5164\n",
      "Epoch 93/100\n",
      " - 9s - loss: 1.2902 - acc: 0.5374 - val_loss: 1.3683 - val_acc: 0.5090\n",
      "Epoch 94/100\n",
      " - 9s - loss: 1.2803 - acc: 0.5378 - val_loss: 1.3908 - val_acc: 0.5078\n",
      "Epoch 95/100\n",
      " - 9s - loss: 1.2840 - acc: 0.5398 - val_loss: 1.3668 - val_acc: 0.5192\n",
      "Epoch 96/100\n",
      " - 9s - loss: 1.2744 - acc: 0.5428 - val_loss: 1.3661 - val_acc: 0.5186\n",
      "Epoch 97/100\n",
      " - 9s - loss: 1.2776 - acc: 0.5424 - val_loss: 1.3763 - val_acc: 0.5143\n",
      "Epoch 98/100\n",
      " - 9s - loss: 1.2776 - acc: 0.5423 - val_loss: 1.3813 - val_acc: 0.5112\n",
      "Epoch 99/100\n",
      " - 9s - loss: 1.2779 - acc: 0.5405 - val_loss: 1.3775 - val_acc: 0.5163\n",
      "Epoch 100/100\n",
      " - 9s - loss: 1.2764 - acc: 0.5442 - val_loss: 1.3973 - val_acc: 0.5095\n",
      "10000/10000 [==============================] - 1s 53us/step\n",
      "*******************************************************\n",
      "=======================================================\n",
      "Experiment0:\t32\n",
      "=======================================================\n",
      "Time Used: 1145.31374\n",
      "-------------------------------------------------------\n",
      "Test loss: 1.397281960105896\n",
      "-------------------------------------------------------\n",
      "Test accuracy: 0.5095\n",
      "*******************************************************\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.9921 - acc: 0.2624 - val_loss: 1.8304 - val_acc: 0.3344\n",
      "Epoch 2/100\n",
      " - 5s - loss: 1.8678 - acc: 0.3141 - val_loss: 1.7696 - val_acc: 0.3602\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.8232 - acc: 0.3311 - val_loss: 1.7211 - val_acc: 0.3845\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.7968 - acc: 0.3454 - val_loss: 1.7062 - val_acc: 0.3905\n",
      "Epoch 5/100\n",
      " - 5s - loss: 1.7779 - acc: 0.3559 - val_loss: 1.6830 - val_acc: 0.4024\n",
      "Epoch 6/100\n",
      " - 5s - loss: 1.7574 - acc: 0.3636 - val_loss: 1.6492 - val_acc: 0.4162\n",
      "Epoch 7/100\n",
      " - 5s - loss: 1.7420 - acc: 0.3688 - val_loss: 1.6494 - val_acc: 0.4200\n",
      "Epoch 8/100\n",
      " - 5s - loss: 1.7255 - acc: 0.3765 - val_loss: 1.6440 - val_acc: 0.4231\n",
      "Epoch 9/100\n",
      " - 5s - loss: 1.7118 - acc: 0.3820 - val_loss: 1.6217 - val_acc: 0.4294\n",
      "Epoch 10/100\n",
      " - 5s - loss: 1.7000 - acc: 0.3853 - val_loss: 1.6058 - val_acc: 0.4313\n",
      "Epoch 11/100\n",
      " - 5s - loss: 1.6876 - acc: 0.3919 - val_loss: 1.6135 - val_acc: 0.4306\n",
      "Epoch 12/100\n",
      " - 5s - loss: 1.6764 - acc: 0.3960 - val_loss: 1.5953 - val_acc: 0.4352\n",
      "Epoch 13/100\n",
      " - 5s - loss: 1.6679 - acc: 0.3988 - val_loss: 1.5920 - val_acc: 0.4394\n",
      "Epoch 14/100\n",
      " - 5s - loss: 1.6603 - acc: 0.4029 - val_loss: 1.6132 - val_acc: 0.4228\n",
      "Epoch 15/100\n",
      " - 5s - loss: 1.6507 - acc: 0.4046 - val_loss: 1.5715 - val_acc: 0.4437\n",
      "Epoch 16/100\n",
      " - 5s - loss: 1.6417 - acc: 0.4086 - val_loss: 1.5567 - val_acc: 0.4541\n",
      "Epoch 17/100\n",
      " - 5s - loss: 1.6342 - acc: 0.4114 - val_loss: 1.5836 - val_acc: 0.4353\n",
      "Epoch 18/100\n",
      " - 5s - loss: 1.6327 - acc: 0.4131 - val_loss: 1.5585 - val_acc: 0.4517\n",
      "Epoch 19/100\n",
      " - 5s - loss: 1.6233 - acc: 0.4160 - val_loss: 1.5649 - val_acc: 0.4505\n",
      "Epoch 20/100\n",
      " - 5s - loss: 1.6209 - acc: 0.4144 - val_loss: 1.5519 - val_acc: 0.4478\n",
      "Epoch 21/100\n",
      " - 5s - loss: 1.6125 - acc: 0.4185 - val_loss: 1.5430 - val_acc: 0.4541\n",
      "Epoch 22/100\n",
      " - 5s - loss: 1.6087 - acc: 0.4209 - val_loss: 1.5416 - val_acc: 0.4555\n",
      "Epoch 23/100\n",
      " - 5s - loss: 1.6044 - acc: 0.4248 - val_loss: 1.5624 - val_acc: 0.4465\n",
      "Epoch 24/100\n",
      " - 5s - loss: 1.6027 - acc: 0.4231 - val_loss: 1.5444 - val_acc: 0.4483\n",
      "Epoch 25/100\n",
      " - 5s - loss: 1.5933 - acc: 0.4251 - val_loss: 1.5376 - val_acc: 0.4584\n",
      "Epoch 26/100\n",
      " - 5s - loss: 1.5919 - acc: 0.4262 - val_loss: 1.5304 - val_acc: 0.4552\n",
      "Epoch 27/100\n",
      " - 5s - loss: 1.5876 - acc: 0.4267 - val_loss: 1.5362 - val_acc: 0.4561\n",
      "Epoch 28/100\n",
      " - 5s - loss: 1.5833 - acc: 0.4287 - val_loss: 1.5201 - val_acc: 0.4620\n",
      "Epoch 29/100\n",
      " - 5s - loss: 1.5844 - acc: 0.4284 - val_loss: 1.5236 - val_acc: 0.4597\n",
      "Epoch 30/100\n",
      " - 5s - loss: 1.5763 - acc: 0.4333 - val_loss: 1.5144 - val_acc: 0.4693\n",
      "Epoch 31/100\n",
      " - 5s - loss: 1.5728 - acc: 0.4337 - val_loss: 1.5157 - val_acc: 0.4589\n",
      "Epoch 32/100\n",
      " - 5s - loss: 1.5664 - acc: 0.4322 - val_loss: 1.5230 - val_acc: 0.4574\n",
      "Epoch 33/100\n",
      " - 5s - loss: 1.5668 - acc: 0.4354 - val_loss: 1.5067 - val_acc: 0.4609\n",
      "Epoch 34/100\n",
      " - 5s - loss: 1.5539 - acc: 0.4406 - val_loss: 1.5015 - val_acc: 0.4651\n",
      "Epoch 35/100\n",
      " - 5s - loss: 1.5579 - acc: 0.4388 - val_loss: 1.5002 - val_acc: 0.4739\n",
      "Epoch 36/100\n",
      " - 5s - loss: 1.5498 - acc: 0.4371 - val_loss: 1.5149 - val_acc: 0.4614\n",
      "Epoch 37/100\n",
      " - 5s - loss: 1.5510 - acc: 0.4407 - val_loss: 1.5181 - val_acc: 0.4624\n",
      "Epoch 38/100\n",
      " - 5s - loss: 1.5486 - acc: 0.4407 - val_loss: 1.5200 - val_acc: 0.4613\n",
      "Epoch 39/100\n",
      " - 5s - loss: 1.5453 - acc: 0.4430 - val_loss: 1.5346 - val_acc: 0.4564\n",
      "Epoch 40/100\n",
      " - 5s - loss: 1.5377 - acc: 0.4465 - val_loss: 1.5026 - val_acc: 0.4675\n",
      "Epoch 41/100\n",
      " - 5s - loss: 1.5324 - acc: 0.4473 - val_loss: 1.5315 - val_acc: 0.4515\n",
      "Epoch 42/100\n",
      " - 5s - loss: 1.5378 - acc: 0.4465 - val_loss: 1.5057 - val_acc: 0.4663\n",
      "Epoch 43/100\n",
      " - 5s - loss: 1.5290 - acc: 0.4483 - val_loss: 1.4880 - val_acc: 0.4761\n",
      "Epoch 44/100\n",
      " - 5s - loss: 1.5293 - acc: 0.4485 - val_loss: 1.4955 - val_acc: 0.4712\n",
      "Epoch 45/100\n",
      " - 5s - loss: 1.5299 - acc: 0.4500 - val_loss: 1.4989 - val_acc: 0.4582\n",
      "Epoch 46/100\n",
      " - 5s - loss: 1.5218 - acc: 0.4520 - val_loss: 1.4915 - val_acc: 0.4652\n",
      "Epoch 47/100\n",
      " - 5s - loss: 1.5208 - acc: 0.4513 - val_loss: 1.4946 - val_acc: 0.4698\n",
      "Epoch 48/100\n",
      " - 5s - loss: 1.5222 - acc: 0.4501 - val_loss: 1.5307 - val_acc: 0.4561\n",
      "Epoch 49/100\n",
      " - 5s - loss: 1.5184 - acc: 0.4519 - val_loss: 1.5101 - val_acc: 0.4629\n",
      "Epoch 50/100\n",
      " - 5s - loss: 1.5158 - acc: 0.4542 - val_loss: 1.5078 - val_acc: 0.4684\n",
      "Epoch 51/100\n",
      " - 5s - loss: 1.5153 - acc: 0.4527 - val_loss: 1.5127 - val_acc: 0.4637\n",
      "Epoch 52/100\n",
      " - 5s - loss: 1.5119 - acc: 0.4557 - val_loss: 1.4870 - val_acc: 0.4675\n",
      "Epoch 53/100\n",
      " - 5s - loss: 1.5137 - acc: 0.4552 - val_loss: 1.4704 - val_acc: 0.4771\n",
      "Epoch 54/100\n",
      " - 5s - loss: 1.5100 - acc: 0.4575 - val_loss: 1.4864 - val_acc: 0.4675\n",
      "Epoch 55/100\n",
      " - 5s - loss: 1.5027 - acc: 0.4585 - val_loss: 1.4872 - val_acc: 0.4784\n",
      "Epoch 56/100\n",
      " - 5s - loss: 1.5040 - acc: 0.4584 - val_loss: 1.5235 - val_acc: 0.4639\n",
      "Epoch 57/100\n",
      " - 5s - loss: 1.5020 - acc: 0.4580 - val_loss: 1.4832 - val_acc: 0.4782\n",
      "Epoch 58/100\n",
      " - 5s - loss: 1.5001 - acc: 0.4604 - val_loss: 1.4815 - val_acc: 0.4798\n",
      "Epoch 59/100\n",
      " - 5s - loss: 1.4982 - acc: 0.4605 - val_loss: 1.4712 - val_acc: 0.4721\n",
      "Epoch 60/100\n",
      " - 5s - loss: 1.4939 - acc: 0.4643 - val_loss: 1.4856 - val_acc: 0.4732\n",
      "Epoch 61/100\n",
      " - 5s - loss: 1.4958 - acc: 0.4607 - val_loss: 1.4752 - val_acc: 0.4809\n",
      "Epoch 62/100\n",
      " - 5s - loss: 1.4947 - acc: 0.4601 - val_loss: 1.4719 - val_acc: 0.4745\n",
      "Epoch 63/100\n",
      " - 5s - loss: 1.4954 - acc: 0.4604 - val_loss: 1.4794 - val_acc: 0.4755\n",
      "Epoch 64/100\n",
      " - 5s - loss: 1.4886 - acc: 0.4632 - val_loss: 1.4769 - val_acc: 0.4734\n",
      "Epoch 65/100\n",
      " - 5s - loss: 1.4890 - acc: 0.4638 - val_loss: 1.4706 - val_acc: 0.4807\n",
      "Epoch 66/100\n",
      " - 5s - loss: 1.4864 - acc: 0.4639 - val_loss: 1.4751 - val_acc: 0.4752\n",
      "Epoch 67/100\n",
      " - 5s - loss: 1.4882 - acc: 0.4649 - val_loss: 1.5029 - val_acc: 0.4713\n",
      "Epoch 68/100\n",
      " - 5s - loss: 1.4873 - acc: 0.4659 - val_loss: 1.4781 - val_acc: 0.4792\n",
      "Epoch 69/100\n",
      " - 5s - loss: 1.4817 - acc: 0.4664 - val_loss: 1.4806 - val_acc: 0.4744\n",
      "Epoch 70/100\n",
      " - 5s - loss: 1.4860 - acc: 0.4658 - val_loss: 1.4783 - val_acc: 0.4758\n",
      "Epoch 71/100\n",
      " - 5s - loss: 1.4813 - acc: 0.4685 - val_loss: 1.4579 - val_acc: 0.4794\n",
      "Epoch 72/100\n",
      " - 5s - loss: 1.4763 - acc: 0.4656 - val_loss: 1.4880 - val_acc: 0.4756\n",
      "Epoch 73/100\n",
      " - 5s - loss: 1.4777 - acc: 0.4682 - val_loss: 1.4925 - val_acc: 0.4705\n",
      "Epoch 74/100\n",
      " - 5s - loss: 1.4761 - acc: 0.4702 - val_loss: 1.4658 - val_acc: 0.4791\n",
      "Epoch 75/100\n",
      " - 5s - loss: 1.4764 - acc: 0.4684 - val_loss: 1.4524 - val_acc: 0.4846\n",
      "Epoch 76/100\n",
      " - 5s - loss: 1.4755 - acc: 0.4697 - val_loss: 1.4819 - val_acc: 0.4777\n",
      "Epoch 77/100\n",
      " - 5s - loss: 1.4723 - acc: 0.4714 - val_loss: 1.4596 - val_acc: 0.4862\n",
      "Epoch 78/100\n",
      " - 5s - loss: 1.4752 - acc: 0.4694 - val_loss: 1.4749 - val_acc: 0.4797\n",
      "Epoch 79/100\n",
      " - 5s - loss: 1.4702 - acc: 0.4720 - val_loss: 1.4644 - val_acc: 0.4785\n",
      "Epoch 80/100\n",
      " - 5s - loss: 1.4706 - acc: 0.4698 - val_loss: 1.4641 - val_acc: 0.4785\n",
      "Epoch 81/100\n",
      " - 5s - loss: 1.4673 - acc: 0.4732 - val_loss: 1.4571 - val_acc: 0.4812\n",
      "Epoch 82/100\n",
      " - 5s - loss: 1.4674 - acc: 0.4725 - val_loss: 1.4723 - val_acc: 0.4794\n",
      "Epoch 83/100\n",
      " - 5s - loss: 1.4651 - acc: 0.4708 - val_loss: 1.4564 - val_acc: 0.4830\n",
      "Epoch 84/100\n",
      " - 5s - loss: 1.4622 - acc: 0.4729 - val_loss: 1.4519 - val_acc: 0.4870\n",
      "Epoch 85/100\n",
      " - 5s - loss: 1.4655 - acc: 0.4717 - val_loss: 1.4535 - val_acc: 0.4856\n",
      "Epoch 86/100\n",
      " - 5s - loss: 1.4639 - acc: 0.4731 - val_loss: 1.4690 - val_acc: 0.4769\n",
      "Epoch 87/100\n",
      " - 5s - loss: 1.4673 - acc: 0.4720 - val_loss: 1.4794 - val_acc: 0.4725\n",
      "Epoch 88/100\n",
      " - 5s - loss: 1.4616 - acc: 0.4738 - val_loss: 1.4509 - val_acc: 0.4816\n",
      "Epoch 89/100\n",
      " - 5s - loss: 1.4580 - acc: 0.4760 - val_loss: 1.4690 - val_acc: 0.4789\n",
      "Epoch 90/100\n",
      " - 5s - loss: 1.4598 - acc: 0.4786 - val_loss: 1.4507 - val_acc: 0.4831\n",
      "Epoch 91/100\n",
      " - 5s - loss: 1.4537 - acc: 0.4785 - val_loss: 1.4639 - val_acc: 0.4774\n",
      "Epoch 92/100\n",
      " - 5s - loss: 1.4566 - acc: 0.4769 - val_loss: 1.4985 - val_acc: 0.4666\n",
      "Epoch 93/100\n",
      " - 5s - loss: 1.4496 - acc: 0.4775 - val_loss: 1.4760 - val_acc: 0.4749\n",
      "Epoch 94/100\n",
      " - 5s - loss: 1.4511 - acc: 0.4789 - val_loss: 1.4547 - val_acc: 0.4845\n",
      "Epoch 95/100\n",
      " - 5s - loss: 1.4485 - acc: 0.4779 - val_loss: 1.4721 - val_acc: 0.4774\n",
      "Epoch 96/100\n",
      " - 5s - loss: 1.4525 - acc: 0.4766 - val_loss: 1.4679 - val_acc: 0.4816\n",
      "Epoch 97/100\n",
      " - 5s - loss: 1.4507 - acc: 0.4789 - val_loss: 1.4724 - val_acc: 0.4837\n",
      "Epoch 98/100\n",
      " - 5s - loss: 1.4498 - acc: 0.4759 - val_loss: 1.4482 - val_acc: 0.4895\n",
      "Epoch 99/100\n",
      " - 5s - loss: 1.4484 - acc: 0.4783 - val_loss: 1.4856 - val_acc: 0.4666\n",
      "Epoch 100/100\n",
      " - 5s - loss: 1.4477 - acc: 0.4773 - val_loss: 1.4670 - val_acc: 0.4839\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "*******************************************************\n",
      "=======================================================\n",
      "Experiment1:\t64\n",
      "=======================================================\n",
      "Time Used: 605.780579\n",
      "-------------------------------------------------------\n",
      "Test loss: 1.4670483303070068\n",
      "-------------------------------------------------------\n",
      "Test accuracy: 0.4839\n",
      "*******************************************************\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 1.9738 - acc: 0.2706 - val_loss: 1.7840 - val_acc: 0.3574\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.8347 - acc: 0.3288 - val_loss: 1.7350 - val_acc: 0.3788\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.7933 - acc: 0.3487 - val_loss: 1.6928 - val_acc: 0.3963\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.7667 - acc: 0.3563 - val_loss: 1.6722 - val_acc: 0.4080\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.7474 - acc: 0.3639 - val_loss: 1.6679 - val_acc: 0.4112\n",
      "Epoch 6/100\n",
      " - 3s - loss: 1.7303 - acc: 0.3745 - val_loss: 1.6425 - val_acc: 0.4184\n",
      "Epoch 7/100\n",
      " - 3s - loss: 1.7153 - acc: 0.3810 - val_loss: 1.6176 - val_acc: 0.4257\n",
      "Epoch 8/100\n",
      " - 3s - loss: 1.6985 - acc: 0.3868 - val_loss: 1.6311 - val_acc: 0.4246\n",
      "Epoch 9/100\n",
      " - 3s - loss: 1.6849 - acc: 0.3896 - val_loss: 1.6076 - val_acc: 0.4347\n",
      "Epoch 10/100\n",
      " - 3s - loss: 1.6728 - acc: 0.3955 - val_loss: 1.5843 - val_acc: 0.4364\n",
      "Epoch 11/100\n",
      " - 3s - loss: 1.6555 - acc: 0.4043 - val_loss: 1.5753 - val_acc: 0.4379\n",
      "Epoch 12/100\n",
      " - 3s - loss: 1.6492 - acc: 0.4047 - val_loss: 1.5627 - val_acc: 0.4414\n",
      "Epoch 13/100\n",
      " - 3s - loss: 1.6403 - acc: 0.4079 - val_loss: 1.5640 - val_acc: 0.4407\n",
      "Epoch 14/100\n",
      " - 3s - loss: 1.6327 - acc: 0.4084 - val_loss: 1.5568 - val_acc: 0.4464\n",
      "Epoch 15/100\n",
      " - 3s - loss: 1.6215 - acc: 0.4161 - val_loss: 1.5616 - val_acc: 0.4475\n",
      "Epoch 16/100\n",
      " - 3s - loss: 1.6182 - acc: 0.4186 - val_loss: 1.5356 - val_acc: 0.4533\n",
      "Epoch 17/100\n",
      " - 3s - loss: 1.6090 - acc: 0.4200 - val_loss: 1.5505 - val_acc: 0.4491\n",
      "Epoch 18/100\n",
      " - 3s - loss: 1.6057 - acc: 0.4224 - val_loss: 1.5253 - val_acc: 0.4575\n",
      "Epoch 19/100\n",
      " - 3s - loss: 1.5952 - acc: 0.4258 - val_loss: 1.5236 - val_acc: 0.4566\n",
      "Epoch 20/100\n",
      " - 3s - loss: 1.5913 - acc: 0.4281 - val_loss: 1.5226 - val_acc: 0.4624\n",
      "Epoch 21/100\n",
      " - 3s - loss: 1.5862 - acc: 0.4289 - val_loss: 1.5133 - val_acc: 0.4640\n",
      "Epoch 22/100\n",
      " - 3s - loss: 1.5795 - acc: 0.4320 - val_loss: 1.5153 - val_acc: 0.4584\n",
      "Epoch 23/100\n",
      " - 3s - loss: 1.5824 - acc: 0.4307 - val_loss: 1.5180 - val_acc: 0.4607\n",
      "Epoch 24/100\n",
      " - 3s - loss: 1.5771 - acc: 0.4315 - val_loss: 1.5110 - val_acc: 0.4662\n",
      "Epoch 25/100\n",
      " - 3s - loss: 1.5669 - acc: 0.4359 - val_loss: 1.5303 - val_acc: 0.4603\n",
      "Epoch 26/100\n",
      " - 3s - loss: 1.5710 - acc: 0.4316 - val_loss: 1.4949 - val_acc: 0.4670\n",
      "Epoch 27/100\n",
      " - 3s - loss: 1.5666 - acc: 0.4369 - val_loss: 1.5099 - val_acc: 0.4658\n",
      "Epoch 28/100\n",
      " - 3s - loss: 1.5621 - acc: 0.4379 - val_loss: 1.4999 - val_acc: 0.4649\n",
      "Epoch 29/100\n",
      " - 3s - loss: 1.5509 - acc: 0.4422 - val_loss: 1.4957 - val_acc: 0.4636\n",
      "Epoch 30/100\n",
      " - 3s - loss: 1.5494 - acc: 0.4416 - val_loss: 1.5086 - val_acc: 0.4595\n",
      "Epoch 31/100\n",
      " - 3s - loss: 1.5437 - acc: 0.4419 - val_loss: 1.5174 - val_acc: 0.4559\n",
      "Epoch 32/100\n",
      " - 3s - loss: 1.5434 - acc: 0.4439 - val_loss: 1.4872 - val_acc: 0.4685\n",
      "Epoch 33/100\n",
      " - 3s - loss: 1.5433 - acc: 0.4399 - val_loss: 1.4939 - val_acc: 0.4687\n",
      "Epoch 34/100\n",
      " - 3s - loss: 1.5341 - acc: 0.4460 - val_loss: 1.4864 - val_acc: 0.4722\n",
      "Epoch 35/100\n",
      " - 3s - loss: 1.5371 - acc: 0.4457 - val_loss: 1.4809 - val_acc: 0.4699\n",
      "Epoch 36/100\n",
      " - 3s - loss: 1.5291 - acc: 0.4472 - val_loss: 1.4950 - val_acc: 0.4643\n",
      "Epoch 37/100\n",
      " - 3s - loss: 1.5278 - acc: 0.4504 - val_loss: 1.5023 - val_acc: 0.4699\n",
      "Epoch 38/100\n",
      " - 3s - loss: 1.5231 - acc: 0.4504 - val_loss: 1.4861 - val_acc: 0.4696\n",
      "Epoch 39/100\n",
      " - 3s - loss: 1.5221 - acc: 0.4523 - val_loss: 1.4756 - val_acc: 0.4723\n",
      "Epoch 40/100\n",
      " - 3s - loss: 1.5216 - acc: 0.4504 - val_loss: 1.4778 - val_acc: 0.4759\n",
      "Epoch 41/100\n",
      " - 3s - loss: 1.5150 - acc: 0.4562 - val_loss: 1.5043 - val_acc: 0.4619\n",
      "Epoch 42/100\n",
      " - 3s - loss: 1.5174 - acc: 0.4541 - val_loss: 1.4783 - val_acc: 0.4721\n",
      "Epoch 43/100\n",
      " - 3s - loss: 1.5130 - acc: 0.4548 - val_loss: 1.4710 - val_acc: 0.4753\n",
      "Epoch 44/100\n",
      " - 3s - loss: 1.5102 - acc: 0.4548 - val_loss: 1.4802 - val_acc: 0.4700\n",
      "Epoch 45/100\n",
      " - 3s - loss: 1.5081 - acc: 0.4555 - val_loss: 1.4709 - val_acc: 0.4749\n",
      "Epoch 46/100\n",
      " - 3s - loss: 1.5073 - acc: 0.4561 - val_loss: 1.4661 - val_acc: 0.4815\n",
      "Epoch 47/100\n",
      " - 3s - loss: 1.5018 - acc: 0.4596 - val_loss: 1.4937 - val_acc: 0.4620\n",
      "Epoch 48/100\n",
      " - 3s - loss: 1.5027 - acc: 0.4581 - val_loss: 1.4646 - val_acc: 0.4766\n",
      "Epoch 49/100\n",
      " - 3s - loss: 1.5018 - acc: 0.4572 - val_loss: 1.4711 - val_acc: 0.4801\n",
      "Epoch 50/100\n",
      " - 3s - loss: 1.4933 - acc: 0.4627 - val_loss: 1.4599 - val_acc: 0.4760\n",
      "Epoch 51/100\n",
      " - 3s - loss: 1.4919 - acc: 0.4616 - val_loss: 1.4666 - val_acc: 0.4817\n",
      "Epoch 52/100\n",
      " - 3s - loss: 1.4946 - acc: 0.4638 - val_loss: 1.4805 - val_acc: 0.4740\n",
      "Epoch 53/100\n",
      " - 3s - loss: 1.4895 - acc: 0.4628 - val_loss: 1.4676 - val_acc: 0.4762\n",
      "Epoch 54/100\n",
      " - 3s - loss: 1.4923 - acc: 0.4631 - val_loss: 1.4694 - val_acc: 0.4791\n",
      "Epoch 55/100\n",
      " - 3s - loss: 1.4889 - acc: 0.4603 - val_loss: 1.4579 - val_acc: 0.4805\n",
      "Epoch 56/100\n",
      " - 3s - loss: 1.4830 - acc: 0.4641 - val_loss: 1.4762 - val_acc: 0.4751\n",
      "Epoch 57/100\n",
      " - 3s - loss: 1.4815 - acc: 0.4676 - val_loss: 1.4861 - val_acc: 0.4687\n",
      "Epoch 58/100\n",
      " - 3s - loss: 1.4844 - acc: 0.4646 - val_loss: 1.4646 - val_acc: 0.4817\n",
      "Epoch 59/100\n",
      " - 3s - loss: 1.4796 - acc: 0.4665 - val_loss: 1.4720 - val_acc: 0.4793\n",
      "Epoch 60/100\n",
      " - 3s - loss: 1.4817 - acc: 0.4661 - val_loss: 1.4557 - val_acc: 0.4814\n",
      "Epoch 61/100\n",
      " - 3s - loss: 1.4789 - acc: 0.4695 - val_loss: 1.4605 - val_acc: 0.4810\n",
      "Epoch 62/100\n",
      " - 3s - loss: 1.4759 - acc: 0.4674 - val_loss: 1.4521 - val_acc: 0.4823\n",
      "Epoch 63/100\n",
      " - 3s - loss: 1.4693 - acc: 0.4701 - val_loss: 1.4773 - val_acc: 0.4686\n",
      "Epoch 64/100\n",
      " - 3s - loss: 1.4726 - acc: 0.4672 - val_loss: 1.4600 - val_acc: 0.4773\n",
      "Epoch 65/100\n",
      " - 3s - loss: 1.4739 - acc: 0.4719 - val_loss: 1.4666 - val_acc: 0.4820\n",
      "Epoch 66/100\n",
      " - 3s - loss: 1.4664 - acc: 0.4719 - val_loss: 1.4575 - val_acc: 0.4826\n",
      "Epoch 67/100\n",
      " - 3s - loss: 1.4643 - acc: 0.4706 - val_loss: 1.4702 - val_acc: 0.4764\n",
      "Epoch 68/100\n",
      " - 3s - loss: 1.4655 - acc: 0.4718 - val_loss: 1.4529 - val_acc: 0.4834\n",
      "Epoch 69/100\n",
      " - 3s - loss: 1.4664 - acc: 0.4733 - val_loss: 1.4547 - val_acc: 0.4757\n",
      "Epoch 70/100\n",
      " - 3s - loss: 1.4632 - acc: 0.4724 - val_loss: 1.4350 - val_acc: 0.4902\n",
      "Epoch 71/100\n",
      " - 3s - loss: 1.4644 - acc: 0.4743 - val_loss: 1.4562 - val_acc: 0.4850\n",
      "Epoch 72/100\n",
      " - 3s - loss: 1.4628 - acc: 0.4747 - val_loss: 1.4502 - val_acc: 0.4826\n",
      "Epoch 73/100\n",
      " - 3s - loss: 1.4611 - acc: 0.4742 - val_loss: 1.4643 - val_acc: 0.4802\n",
      "Epoch 74/100\n",
      " - 3s - loss: 1.4557 - acc: 0.4766 - val_loss: 1.4642 - val_acc: 0.4811\n",
      "Epoch 75/100\n",
      " - 3s - loss: 1.4609 - acc: 0.4729 - val_loss: 1.4428 - val_acc: 0.4891\n",
      "Epoch 76/100\n",
      " - 3s - loss: 1.4590 - acc: 0.4757 - val_loss: 1.4437 - val_acc: 0.4896\n",
      "Epoch 77/100\n",
      " - 3s - loss: 1.4550 - acc: 0.4756 - val_loss: 1.4797 - val_acc: 0.4743\n",
      "Epoch 78/100\n",
      " - 3s - loss: 1.4541 - acc: 0.4768 - val_loss: 1.4507 - val_acc: 0.4835\n",
      "Epoch 79/100\n",
      " - 3s - loss: 1.4530 - acc: 0.4758 - val_loss: 1.4487 - val_acc: 0.4921\n",
      "Epoch 80/100\n",
      " - 3s - loss: 1.4540 - acc: 0.4781 - val_loss: 1.4559 - val_acc: 0.4800\n",
      "Epoch 81/100\n",
      " - 3s - loss: 1.4557 - acc: 0.4751 - val_loss: 1.4542 - val_acc: 0.4819\n",
      "Epoch 82/100\n",
      " - 3s - loss: 1.4493 - acc: 0.4791 - val_loss: 1.4454 - val_acc: 0.4851\n",
      "Epoch 83/100\n",
      " - 3s - loss: 1.4433 - acc: 0.4803 - val_loss: 1.4650 - val_acc: 0.4761\n",
      "Epoch 84/100\n",
      " - 3s - loss: 1.4536 - acc: 0.4757 - val_loss: 1.4581 - val_acc: 0.4810\n",
      "Epoch 85/100\n",
      " - 3s - loss: 1.4421 - acc: 0.4813 - val_loss: 1.4482 - val_acc: 0.4872\n",
      "Epoch 86/100\n",
      " - 3s - loss: 1.4422 - acc: 0.4828 - val_loss: 1.4580 - val_acc: 0.4825\n",
      "Epoch 87/100\n",
      " - 3s - loss: 1.4403 - acc: 0.4811 - val_loss: 1.4628 - val_acc: 0.4822\n",
      "Epoch 88/100\n",
      " - 3s - loss: 1.4445 - acc: 0.4795 - val_loss: 1.4617 - val_acc: 0.4772\n",
      "Epoch 89/100\n",
      " - 3s - loss: 1.4403 - acc: 0.4821 - val_loss: 1.4406 - val_acc: 0.4843\n",
      "Epoch 90/100\n",
      " - 3s - loss: 1.4388 - acc: 0.4841 - val_loss: 1.4357 - val_acc: 0.4929\n",
      "Epoch 91/100\n",
      " - 3s - loss: 1.4415 - acc: 0.4824 - val_loss: 1.4339 - val_acc: 0.4822\n",
      "Epoch 92/100\n",
      " - 3s - loss: 1.4417 - acc: 0.4814 - val_loss: 1.4305 - val_acc: 0.4908\n",
      "Epoch 93/100\n",
      " - 3s - loss: 1.4318 - acc: 0.4855 - val_loss: 1.4522 - val_acc: 0.4867\n",
      "Epoch 94/100\n",
      " - 3s - loss: 1.4360 - acc: 0.4831 - val_loss: 1.4471 - val_acc: 0.4833\n",
      "Epoch 95/100\n",
      " - 3s - loss: 1.4348 - acc: 0.4830 - val_loss: 1.4539 - val_acc: 0.4779\n",
      "Epoch 96/100\n",
      " - 3s - loss: 1.4355 - acc: 0.4830 - val_loss: 1.4410 - val_acc: 0.4902\n",
      "Epoch 97/100\n",
      " - 3s - loss: 1.4297 - acc: 0.4875 - val_loss: 1.4406 - val_acc: 0.4864\n",
      "Epoch 98/100\n",
      " - 3s - loss: 1.4357 - acc: 0.4835 - val_loss: 1.4353 - val_acc: 0.4925\n",
      "Epoch 99/100\n",
      " - 3s - loss: 1.4333 - acc: 0.4840 - val_loss: 1.4447 - val_acc: 0.4897\n",
      "Epoch 100/100\n",
      " - 3s - loss: 1.4302 - acc: 0.4872 - val_loss: 1.4586 - val_acc: 0.4854\n",
      "10000/10000 [==============================] - 1s 55us/step\n",
      "*******************************************************\n",
      "=======================================================\n",
      "Experiment2:\t128\n",
      "=======================================================\n",
      "Time Used: 329.9253080000001\n",
      "-------------------------------------------------------\n",
      "Test loss: 1.458573247909546\n",
      "-------------------------------------------------------\n",
      "Test accuracy: 0.4854\n",
      "*******************************************************\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.9763 - acc: 0.2737 - val_loss: 1.7985 - val_acc: 0.3603\n",
      "Epoch 2/100\n",
      " - 2s - loss: 1.8184 - acc: 0.3444 - val_loss: 1.7165 - val_acc: 0.3909\n",
      "Epoch 3/100\n",
      " - 2s - loss: 1.7716 - acc: 0.3617 - val_loss: 1.6952 - val_acc: 0.4026\n",
      "Epoch 4/100\n",
      " - 2s - loss: 1.7399 - acc: 0.3750 - val_loss: 1.6392 - val_acc: 0.4144\n",
      "Epoch 5/100\n",
      " - 2s - loss: 1.7161 - acc: 0.3874 - val_loss: 1.6314 - val_acc: 0.4215\n",
      "Epoch 6/100\n",
      " - 2s - loss: 1.6959 - acc: 0.3924 - val_loss: 1.6154 - val_acc: 0.4287\n",
      "Epoch 7/100\n",
      " - 2s - loss: 1.6757 - acc: 0.4020 - val_loss: 1.5937 - val_acc: 0.4381\n",
      "Epoch 8/100\n",
      " - 2s - loss: 1.6641 - acc: 0.4019 - val_loss: 1.5811 - val_acc: 0.4347\n",
      "Epoch 9/100\n",
      " - 2s - loss: 1.6501 - acc: 0.4078 - val_loss: 1.5694 - val_acc: 0.4389\n",
      "Epoch 10/100\n",
      " - 2s - loss: 1.6380 - acc: 0.4148 - val_loss: 1.5457 - val_acc: 0.4512\n",
      "Epoch 11/100\n",
      " - 2s - loss: 1.6331 - acc: 0.4166 - val_loss: 1.5438 - val_acc: 0.4501\n",
      "Epoch 12/100\n",
      " - 2s - loss: 1.6123 - acc: 0.4197 - val_loss: 1.5497 - val_acc: 0.4434\n",
      "Epoch 13/100\n",
      " - 2s - loss: 1.6071 - acc: 0.4239 - val_loss: 1.5280 - val_acc: 0.4556\n",
      "Epoch 14/100\n",
      " - 2s - loss: 1.5996 - acc: 0.4227 - val_loss: 1.5230 - val_acc: 0.4576\n",
      "Epoch 15/100\n",
      " - 2s - loss: 1.5894 - acc: 0.4289 - val_loss: 1.5195 - val_acc: 0.4563\n",
      "Epoch 16/100\n",
      " - 2s - loss: 1.5818 - acc: 0.4304 - val_loss: 1.5116 - val_acc: 0.4633\n",
      "Epoch 17/100\n",
      " - 2s - loss: 1.5799 - acc: 0.4319 - val_loss: 1.4970 - val_acc: 0.4700\n",
      "Epoch 18/100\n",
      " - 2s - loss: 1.5668 - acc: 0.4366 - val_loss: 1.4951 - val_acc: 0.4679\n",
      "Epoch 19/100\n",
      " - 2s - loss: 1.5673 - acc: 0.4373 - val_loss: 1.5011 - val_acc: 0.4676\n",
      "Epoch 20/100\n",
      " - 2s - loss: 1.5580 - acc: 0.4400 - val_loss: 1.4968 - val_acc: 0.4701\n",
      "Epoch 21/100\n",
      " - 2s - loss: 1.5570 - acc: 0.4448 - val_loss: 1.4985 - val_acc: 0.4664\n",
      "Epoch 22/100\n",
      " - 2s - loss: 1.5448 - acc: 0.4440 - val_loss: 1.4912 - val_acc: 0.4701\n",
      "Epoch 23/100\n",
      " - 2s - loss: 1.5486 - acc: 0.4445 - val_loss: 1.4913 - val_acc: 0.4701\n",
      "Epoch 24/100\n",
      " - 2s - loss: 1.5431 - acc: 0.4467 - val_loss: 1.4920 - val_acc: 0.4746\n",
      "Epoch 25/100\n",
      " - 2s - loss: 1.5347 - acc: 0.4495 - val_loss: 1.4812 - val_acc: 0.4754\n",
      "Epoch 26/100\n",
      " - 2s - loss: 1.5344 - acc: 0.4496 - val_loss: 1.4818 - val_acc: 0.4730\n",
      "Epoch 27/100\n",
      " - 2s - loss: 1.5277 - acc: 0.4520 - val_loss: 1.4727 - val_acc: 0.4754\n",
      "Epoch 28/100\n",
      " - 2s - loss: 1.5195 - acc: 0.4577 - val_loss: 1.4830 - val_acc: 0.4725\n",
      "Epoch 29/100\n",
      " - 2s - loss: 1.5169 - acc: 0.4576 - val_loss: 1.4655 - val_acc: 0.4787\n",
      "Epoch 30/100\n",
      " - 2s - loss: 1.5159 - acc: 0.4558 - val_loss: 1.4726 - val_acc: 0.4748\n",
      "Epoch 31/100\n",
      " - 2s - loss: 1.5096 - acc: 0.4593 - val_loss: 1.4566 - val_acc: 0.4813\n",
      "Epoch 32/100\n",
      " - 2s - loss: 1.5064 - acc: 0.4603 - val_loss: 1.4711 - val_acc: 0.4755\n",
      "Epoch 33/100\n",
      " - 2s - loss: 1.5044 - acc: 0.4626 - val_loss: 1.4669 - val_acc: 0.4836\n",
      "Epoch 34/100\n",
      " - 2s - loss: 1.5026 - acc: 0.4618 - val_loss: 1.4893 - val_acc: 0.4674\n",
      "Epoch 35/100\n",
      " - 2s - loss: 1.4906 - acc: 0.4643 - val_loss: 1.4587 - val_acc: 0.4820\n",
      "Epoch 36/100\n",
      " - 2s - loss: 1.4944 - acc: 0.4617 - val_loss: 1.4609 - val_acc: 0.4828\n",
      "Epoch 37/100\n",
      " - 2s - loss: 1.4908 - acc: 0.4680 - val_loss: 1.4648 - val_acc: 0.4783\n",
      "Epoch 38/100\n",
      " - 2s - loss: 1.4865 - acc: 0.4666 - val_loss: 1.4501 - val_acc: 0.4856\n",
      "Epoch 39/100\n",
      " - 2s - loss: 1.4854 - acc: 0.4691 - val_loss: 1.4467 - val_acc: 0.4890\n",
      "Epoch 40/100\n",
      " - 2s - loss: 1.4796 - acc: 0.4696 - val_loss: 1.4568 - val_acc: 0.4794\n",
      "Epoch 41/100\n",
      " - 2s - loss: 1.4769 - acc: 0.4706 - val_loss: 1.4419 - val_acc: 0.4894\n",
      "Epoch 42/100\n",
      " - 2s - loss: 1.4767 - acc: 0.4699 - val_loss: 1.4473 - val_acc: 0.4824\n",
      "Epoch 43/100\n",
      " - 2s - loss: 1.4706 - acc: 0.4732 - val_loss: 1.4427 - val_acc: 0.4913\n",
      "Epoch 44/100\n",
      " - 2s - loss: 1.4651 - acc: 0.4739 - val_loss: 1.4424 - val_acc: 0.4898\n",
      "Epoch 45/100\n",
      " - 2s - loss: 1.4705 - acc: 0.4721 - val_loss: 1.4446 - val_acc: 0.4851\n",
      "Epoch 46/100\n",
      " - 2s - loss: 1.4631 - acc: 0.4751 - val_loss: 1.4356 - val_acc: 0.4882\n",
      "Epoch 47/100\n",
      " - 2s - loss: 1.4675 - acc: 0.4759 - val_loss: 1.4555 - val_acc: 0.4802\n",
      "Epoch 48/100\n",
      " - 2s - loss: 1.4597 - acc: 0.4763 - val_loss: 1.4390 - val_acc: 0.4878\n",
      "Epoch 49/100\n",
      " - 2s - loss: 1.4592 - acc: 0.4768 - val_loss: 1.4272 - val_acc: 0.4933\n",
      "Epoch 50/100\n",
      " - 2s - loss: 1.4553 - acc: 0.4767 - val_loss: 1.4381 - val_acc: 0.4904\n",
      "Epoch 51/100\n",
      " - 2s - loss: 1.4552 - acc: 0.4766 - val_loss: 1.4362 - val_acc: 0.4895\n",
      "Epoch 52/100\n",
      " - 2s - loss: 1.4561 - acc: 0.4786 - val_loss: 1.4289 - val_acc: 0.4899\n",
      "Epoch 53/100\n",
      " - 2s - loss: 1.4470 - acc: 0.4784 - val_loss: 1.4230 - val_acc: 0.4962\n",
      "Epoch 54/100\n",
      " - 2s - loss: 1.4455 - acc: 0.4798 - val_loss: 1.4237 - val_acc: 0.4933\n",
      "Epoch 55/100\n",
      " - 2s - loss: 1.4472 - acc: 0.4796 - val_loss: 1.4442 - val_acc: 0.4870\n",
      "Epoch 56/100\n",
      " - 2s - loss: 1.4468 - acc: 0.4772 - val_loss: 1.4344 - val_acc: 0.4923\n",
      "Epoch 57/100\n",
      " - 2s - loss: 1.4409 - acc: 0.4813 - val_loss: 1.4368 - val_acc: 0.4909\n",
      "Epoch 58/100\n",
      " - 2s - loss: 1.4421 - acc: 0.4812 - val_loss: 1.4284 - val_acc: 0.4901\n",
      "Epoch 59/100\n",
      " - 2s - loss: 1.4339 - acc: 0.4864 - val_loss: 1.4283 - val_acc: 0.4936\n",
      "Epoch 60/100\n",
      " - 2s - loss: 1.4372 - acc: 0.4853 - val_loss: 1.4252 - val_acc: 0.4932\n",
      "Epoch 61/100\n",
      " - 2s - loss: 1.4323 - acc: 0.4874 - val_loss: 1.4232 - val_acc: 0.4947\n",
      "Epoch 62/100\n",
      " - 2s - loss: 1.4260 - acc: 0.4878 - val_loss: 1.4244 - val_acc: 0.4969\n",
      "Epoch 63/100\n",
      " - 2s - loss: 1.4236 - acc: 0.4891 - val_loss: 1.4262 - val_acc: 0.4933\n",
      "Epoch 64/100\n",
      " - 2s - loss: 1.4213 - acc: 0.4890 - val_loss: 1.4105 - val_acc: 0.4961\n",
      "Epoch 65/100\n",
      " - 2s - loss: 1.4235 - acc: 0.4898 - val_loss: 1.4333 - val_acc: 0.4855\n",
      "Epoch 66/100\n",
      " - 2s - loss: 1.4262 - acc: 0.4881 - val_loss: 1.4205 - val_acc: 0.4938\n",
      "Epoch 67/100\n",
      " - 2s - loss: 1.4240 - acc: 0.4848 - val_loss: 1.4283 - val_acc: 0.4955\n",
      "Epoch 68/100\n",
      " - 2s - loss: 1.4168 - acc: 0.4899 - val_loss: 1.4382 - val_acc: 0.4894\n",
      "Epoch 69/100\n",
      " - 2s - loss: 1.4195 - acc: 0.4916 - val_loss: 1.4171 - val_acc: 0.5007\n",
      "Epoch 70/100\n",
      " - 2s - loss: 1.4196 - acc: 0.4919 - val_loss: 1.4182 - val_acc: 0.4951\n",
      "Epoch 71/100\n",
      " - 2s - loss: 1.4164 - acc: 0.4916 - val_loss: 1.4186 - val_acc: 0.4956\n",
      "Epoch 72/100\n",
      " - 2s - loss: 1.4097 - acc: 0.4947 - val_loss: 1.4140 - val_acc: 0.4975\n",
      "Epoch 73/100\n",
      " - 2s - loss: 1.4102 - acc: 0.4955 - val_loss: 1.4358 - val_acc: 0.4898\n",
      "Epoch 74/100\n",
      " - 2s - loss: 1.4088 - acc: 0.4940 - val_loss: 1.4291 - val_acc: 0.4914\n",
      "Epoch 75/100\n",
      " - 2s - loss: 1.4149 - acc: 0.4920 - val_loss: 1.4092 - val_acc: 0.4992\n",
      "Epoch 76/100\n",
      " - 2s - loss: 1.4050 - acc: 0.4953 - val_loss: 1.4138 - val_acc: 0.4954\n",
      "Epoch 77/100\n",
      " - 2s - loss: 1.4034 - acc: 0.4977 - val_loss: 1.4169 - val_acc: 0.4947\n",
      "Epoch 78/100\n",
      " - 2s - loss: 1.4033 - acc: 0.4962 - val_loss: 1.4154 - val_acc: 0.4934\n",
      "Epoch 79/100\n",
      " - 2s - loss: 1.4028 - acc: 0.4944 - val_loss: 1.3973 - val_acc: 0.5029\n",
      "Epoch 80/100\n",
      " - 2s - loss: 1.3971 - acc: 0.4995 - val_loss: 1.4138 - val_acc: 0.4960\n",
      "Epoch 81/100\n",
      " - 2s - loss: 1.3985 - acc: 0.4992 - val_loss: 1.4076 - val_acc: 0.4980\n",
      "Epoch 82/100\n",
      " - 2s - loss: 1.4005 - acc: 0.4974 - val_loss: 1.4044 - val_acc: 0.4998\n",
      "Epoch 83/100\n",
      " - 2s - loss: 1.3928 - acc: 0.4993 - val_loss: 1.4137 - val_acc: 0.4983\n",
      "Epoch 84/100\n",
      " - 2s - loss: 1.3931 - acc: 0.4976 - val_loss: 1.4141 - val_acc: 0.4986\n",
      "Epoch 85/100\n",
      " - 2s - loss: 1.3945 - acc: 0.4998 - val_loss: 1.4106 - val_acc: 0.4951\n",
      "Epoch 86/100\n",
      " - 2s - loss: 1.3929 - acc: 0.4985 - val_loss: 1.4052 - val_acc: 0.5034\n",
      "Epoch 87/100\n",
      " - 2s - loss: 1.3861 - acc: 0.5044 - val_loss: 1.4115 - val_acc: 0.4965\n",
      "Epoch 88/100\n",
      " - 2s - loss: 1.3923 - acc: 0.4998 - val_loss: 1.3997 - val_acc: 0.5059\n",
      "Epoch 89/100\n",
      " - 2s - loss: 1.3911 - acc: 0.5007 - val_loss: 1.3975 - val_acc: 0.5024\n",
      "Epoch 90/100\n",
      " - 2s - loss: 1.3939 - acc: 0.5003 - val_loss: 1.4044 - val_acc: 0.5007\n",
      "Epoch 91/100\n",
      " - 2s - loss: 1.3827 - acc: 0.5028 - val_loss: 1.4104 - val_acc: 0.4975\n",
      "Epoch 92/100\n",
      " - 2s - loss: 1.3826 - acc: 0.5038 - val_loss: 1.4081 - val_acc: 0.4977\n",
      "Epoch 93/100\n",
      " - 2s - loss: 1.3824 - acc: 0.5034 - val_loss: 1.4127 - val_acc: 0.4991\n",
      "Epoch 94/100\n",
      " - 2s - loss: 1.3770 - acc: 0.5065 - val_loss: 1.4045 - val_acc: 0.5031\n",
      "Epoch 95/100\n",
      " - 2s - loss: 1.3806 - acc: 0.5053 - val_loss: 1.4116 - val_acc: 0.5033\n",
      "Epoch 96/100\n",
      " - 2s - loss: 1.3819 - acc: 0.5054 - val_loss: 1.4034 - val_acc: 0.4993\n",
      "Epoch 97/100\n",
      " - 2s - loss: 1.3774 - acc: 0.5059 - val_loss: 1.4046 - val_acc: 0.5009\n",
      "Epoch 98/100\n",
      " - 2s - loss: 1.3794 - acc: 0.5048 - val_loss: 1.4137 - val_acc: 0.4977\n",
      "Epoch 99/100\n",
      " - 2s - loss: 1.3732 - acc: 0.5072 - val_loss: 1.4057 - val_acc: 0.4990\n",
      "Epoch 100/100\n",
      " - 2s - loss: 1.3746 - acc: 0.5059 - val_loss: 1.4088 - val_acc: 0.5000\n",
      "10000/10000 [==============================] - 1s 55us/step\n",
      "*******************************************************\n",
      "=======================================================\n",
      "Experiment3:\t256\n",
      "=======================================================\n",
      "Time Used: 190.86237699999992\n",
      "-------------------------------------------------------\n",
      "Test loss: 1.4087547842025756\n",
      "-------------------------------------------------------\n",
      "Test accuracy: 0.5\n",
      "*******************************************************\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.0940 - acc: 0.2349 - val_loss: 1.8641 - val_acc: 0.3378\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.8840 - acc: 0.3146 - val_loss: 1.7782 - val_acc: 0.3715\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.8294 - acc: 0.3392 - val_loss: 1.7437 - val_acc: 0.3809\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.7970 - acc: 0.3526 - val_loss: 1.7059 - val_acc: 0.3948\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.7714 - acc: 0.3629 - val_loss: 1.6889 - val_acc: 0.3977\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.7557 - acc: 0.3681 - val_loss: 1.6646 - val_acc: 0.4132\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.7435 - acc: 0.3732 - val_loss: 1.6460 - val_acc: 0.4142\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.7243 - acc: 0.3803 - val_loss: 1.6321 - val_acc: 0.4253\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.7112 - acc: 0.3870 - val_loss: 1.6259 - val_acc: 0.4278\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.7034 - acc: 0.3889 - val_loss: 1.6123 - val_acc: 0.4308\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.6910 - acc: 0.3930 - val_loss: 1.6048 - val_acc: 0.4320\n",
      "Epoch 12/100\n",
      " - 1s - loss: 1.6830 - acc: 0.3974 - val_loss: 1.6028 - val_acc: 0.4342\n",
      "Epoch 13/100\n",
      " - 1s - loss: 1.6732 - acc: 0.4012 - val_loss: 1.5932 - val_acc: 0.4355\n",
      "Epoch 14/100\n",
      " - 1s - loss: 1.6681 - acc: 0.4039 - val_loss: 1.5853 - val_acc: 0.4375\n",
      "Epoch 15/100\n",
      " - 1s - loss: 1.6639 - acc: 0.4052 - val_loss: 1.5776 - val_acc: 0.4425\n",
      "Epoch 16/100\n",
      " - 1s - loss: 1.6527 - acc: 0.4071 - val_loss: 1.5738 - val_acc: 0.4466\n",
      "Epoch 17/100\n",
      " - 1s - loss: 1.6491 - acc: 0.4080 - val_loss: 1.5770 - val_acc: 0.4455\n",
      "Epoch 18/100\n",
      " - 1s - loss: 1.6402 - acc: 0.4152 - val_loss: 1.5728 - val_acc: 0.4491\n",
      "Epoch 19/100\n",
      " - 1s - loss: 1.6367 - acc: 0.4128 - val_loss: 1.5557 - val_acc: 0.4530\n",
      "Epoch 20/100\n",
      " - 1s - loss: 1.6380 - acc: 0.4151 - val_loss: 1.5565 - val_acc: 0.4522\n",
      "Epoch 21/100\n",
      " - 1s - loss: 1.6277 - acc: 0.4175 - val_loss: 1.5532 - val_acc: 0.4454\n",
      "Epoch 22/100\n",
      " - 1s - loss: 1.6193 - acc: 0.4164 - val_loss: 1.5568 - val_acc: 0.4520\n",
      "Epoch 23/100\n",
      " - 1s - loss: 1.6162 - acc: 0.4221 - val_loss: 1.5452 - val_acc: 0.4545\n",
      "Epoch 24/100\n",
      " - 1s - loss: 1.6141 - acc: 0.4229 - val_loss: 1.5505 - val_acc: 0.4533\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.6123 - acc: 0.4235 - val_loss: 1.5460 - val_acc: 0.4550\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.6058 - acc: 0.4260 - val_loss: 1.5400 - val_acc: 0.4516\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.6066 - acc: 0.4224 - val_loss: 1.5387 - val_acc: 0.4543\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.5990 - acc: 0.4275 - val_loss: 1.5462 - val_acc: 0.4458\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.5902 - acc: 0.4309 - val_loss: 1.5389 - val_acc: 0.4550\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.5964 - acc: 0.4258 - val_loss: 1.5282 - val_acc: 0.4575\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.5907 - acc: 0.4303 - val_loss: 1.5286 - val_acc: 0.4581\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.5920 - acc: 0.4288 - val_loss: 1.5355 - val_acc: 0.4545\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.5902 - acc: 0.4294 - val_loss: 1.5338 - val_acc: 0.4558\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.5850 - acc: 0.4297 - val_loss: 1.5355 - val_acc: 0.4569\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.5815 - acc: 0.4338 - val_loss: 1.5246 - val_acc: 0.4636\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.5820 - acc: 0.4315 - val_loss: 1.5267 - val_acc: 0.4568\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.5765 - acc: 0.4343 - val_loss: 1.5161 - val_acc: 0.4621\n",
      "Epoch 38/100\n",
      " - 1s - loss: 1.5690 - acc: 0.4375 - val_loss: 1.5251 - val_acc: 0.4562\n",
      "Epoch 39/100\n",
      " - 1s - loss: 1.5674 - acc: 0.4399 - val_loss: 1.5188 - val_acc: 0.4566\n",
      "Epoch 40/100\n",
      " - 1s - loss: 1.5734 - acc: 0.4351 - val_loss: 1.5194 - val_acc: 0.4610\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.5711 - acc: 0.4381 - val_loss: 1.5159 - val_acc: 0.4645\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.5647 - acc: 0.4395 - val_loss: 1.5195 - val_acc: 0.4575\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.5695 - acc: 0.4380 - val_loss: 1.5270 - val_acc: 0.4541\n",
      "Epoch 44/100\n",
      " - 1s - loss: 1.5582 - acc: 0.4421 - val_loss: 1.5102 - val_acc: 0.4628\n",
      "Epoch 45/100\n",
      " - 1s - loss: 1.5610 - acc: 0.4411 - val_loss: 1.5057 - val_acc: 0.4660\n",
      "Epoch 46/100\n",
      " - 1s - loss: 1.5592 - acc: 0.4407 - val_loss: 1.5120 - val_acc: 0.4595\n",
      "Epoch 47/100\n",
      " - 1s - loss: 1.5519 - acc: 0.4441 - val_loss: 1.5174 - val_acc: 0.4565\n",
      "Epoch 48/100\n",
      " - 1s - loss: 1.5554 - acc: 0.4443 - val_loss: 1.5047 - val_acc: 0.4687\n",
      "Epoch 49/100\n",
      " - 1s - loss: 1.5520 - acc: 0.4435 - val_loss: 1.5056 - val_acc: 0.4626\n",
      "Epoch 50/100\n",
      " - 1s - loss: 1.5470 - acc: 0.4447 - val_loss: 1.5006 - val_acc: 0.4619\n",
      "Epoch 51/100\n",
      " - 1s - loss: 1.5479 - acc: 0.4436 - val_loss: 1.5035 - val_acc: 0.4635\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.5438 - acc: 0.4474 - val_loss: 1.5045 - val_acc: 0.4628\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.5421 - acc: 0.4459 - val_loss: 1.5013 - val_acc: 0.4675\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.5423 - acc: 0.4503 - val_loss: 1.5019 - val_acc: 0.4625\n",
      "Epoch 55/100\n",
      " - 1s - loss: 1.5382 - acc: 0.4489 - val_loss: 1.4993 - val_acc: 0.4698\n",
      "Epoch 56/100\n",
      " - 1s - loss: 1.5380 - acc: 0.4482 - val_loss: 1.4984 - val_acc: 0.4659\n",
      "Epoch 57/100\n",
      " - 1s - loss: 1.5383 - acc: 0.4518 - val_loss: 1.5040 - val_acc: 0.4595\n",
      "Epoch 58/100\n",
      " - 1s - loss: 1.5363 - acc: 0.4516 - val_loss: 1.4988 - val_acc: 0.4678\n",
      "Epoch 59/100\n",
      " - 1s - loss: 1.5326 - acc: 0.4519 - val_loss: 1.4864 - val_acc: 0.4714\n",
      "Epoch 60/100\n",
      " - 1s - loss: 1.5285 - acc: 0.4540 - val_loss: 1.4948 - val_acc: 0.4664\n",
      "Epoch 61/100\n",
      " - 1s - loss: 1.5257 - acc: 0.4538 - val_loss: 1.4913 - val_acc: 0.4674\n",
      "Epoch 62/100\n",
      " - 1s - loss: 1.5258 - acc: 0.4543 - val_loss: 1.5047 - val_acc: 0.4640\n",
      "Epoch 63/100\n",
      " - 1s - loss: 1.5297 - acc: 0.4527 - val_loss: 1.4917 - val_acc: 0.4673\n",
      "Epoch 64/100\n",
      " - 1s - loss: 1.5276 - acc: 0.4537 - val_loss: 1.4862 - val_acc: 0.4697\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.5222 - acc: 0.4540 - val_loss: 1.4824 - val_acc: 0.4680\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.5223 - acc: 0.4558 - val_loss: 1.4836 - val_acc: 0.4720\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.5223 - acc: 0.4576 - val_loss: 1.4984 - val_acc: 0.4692\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.5178 - acc: 0.4570 - val_loss: 1.4875 - val_acc: 0.4693\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.5262 - acc: 0.4533 - val_loss: 1.4845 - val_acc: 0.4661\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.5173 - acc: 0.4566 - val_loss: 1.4794 - val_acc: 0.4714\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.5135 - acc: 0.4577 - val_loss: 1.4978 - val_acc: 0.4629\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.5131 - acc: 0.4593 - val_loss: 1.4827 - val_acc: 0.4668\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.5104 - acc: 0.4590 - val_loss: 1.4905 - val_acc: 0.4699\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.5134 - acc: 0.4596 - val_loss: 1.4793 - val_acc: 0.4719\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.5077 - acc: 0.4585 - val_loss: 1.4746 - val_acc: 0.4788\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.5081 - acc: 0.4598 - val_loss: 1.4768 - val_acc: 0.4721\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.5071 - acc: 0.4605 - val_loss: 1.4778 - val_acc: 0.4756\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.5048 - acc: 0.4615 - val_loss: 1.4789 - val_acc: 0.4767\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.5030 - acc: 0.4613 - val_loss: 1.4688 - val_acc: 0.4802\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.5032 - acc: 0.4658 - val_loss: 1.4721 - val_acc: 0.4742\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.5053 - acc: 0.4627 - val_loss: 1.4804 - val_acc: 0.4777\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.5004 - acc: 0.4650 - val_loss: 1.4810 - val_acc: 0.4721\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.4987 - acc: 0.4652 - val_loss: 1.4944 - val_acc: 0.4676\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.4966 - acc: 0.4661 - val_loss: 1.4845 - val_acc: 0.4761\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.4939 - acc: 0.4661 - val_loss: 1.4767 - val_acc: 0.4746\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.4948 - acc: 0.4643 - val_loss: 1.4716 - val_acc: 0.4788\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.4955 - acc: 0.4669 - val_loss: 1.4656 - val_acc: 0.4773\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.4944 - acc: 0.4654 - val_loss: 1.4679 - val_acc: 0.4808\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.4873 - acc: 0.4695 - val_loss: 1.4785 - val_acc: 0.4737\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.4910 - acc: 0.4658 - val_loss: 1.4709 - val_acc: 0.4756\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.4929 - acc: 0.4694 - val_loss: 1.4803 - val_acc: 0.4702\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.4845 - acc: 0.4672 - val_loss: 1.4632 - val_acc: 0.4807\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.4882 - acc: 0.4666 - val_loss: 1.4731 - val_acc: 0.4773\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.4810 - acc: 0.4718 - val_loss: 1.4699 - val_acc: 0.4806\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.4813 - acc: 0.4717 - val_loss: 1.4712 - val_acc: 0.4763\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.4794 - acc: 0.4703 - val_loss: 1.4684 - val_acc: 0.4724\n",
      "Epoch 97/100\n",
      " - 1s - loss: 1.4826 - acc: 0.4703 - val_loss: 1.4758 - val_acc: 0.4726\n",
      "Epoch 98/100\n",
      " - 1s - loss: 1.4767 - acc: 0.4713 - val_loss: 1.4699 - val_acc: 0.4734\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.4812 - acc: 0.4729 - val_loss: 1.4670 - val_acc: 0.4766\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.4791 - acc: 0.4717 - val_loss: 1.4628 - val_acc: 0.4812\n",
      "10000/10000 [==============================] - 1s 54us/step\n",
      "*******************************************************\n",
      "=======================================================\n",
      "Experiment4:\t512\n",
      "=======================================================\n",
      "Time Used: 116.50872700000036\n",
      "-------------------------------------------------------\n",
      "Test loss: 1.4627923561096192\n",
      "-------------------------------------------------------\n",
      "Test accuracy: 0.4812\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "record = experiment_batchSize(list_batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PSDOmAw5zp6U"
   },
   "source": [
    "### 4. SUMMRIZE EXPERIMENTS RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnWnjIN_0UuL"
   },
   "source": [
    "#### 1. Best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Yg_QkZk8hIny",
    "outputId": "0b8e247d-ff96-480e-ec22-83f8e8cb4cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Result is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5095, '32')"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_acc, experiment, history = getBest(record)\n",
    "print('The Best Result is:')\n",
    "max_acc, experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "S0JuxvIGiycn",
    "outputId": "c04c9797-2c41-43b1-a9e4-0965abc6cb93"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEVCAYAAAAPRfkLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFEREJKKkICIiESUFERGJ/A/w+xcdTWEL1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotAcc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "PA60iLgxkQLs",
    "outputId": "26e5981f-7feb-411a-a374-e99d70af0a69"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLoss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9ncqNmU0joA"
   },
   "source": [
    "#### 2. Result summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4hexsZP4l5h"
   },
   "outputs": [],
   "source": [
    "df_result = get_allResult(record)\n",
    "\n",
    "# add control parameters\n",
    "\n",
    "df_result['activation'] = 'relu'\n",
    "df_result['optimizer'] = 'Adam with learning rate @ 0.0003'\n",
    "df_result['num_layers'] = 3\n",
    "df_result['num_neurons'] = 256\n",
    "df_result['dropout_rate'] = 0.2\n",
    "df_result['epochs'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4e_34RtuGLy0",
    "outputId": "5d7064c6-0708-425a-ef35-0b7cc681e2d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1.397282</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam with learning rate @ 0.0003</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>1.408755</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam with learning rate @ 0.0003</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>1.458573</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam with learning rate @ 0.0003</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>1.467048</td>\n",
       "      <td>0.4839</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam with learning rate @ 0.0003</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>512</td>\n",
       "      <td>1.462792</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adam with learning rate @ 0.0003</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  batch_size      Loss  Accuracy activation                         optimizer  \\\n",
       "0         32  1.397282    0.5095       relu  Adam with learning rate @ 0.0003   \n",
       "3        256  1.408755    0.5000       relu  Adam with learning rate @ 0.0003   \n",
       "2        128  1.458573    0.4854       relu  Adam with learning rate @ 0.0003   \n",
       "1         64  1.467048    0.4839       relu  Adam with learning rate @ 0.0003   \n",
       "4        512  1.462792    0.4812       relu  Adam with learning rate @ 0.0003   \n",
       "\n",
       "   num_layers  num_neurons  dropout_rate  epochs  \n",
       "0           3          256           0.2     100  \n",
       "3           3          256           0.2     100  \n",
       "2           3          256           0.2     100  \n",
       "1           3          256           0.2     100  \n",
       "4           3          256           0.2     100  "
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.rename(columns = {\"Experiment\": \"batch_size\"}, inplace = True)\n",
    "df_result.sort_values(by = 'Accuracy', axis = 0, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "leepUYfeJn0f"
   },
   "outputs": [],
   "source": [
    "df_result.to_csv('exe_batchSize_epoch.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EXP_BatchSize_Epoch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
