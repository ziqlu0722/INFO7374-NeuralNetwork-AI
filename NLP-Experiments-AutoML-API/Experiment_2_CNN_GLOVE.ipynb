{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_2_CNN_GLOVE.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["Rsx9iwfj4Ak3"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Pbw_PwyYjJO1","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","from random import randrange\n","import zipfile\n","\n","\n","import keras\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","\n","from keras import regularizers\n","from keras.layers import Dense, Activation, Dropout, Flatten, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n","\n","from keras import optimizers\n","from keras.models import Sequential\n","from keras.callbacks import EarlyStopping\n","\n","from tqdm import tqdm\n","from nltk.corpus import stopwords\n","from nltk.tokenize import RegexpTokenizer \n","import os, re, csv, math, codecs\n","\n","import seaborn as sns\n","from sklearn import metrics"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rsx9iwfj4Ak3","colab_type":"text"},"cell_type":"markdown","source":["# 1.Load and Preprocess IMDB Data\n"]},{"metadata":{"colab_type":"code","id":"2DQyVllMe1Wl","colab":{}},"cell_type":"code","source":["with zipfile.ZipFile('drive/INFO7374_NeuralNetwork&AI/Assignment_3/data/aclImdb.zip','r') as zip_ref:\n","    zip_ref.extractall('')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kBMYgs36gPAc","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","\n","imdb_dir = 'aclImdb'\n","train_dir = os.path.join(imdb_dir, 'train')\n","\n","labels = []\n","texts = []\n","\n","for label_type in ['neg', 'pos']:\n","    dir_name = os.path.join(train_dir, label_type)\n","    for fname in os.listdir(dir_name):\n","        if fname[-4:] == '.txt':\n","            f = open(os.path.join(dir_name, fname))\n","            texts.append(f.read())\n","            f.close()\n","            if label_type == 'neg':\n","                labels.append(0)\n","            else:\n","                labels.append(1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C-l2RAA1Nmz-","colab_type":"code","outputId":"b4936a26-9822-42e5-ef68-100ae64b3af9","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["len(texts)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25000"]},"metadata":{"tags":[]},"execution_count":42}]},{"metadata":{"colab_type":"code","outputId":"76aae328-9e1f-4309-f6fd-73e9addc3395","id":"9xn2HAlw2PrA","colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["maxlen = 100  # We will cut reviews after 100 words\n","training_samples = 200  # We will be training on 200 samples\n","validation_samples = 10000  # We will be validating on 10000 samples\n","max_words = 10000  # We will only consider the top 10,000 words in the dataset\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","data = pad_sequences(sequences, maxlen=maxlen)\n","\n","labels = np.asarray(labels)\n","print('Shape of data tensor:', data.shape)\n","print('Shape of label tensor:', labels.shape)\n","\n","# Split the data into a training set and a validation set\n","# But first, shuffle the data, since we started from data\n","# where sample are ordered (all negative first, then all positive).\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","x_train_mv = data[:training_samples]\n","y_train_mv = labels[:training_samples]\n","x_val_mv = data[training_samples: training_samples + validation_samples]\n","y_val_mv = labels[training_samples: training_samples + validation_samples]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 88582 unique tokens.\n","Shape of data tensor: (25000, 100)\n","Shape of label tensor: (25000,)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","outputId":"deafc1eb-df2d-44cf-bd6c-f7837325e880","id":"e_MGRkzJ3GnW","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["embeddings_index = {}\n","\n","with open('glove.6B.100d.txt') as f:\n","  for line in f:\n","      values = line.split()\n","      word = values[0]\n","      coefs = np.asarray(values[1:], dtype='float32')\n","      embeddings_index[word] = coefs\n","\n","print('Found %s word vectors.' % len(embeddings_index))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 400000 word vectors.\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"9A4q9p0J3Gna","colab":{}},"cell_type":"code","source":["embedding_dim = 100\n","\n","embedding_matrix = np.zeros((max_words, embedding_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if i < max_words:\n","        if embedding_vector is not None:\n","            # Words not found in embedding index will be all-zeros.\n","            embedding_matrix[i] = embedding_vector"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AwovI_tT4xsS","colab_type":"text"},"cell_type":"markdown","source":["# 2. Training IMDB"]},{"metadata":{"id":"-8gGVCb-_yFT","colab_type":"text"},"cell_type":"markdown","source":["## 2.1 GloVe"]},{"metadata":{"colab_type":"code","outputId":"8874f2cb-6439-43c6-ea31-b8fa2d2a5f3e","id":"0009gsvA2PLJ","colab":{"base_uri":"https://localhost:8080/","height":272}},"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, weights = [embedding_matrix], trainable = False, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","\n","#define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n","callbacks_list = [early_stopping]\n","\n","model.compile(optimizer='rmsprop',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","\n","# hist = model.fit(x_train_mv, y_train_mv,\n","#                  epochs=100,\n","#                  batch_size=32,\n","#                  validation_data=(x_val_mv, y_val_mv),\n","#                  callbacks=callbacks_list)\n","# model.save_weights('transfer_1.h5')\n","\n","base_model = model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_24 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 10000)             0         \n","_________________________________________________________________\n","dense_47 (Dense)             (None, 32)                320032    \n","_________________________________________________________________\n","dense_48 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 320,065\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"Q-dBXSg24VFj","colab_type":"code","outputId":"ac654deb-9559-47ae-9278-714a8fd0fd9f","colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["model.evaluate(x_val_mv, y_val_mv)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 1s 69us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.7317584680557251, 0.5622]"]},"metadata":{"tags":[]},"execution_count":59}]},{"metadata":{"id":"6bUwbot63bNk","colab_type":"code","outputId":"db840277-3078-43ff-8b40-1d4699e2ea54","colab":{"base_uri":"https://localhost:8080/","height":364}},"cell_type":"code","source":["y_pred = model.predict(x_val_mv)\n","y_p = y_pred.flatten()\n","y_p = [1 if i > 0.5 else 0 for i in y_p]\n","\n","matrix = metrics.confusion_matrix(y_val_mv, y_p)\n","sns.heatmap(matrix,annot=True,fmt='.5g')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f4b3de25128>"]},"metadata":{"tags":[]},"execution_count":60},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAccAAAFKCAYAAABo0pS0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 576x396 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"CtdTL800ePiQ","colab_type":"code","outputId":"e5107636-2759-47ac-86b2-5d49383c79e2","colab":{"base_uri":"https://localhost:8080/","height":496}},"cell_type":"code","source":["#define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n","callbacks_list = [early_stopping]\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","\n","optimizer = optimizers.SGD(lr=0.01, nesterov=True)\n","\n","model.compile(optimizer= optimizer,\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","hisT = model.fit(x_train_mv, y_train_mv,\n","                    epochs=200,\n","                    batch_size=32,\n","                    validation_data=(x_val_mv, y_val_mv),\n","                 callbacks = callbacks_list)\n","\n","model.save_weights('transfer_3.h5')\n","base_model = model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_19 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_13 (Flatten)         (None, 10000)             0         \n","_________________________________________________________________\n","dense_37 (Dense)             (None, 32)                320032    \n","_________________________________________________________________\n","dense_38 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 1,320,065\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 200 samples, validate on 10000 samples\n","Epoch 1/200\n","200/200 [==============================] - 2s 10ms/step - loss: 0.6927 - acc: 0.5250 - val_loss: 0.6936 - val_acc: 0.4932\n","Epoch 2/200\n","200/200 [==============================] - 1s 3ms/step - loss: 0.6917 - acc: 0.5600 - val_loss: 0.6936 - val_acc: 0.4915\n","Epoch 3/200\n","200/200 [==============================] - 1s 3ms/step - loss: 0.6908 - acc: 0.5800 - val_loss: 0.6936 - val_acc: 0.4907\n","Epoch 4/200\n","200/200 [==============================] - 1s 3ms/step - loss: 0.6898 - acc: 0.6150 - val_loss: 0.6936 - val_acc: 0.4911\n","Epoch 5/200\n","200/200 [==============================] - 1s 3ms/step - loss: 0.6890 - acc: 0.6300 - val_loss: 0.6936 - val_acc: 0.4904\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"cV3WLDx8gKuD","colab_type":"code","outputId":"12f08fa7-9062-4499-a6fd-b807ee317977","colab":{"base_uri":"https://localhost:8080/","height":496}},"cell_type":"code","source":["#define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n","callbacks_list = [early_stopping]\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","\n","optimizer = optimizers.SGD(lr=0.1, nesterov=True)\n","\n","model.compile(optimizer= optimizer,\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","hisT = model.fit(x_train_mv, y_train_mv,\n","                 epochs=200,\n","                 batch_size=32,\n","                 validation_data=(x_val_mv, y_val_mv),\n","                 callbacks = callbacks_list)\n","\n","model.save_weights('transfer_4.h5')\n","base_model = model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_20 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_14 (Flatten)         (None, 10000)             0         \n","_________________________________________________________________\n","dense_39 (Dense)             (None, 32)                320032    \n","_________________________________________________________________\n","dense_40 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 1,320,065\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 200 samples, validate on 10000 samples\n","Epoch 1/200\n","200/200 [==============================] - 2s 10ms/step - loss: 0.6939 - acc: 0.4850 - val_loss: 0.6943 - val_acc: 0.4982\n","Epoch 2/200\n","200/200 [==============================] - 1s 3ms/step - loss: 0.6853 - acc: 0.5700 - val_loss: 0.6958 - val_acc: 0.4969\n","Epoch 3/200\n","200/200 [==============================] - 1s 3ms/step - loss: 0.6773 - acc: 0.5300 - val_loss: 0.6944 - val_acc: 0.4971\n","Epoch 4/200\n","200/200 [==============================] - 1s 3ms/step - loss: 0.6692 - acc: 0.6150 - val_loss: 0.6967 - val_acc: 0.4969\n","Epoch 5/200\n","200/200 [==============================] - 1s 3ms/step - loss: 0.6603 - acc: 0.5600 - val_loss: 0.6980 - val_acc: 0.4968\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"YUxHWRXx-011","colab_type":"text"},"cell_type":"markdown","source":["## 2.2 CNN + GloVe"]},{"metadata":{"id":"7jmQGy83yBEQ","colab_type":"code","outputId":"abf14791-e017-4b21-c56b-b2abb31af36d","colab":{"base_uri":"https://localhost:8080/","height":680}},"cell_type":"code","source":["#training params\n","batch_size = 256 \n","num_epochs = 50\n","\n","#model parameters\n","num_filters = 64 \n","embedding_dim = 100 \n","weight_decay = 1e-4\n","\n","optimizer = optimizers.Adam(lr=0.001)\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim,\n","          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","#define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n","callbacks_list = [early_stopping]\n","\n","#model training\n","hist = model.fit(x_train_mv, \n","                 y_train_mv, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val_mv, y_val_mv),\n","#                  validation_split=0.1, \n","                 shuffle=True, verbose=2)\n","\n","model.save_weights('transfer_cnn_1.h5')\n","base_model = model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_21 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_13 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_7 (MaxPooling1 (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_14 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_7 (Glob (None, 64)                0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_41 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_42 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,075,713\n","Trainable params: 75,713\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Train on 200 samples, validate on 10000 samples\n","Epoch 1/50\n"," - 2s - loss: 0.8591 - acc: 0.5450 - val_loss: 0.7369 - val_acc: 0.4966\n","Epoch 2/50\n"," - 0s - loss: 0.7988 - acc: 0.5150 - val_loss: 0.7341 - val_acc: 0.4966\n","Epoch 3/50\n"," - 0s - loss: 0.8029 - acc: 0.5350 - val_loss: 0.6995 - val_acc: 0.5112\n","Epoch 4/50\n"," - 0s - loss: 0.7138 - acc: 0.5650 - val_loss: 0.7028 - val_acc: 0.5062\n","Epoch 5/50\n"," - 0s - loss: 0.6885 - acc: 0.5500 - val_loss: 0.7188 - val_acc: 0.5032\n","Epoch 6/50\n"," - 0s - loss: 0.7009 - acc: 0.5450 - val_loss: 0.7205 - val_acc: 0.5032\n","Epoch 7/50\n"," - 0s - loss: 0.6749 - acc: 0.5950 - val_loss: 0.7138 - val_acc: 0.5031\n","Epoch 00007: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"L5D_wpjA7ahj","colab_type":"code","outputId":"5c4e9b71-657e-41e8-c75b-e18660c9280d","colab":{"base_uri":"https://localhost:8080/","height":714}},"cell_type":"code","source":["#training params\n","batch_size = 256 \n","num_epochs = 50\n","\n","#model parameters\n","num_filters = 64 \n","embedding_dim = 100 \n","weight_decay = 1e-4\n","\n","optimizer = optimizers.Adam(lr=0.01)\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim,\n","          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","#define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n","callbacks_list = [early_stopping]\n","\n","#model training\n","hist = model.fit(x_train_mv, \n","                 y_train_mv, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val_mv, y_val_mv),\n","#                  validation_split=0.1, \n","                 shuffle=True, verbose=2)\n","\n","model.save_weights('transfer_cnn_2.h5')\n","base_model = model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_23 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_17 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_9 (MaxPooling1 (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_18 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_9 (Glob (None, 64)                0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_45 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_46 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,075,713\n","Trainable params: 75,713\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Train on 200 samples, validate on 10000 samples\n","Epoch 1/50\n"," - 2s - loss: 0.7747 - acc: 0.4400 - val_loss: 0.8380 - val_acc: 0.5032\n","Epoch 2/50\n"," - 0s - loss: 1.0591 - acc: 0.4750 - val_loss: 1.5259 - val_acc: 0.4968\n","Epoch 3/50\n"," - 0s - loss: 1.4405 - acc: 0.5300 - val_loss: 0.7674 - val_acc: 0.4968\n","Epoch 4/50\n"," - 0s - loss: 0.7639 - acc: 0.5400 - val_loss: 0.6981 - val_acc: 0.4862\n","Epoch 5/50\n"," - 0s - loss: 0.6934 - acc: 0.5450 - val_loss: 0.7002 - val_acc: 0.5031\n","Epoch 6/50\n"," - 0s - loss: 0.7010 - acc: 0.5250 - val_loss: 0.6987 - val_acc: 0.5030\n","Epoch 7/50\n"," - 0s - loss: 0.7130 - acc: 0.4450 - val_loss: 0.6980 - val_acc: 0.5032\n","Epoch 8/50\n"," - 0s - loss: 0.6965 - acc: 0.5050 - val_loss: 0.6978 - val_acc: 0.5038\n","Epoch 00008: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"TvNlwT9ZZ_jF","colab_type":"text"},"cell_type":"markdown","source":["## 2.3 Train From Scratch - MLP"]},{"metadata":{"id":"bJEGD0peg9sy","colab_type":"code","outputId":"98b81d3e-0685-4303-9d2f-9658fb22c2b8","colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","maxlen = 100  # We will cut reviews after 100 words\n","training_samples = 20000  # We will be training on 200 samples\n","validation_samples = 5000  # We will be validating on 10000 samples\n","max_words = 10000  # We will only consider the top 10,000 words in the dataset\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","data = pad_sequences(sequences, maxlen=maxlen)\n","\n","labels = np.asarray(labels)\n","print('Shape of data tensor:', data.shape)\n","print('Shape of label tensor:', labels.shape)\n","\n","# Split the data into a training set and a validation set\n","# But first, shuffle the data, since we started from data\n","# where sample are ordered (all negative first, then all positive).\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","x_train_mv = data[:training_samples]\n","y_train_mv = labels[:training_samples]\n","x_val_mv = data[training_samples: training_samples + validation_samples]\n","y_val_mv = labels[training_samples: training_samples + validation_samples]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 88582 unique tokens.\n","Shape of data tensor: (25000, 100)\n","Shape of label tensor: (25000,)\n"],"name":"stdout"}]},{"metadata":{"id":"QZ5_HbdqaGhT","colab_type":"code","outputId":"3d06f831-71d7-4f41-9816-9f4114e168fd","colab":{"base_uri":"https://localhost:8080/","height":496}},"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","\n","optimizer = optimizers.SGD(lr=0.01, nesterov=True)\n","\n","model.compile(optimizer= optimizer,\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","hist = model.fit(x_train_mv, y_train_mv,\n","                    epochs=200,\n","                    batch_size=32,\n","                    validation_data=(x_val_mv, y_val_mv),\n","                    callbacks=callbacks_list)\n","\n","base_model = model\n","model.save_weights('transfer_scratch_mlp.h5')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_38 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_14 (Flatten)         (None, 10000)             0         \n","_________________________________________________________________\n","dense_73 (Dense)             (None, 32)                320032    \n","_________________________________________________________________\n","dense_74 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 1,320,065\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 20000 samples, validate on 5000 samples\n","Epoch 1/200\n","20000/20000 [==============================] - 9s 443us/step - loss: 0.6935 - acc: 0.4952 - val_loss: 0.6932 - val_acc: 0.4950\n","Epoch 2/200\n","20000/20000 [==============================] - 4s 205us/step - loss: 0.6927 - acc: 0.5136 - val_loss: 0.6932 - val_acc: 0.5006\n","Epoch 3/200\n","20000/20000 [==============================] - 4s 206us/step - loss: 0.6920 - acc: 0.5273 - val_loss: 0.6933 - val_acc: 0.4954\n","Epoch 4/200\n","20000/20000 [==============================] - 4s 204us/step - loss: 0.6913 - acc: 0.5457 - val_loss: 0.6933 - val_acc: 0.4948\n","Epoch 5/200\n","20000/20000 [==============================] - 4s 205us/step - loss: 0.6905 - acc: 0.5591 - val_loss: 0.6933 - val_acc: 0.4914\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"dwZzXP9aa3BA","colab_type":"code","outputId":"b737aeae-35f9-4a27-e0c9-bd19e22864af","colab":{"base_uri":"https://localhost:8080/","height":496}},"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","\n","optimizer = optimizers.SGD(lr=0.001, nesterov=True)\n","\n","model.compile(optimizer= optimizer,\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","hist = model.fit(x_train_mv, y_train_mv,\n","                    epochs=200,\n","                    batch_size=32,\n","                    validation_data=(x_val_mv, y_val_mv),\n","                    callbacks=callbacks_list)\n","\n","base_model = model\n","model.save_weights('transfer_scratch_mlp_2.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_39 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 10000)             0         \n","_________________________________________________________________\n","dense_75 (Dense)             (None, 32)                320032    \n","_________________________________________________________________\n","dense_76 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 1,320,065\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 20000 samples, validate on 5000 samples\n","Epoch 1/200\n","20000/20000 [==============================] - 9s 470us/step - loss: 0.6931 - acc: 0.5004 - val_loss: 0.6934 - val_acc: 0.5022\n","Epoch 2/200\n","20000/20000 [==============================] - 4s 207us/step - loss: 0.6930 - acc: 0.5032 - val_loss: 0.6934 - val_acc: 0.4984\n","Epoch 3/200\n","20000/20000 [==============================] - 4s 206us/step - loss: 0.6929 - acc: 0.5060 - val_loss: 0.6934 - val_acc: 0.5000\n","Epoch 4/200\n","20000/20000 [==============================] - 4s 205us/step - loss: 0.6928 - acc: 0.5072 - val_loss: 0.6934 - val_acc: 0.5014\n","Epoch 5/200\n","20000/20000 [==============================] - 4s 205us/step - loss: 0.6927 - acc: 0.5106 - val_loss: 0.6934 - val_acc: 0.5024\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"BnJYWLcObX65","colab_type":"code","outputId":"1a33383e-b653-451a-9edc-7e45c046fe64","colab":{"base_uri":"https://localhost:8080/","height":496}},"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","\n","optimizer = optimizers.Adam(lr=0.001)\n","\n","model.compile(optimizer= optimizer,\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","hist = model.fit(x_train_mv, y_train_mv,\n","                    epochs=200,\n","                    batch_size=32,\n","                    validation_data=(x_val_mv, y_val_mv),\n","                    callbacks=callbacks_list)\n","\n","base_model = model\n","model.save_weights('transfer_scratch_mlp_3.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_41 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_17 (Flatten)         (None, 10000)             0         \n","_________________________________________________________________\n","dense_79 (Dense)             (None, 32)                320032    \n","_________________________________________________________________\n","dense_80 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 1,320,065\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 20000 samples, validate on 5000 samples\n","Epoch 1/200\n","20000/20000 [==============================] - 10s 513us/step - loss: 0.6938 - acc: 0.4996 - val_loss: 0.6937 - val_acc: 0.4998\n","Epoch 2/200\n","20000/20000 [==============================] - 5s 249us/step - loss: 0.4813 - acc: 0.7731 - val_loss: 0.9015 - val_acc: 0.4982\n","Epoch 3/200\n","20000/20000 [==============================] - 5s 249us/step - loss: 0.0514 - acc: 0.9861 - val_loss: 1.5300 - val_acc: 0.4938\n","Epoch 4/200\n","20000/20000 [==============================] - 5s 251us/step - loss: 0.0126 - acc: 0.9972 - val_loss: 1.6833 - val_acc: 0.4890\n","Epoch 5/200\n","20000/20000 [==============================] - 5s 251us/step - loss: 0.0046 - acc: 0.9981 - val_loss: 1.7839 - val_acc: 0.4868\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"i8UOvFt1aapw","colab_type":"text"},"cell_type":"markdown","source":["## 2.4 Train From Scratch - CNN - dim100"]},{"metadata":{"id":"_z2spU5ncdcp","colab_type":"code","outputId":"da1afa25-8a60-4db6-ab70-bd2b5bbf1b35","colab":{"base_uri":"https://localhost:8080/","height":612}},"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","optimizer = optimizers.SGD(lr=0.01)\n","\n","#model training\n","hist = model.fit(x_train_mv, \n","                 y_train_mv, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val_mv, y_val_mv),\n","                 shuffle=True, verbose=2)\n","\n","model.save_weights('transfer_scratch_cnn_0.h5')\n","\n","base_model = model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_44 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_49 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_25 (MaxPooling (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_50 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_25 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_85 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_86 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,075,713\n","Trainable params: 1,075,713\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 20000 samples, validate on 5000 samples\n","Epoch 1/50\n"," - 7s - loss: 0.6976 - acc: 0.5055 - val_loss: 0.6974 - val_acc: 0.4994\n","Epoch 2/50\n"," - 1s - loss: 0.6980 - acc: 0.4998 - val_loss: 0.6974 - val_acc: 0.4994\n","Epoch 3/50\n"," - 1s - loss: 0.6978 - acc: 0.4998 - val_loss: 0.6974 - val_acc: 0.4998\n","Epoch 4/50\n"," - 1s - loss: 0.6977 - acc: 0.5018 - val_loss: 0.6974 - val_acc: 0.5004\n","Epoch 5/50\n"," - 1s - loss: 0.6977 - acc: 0.5023 - val_loss: 0.6974 - val_acc: 0.5004\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"RjZ08aO9cHBn","colab_type":"code","outputId":"98550c9b-79d2-464e-a6bd-c1bdb3fd95e3","colab":{"base_uri":"https://localhost:8080/","height":612}},"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","optimizer = optimizers.SGD(lr=0.001)\n","\n","#model training\n","hist = model.fit(x_train_mv, \n","                 y_train_mv, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val_mv, y_val_mv),\n","#                  validation_split=0.1, \n","                 shuffle=True, verbose=2)\n","\n","model.save_weights('transfer_scratch_cnn_1.h5')\n","\n","base_model = model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_43 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_47 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_24 (MaxPooling (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_48 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_24 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_24 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_83 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_84 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,075,713\n","Trainable params: 1,075,713\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 20000 samples, validate on 5000 samples\n","Epoch 1/50\n"," - 7s - loss: 0.6963 - acc: 0.5031 - val_loss: 0.6948 - val_acc: 0.4990\n","Epoch 2/50\n"," - 1s - loss: 0.6932 - acc: 0.5227 - val_loss: 0.6946 - val_acc: 0.5010\n","Epoch 3/50\n"," - 1s - loss: 0.6841 - acc: 0.5516 - val_loss: 0.6961 - val_acc: 0.5044\n","Epoch 4/50\n"," - 1s - loss: 0.5931 - acc: 0.6938 - val_loss: 0.7824 - val_acc: 0.5018\n","Epoch 5/50\n"," - 1s - loss: 0.3672 - acc: 0.8389 - val_loss: 1.0463 - val_acc: 0.4948\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"YCvWnYA6aGen","colab_type":"code","outputId":"bf4b82f5-0967-41f4-d386-782cda43dc60","colab":{"base_uri":"https://localhost:8080/","height":612}},"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","optimizer = optimizers.Adam(lr=0.001)\n","\n","#model training\n","hist = model.fit(x_train_mv, \n","                 y_train_mv, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val_mv, y_val_mv),\n","#                  validation_split=0.1, \n","                 shuffle=True, verbose=2)\n","\n","model.save_weights('transfer_scratch_cnn_1.h5')\n","\n","base_model = model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_42 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_45 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_23 (MaxPooling (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_46 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_23 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_81 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_82 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,075,713\n","Trainable params: 1,075,713\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 20000 samples, validate on 5000 samples\n","Epoch 1/50\n"," - 7s - loss: 0.6970 - acc: 0.4945 - val_loss: 0.6951 - val_acc: 0.5010\n","Epoch 2/50\n"," - 1s - loss: 0.6933 - acc: 0.5190 - val_loss: 0.6951 - val_acc: 0.5036\n","Epoch 3/50\n"," - 1s - loss: 0.6779 - acc: 0.5745 - val_loss: 0.7009 - val_acc: 0.5042\n","Epoch 4/50\n"," - 1s - loss: 0.5996 - acc: 0.6833 - val_loss: 0.8146 - val_acc: 0.4944\n","Epoch 5/50\n"," - 1s - loss: 0.4218 - acc: 0.8091 - val_loss: 0.9781 - val_acc: 0.5036\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"aCqVn98npNSb","colab_type":"text"},"cell_type":"markdown","source":["# 3.Transfer Learning"]},{"metadata":{"id":"_8LOPkioAWxx","colab_type":"text"},"cell_type":"markdown","source":["## 3.1 Load Financial Data"]},{"metadata":{"id":"d7wBjICwjQVq","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_data(link):\n","  \n","  text = []\n","  sentiment = []\n","\n","  for filename in os.listdir(link):\n","    if filename != '.ipynb_checkpoints':\n","      file_path = os.path.join(link, filename)\n","      with open(file_path, encoding = 'unicode_escape') as f:\n","        dic = json.load(f)\n","\n","        for k, v in dic['text'].items():\n","          text.append(v)\n","        for k, v in dic['sentiment'].items():\n","          sentiment.append(v)\n","  return text, sentiment"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3dJEd10c37c_","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess_data(text, sentiment):\n","  # 80-20 split\n","  combo = [list(i) for i in zip(text, sentiment)]\n","  \n","  combo_test = []\n","\n","  test_size = int(len(combo)*0.2)\n","  while len(combo_test) < test_size:\n","    index = randrange(len(combo))\n","    combo_test.append(combo.pop(index))\n","  \n","  x_train = []\n","  y_train = []\n","  x_test = []\n","  y_test = []\n","  # x, y split\n","  for line in combo:\n","    x_train.append(line[0])\n","    if line[1] in ['Positive', 'positive', 'postive']:\n","      y_train.append(2)\n","    elif line[1] in ['Neutral', 'neutral', 'neutra', 'neutra;', 'Neural']:\n","      y_train.append(1)\n","    elif line[1] in ['Negative', 'negative', 'Negetive']:\n","      y_train.append(0)\n","    else:\n","      print('error in sentiment label {}'.format(line[1]))\n","  for line in combo_test:\n","    x_test.append(line[0])\n","    if line[1] in ['Positive', 'positive', 'postive']:\n","      y_test.append(2)\n","    elif line[1] in ['Neutral', 'neutral', 'neutra', 'neutra;', 'Neural']:\n","      y_test.append(1)\n","    elif line[1] in ['Negative', 'negative', 'Negetive']:\n","      y_test.append(0)\n","    else:\n","      print('error in sentiment label {}'.format(line[1]))\n","      \n","  return (x_train, y_train), (x_test, y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qufGKe6S204Z","colab_type":"code","colab":{}},"cell_type":"code","source":["link = 'drive/INFO7374_NeuralNetwork&AI/Assignment_3/data/updated-json-files'\n","text, sentiment = load_data(link)\n","(x_train, y_train), (x_test, y_test) = preprocess_data(text, sentiment)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5YZyfWNbd_hA","colab_type":"code","colab":{}},"cell_type":"code","source":["# convert to one-hot encoding\n","\n","from keras.utils import to_categorical\n","\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XuMk60uocOoF","colab_type":"code","outputId":"4e06ab83-204b-4c8f-feb2-e0a46c4cfce5","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["len(x_train), len(x_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1316, 328)"]},"metadata":{"tags":[]},"execution_count":71}]},{"metadata":{"id":"Al6u9YsJFTWH","colab_type":"code","outputId":"09beeaa0-c811-4ae4-f4ea-6cdf5de55db7","colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","maxlen = 100  # We will cut reviews after 100 words\n","training_samples = 1000  # We will be training on 200 samples\n","validation_samples = 316  # We will be validating on 10000 samples\n","max_words = 10000  # We will only consider the top 10,000 words in the dataset\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(x_train)\n","sequences = tokenizer.texts_to_sequences(x_train)\n","\n","sequences_test = tokenizer.texts_to_sequences(x_test)\n","x_test = pad_sequences(sequences_test, maxlen=maxlen)\n","y_test = np.asarray(y_test)\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","data = pad_sequences(sequences, maxlen=maxlen)\n","\n","labels = np.asarray(y_train)\n","print('Shape of data tensor:', data.shape)\n","print('Shape of label tensor:', labels.shape)\n","\n","# Split the data into a training set and a validation set\n","# But first, shuffle the data, since we started from data\n","# where sample are ordered (all negative first, then all positive).\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","x_train = data[:training_samples]\n","y_train = labels[:training_samples]\n","x_val = data[training_samples: training_samples + validation_samples]\n","y_val = labels[training_samples: training_samples + validation_samples]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 5867 unique tokens.\n","Shape of data tensor: (1316, 100)\n","Shape of label tensor: (1316, 3)\n"],"name":"stdout"}]},{"metadata":{"id":"09OMz2eTp7CM","colab_type":"code","outputId":"c2d443cf-5fec-41aa-91e4-823063b896e7","colab":{"base_uri":"https://localhost:8080/","height":272}},"cell_type":"code","source":["base_model.load_weights('transfer_1.h5')\n","base_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_24 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 10000)             0         \n","_________________________________________________________________\n","dense_47 (Dense)             (None, 32)                320032    \n","_________________________________________________________________\n","dense_48 (Dense)             (None, 1)                 33        \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 320,065\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"ptgLhdgKpLMp","colab_type":"code","outputId":"b33719e7-fef2-4435-a498-396b13066283","colab":{"base_uri":"https://localhost:8080/","height":306}},"cell_type":"code","source":["model = Sequential()\n","for layer in base_model.layers[:-1]:\n","    model.add(layer)\n","    \n","for layer in model.layers:\n","  layer.trainable = False\n","  \n","\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(3, activation='softmax'))\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_24 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 10000)             0         \n","_________________________________________________________________\n","dense_47 (Dense)             (None, 32)                320032    \n","_________________________________________________________________\n","dense_49 (Dense)             (None, 32)                1056      \n","_________________________________________________________________\n","dense_50 (Dense)             (None, 3)                 99        \n","=================================================================\n","Total params: 1,321,187\n","Trainable params: 1,155\n","Non-trainable params: 1,320,032\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"oJMsTGycuqjR","colab_type":"text"},"cell_type":"markdown","source":["### 5.4 Train use Financial Data"]},{"metadata":{"id":"PsnjBhQMV1v-","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optimizers.SGD(lr=0.1)\n","loss = 'categorical_crossentropy'\n","epochs = 200\n","batch_size = 54\n","\n","model.compile(optimizer= optimizer,\n","              loss = loss,\n","              metrics=['acc'])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xQAz2QhsE_48","colab_type":"code","outputId":"60574a7e-e15f-41a9-92ce-53944776c0d4","colab":{"base_uri":"https://localhost:8080/","height":479}},"cell_type":"code","source":["hist = model.fit(x_train, y_train,\n","                 epochs=epochs,\n","                 batch_size=batch_size,\n","                 validation_split=0.2,\n","                 callbacks = callbacks_list\n","                )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 800 samples, validate on 200 samples\n","Epoch 1/200\n","800/800 [==============================] - 2s 2ms/step - loss: 1.0001 - acc: 0.5275 - val_loss: 0.9965 - val_acc: 0.5600\n","Epoch 2/200\n","800/800 [==============================] - 0s 95us/step - loss: 0.9387 - acc: 0.5875 - val_loss: 0.9688 - val_acc: 0.5550\n","Epoch 3/200\n","800/800 [==============================] - 0s 92us/step - loss: 0.8961 - acc: 0.5987 - val_loss: 0.9430 - val_acc: 0.5450\n","Epoch 4/200\n","800/800 [==============================] - 0s 83us/step - loss: 0.8783 - acc: 0.6088 - val_loss: 0.9180 - val_acc: 0.5950\n","Epoch 5/200\n","800/800 [==============================] - 0s 103us/step - loss: 0.8558 - acc: 0.6100 - val_loss: 0.9093 - val_acc: 0.5850\n","Epoch 6/200\n","800/800 [==============================] - 0s 94us/step - loss: 0.8490 - acc: 0.5950 - val_loss: 0.8969 - val_acc: 0.6100\n","Epoch 7/200\n","800/800 [==============================] - 0s 98us/step - loss: 0.8358 - acc: 0.5950 - val_loss: 0.9028 - val_acc: 0.5700\n","Epoch 8/200\n","800/800 [==============================] - 0s 99us/step - loss: 0.8340 - acc: 0.6050 - val_loss: 0.8861 - val_acc: 0.6150\n","Epoch 9/200\n","800/800 [==============================] - 0s 99us/step - loss: 0.8236 - acc: 0.6075 - val_loss: 0.8965 - val_acc: 0.6000\n","Epoch 10/200\n","800/800 [==============================] - 0s 98us/step - loss: 0.8151 - acc: 0.6050 - val_loss: 0.8825 - val_acc: 0.5750\n","Epoch 11/200\n","800/800 [==============================] - 0s 98us/step - loss: 0.8138 - acc: 0.6087 - val_loss: 0.9100 - val_acc: 0.5250\n","Epoch 12/200\n","800/800 [==============================] - 0s 123us/step - loss: 0.8120 - acc: 0.5962 - val_loss: 0.8801 - val_acc: 0.6250\n","Epoch 00012: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"pQHnJ5IRFgzE","colab_type":"code","outputId":"7e42ffd9-090e-4ee8-ed20-8d2894c238e9","colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["model.evaluate(x_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["328/328 [==============================] - 0s 89us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.8400967150199704, 0.573170731707317]"]},"metadata":{"tags":[]},"execution_count":88}]},{"metadata":{"id":"lieYr-B2FqlY","colab_type":"code","outputId":"b505e3bc-5277-4628-e133-0f1541f53e6c","colab":{"base_uri":"https://localhost:8080/","height":364}},"cell_type":"code","source":["import seaborn as sns\n","from sklearn import metrics\n","\n","y_pred = model.predict(x_test)\n","matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n","sns.heatmap(matrix,annot=True,fmt='.5g')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f4b41fce358>"]},"metadata":{"tags":[]},"execution_count":89},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAcEAAAFKCAYAAABlzOTzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHXdJREFUeJzt3Xt0VGWa7/FfJSFXEgIhBSZAQJSg\nGJCrDRiQBm1abcWDChOh1WY8ONKI00wHRBppEYaLLgVFoUXBRiLRjCjHxk64CK1NCDcF1KHBG7dA\nSDAht6qEJDV/9JzqYdAIxVtsdvb346q1qF1Vbz0ulvn5vPvZOy6fz+cTAAAOFGJ1AQAAWIUQBAA4\nFiEIAHAsQhAA4FiEIADAsQhBAIBjhQX7C2rLTwX7K2CRym++troEBEldpcfqEhAk7oGDgrZ295TB\nAX9276EtBis5f0EPQQCAM7hcLqtLuGBshwIAHItOEABghMtlv77KfhUDAGAInSAAwIgQ2e+cICEI\nADDCjoMxhCAAwIgQG54TJAQBAEbYsRO0X2wDAGAIIQgAcCy2QwEARriYDgUAOBWDMQAAx7LjYAwh\nCAAwIsSGIWi/3hUAAEMIQQCAY7EdCgAwwmXDvooQBAAYwWAMAMCx7DgYQwgCAIyw48Xy9tvABQDA\nEEIQAOBYbIcCAIzgtmkAAMdiOhQA4FhMhwIAHIvpUAAAbIROEABghB0HY+xXMQAAhtAJAgCMYDoU\nAOBYTIcCAByL6VAAAGyEThAAYATnBAEAjmXHc4JshwIAHIsQBAAY4bqIf37MgQMHNGzYML3xxhuS\npOPHj2vs2LHKyMjQpEmTVFtbK0lau3atRo4cqXvuuUdvv/32j65LCAIAjAhxhQT8aEx1dbVmzZql\n/v37+48tWrRIGRkZysrKUkpKinJyclRdXa3FixdrxYoVWrlypV5//XWVlZU1XrORf3MAAIIkPDxc\nr7zyitxut/9YQUGBhg4dKkkaMmSI8vPztWfPHqWlpSk2NlaRkZHq1auXdu/e3ejaDMYAAIwI1nRo\nWFiYwsLOjiuPx6Pw8HBJUkJCgoqLi1VSUqJWrVr539OqVSsVFxc3vrb5cgEATmTVdKjP57ug4/8T\n26EAACOCORjzv0VHR8vr9UqSioqK5Ha75Xa7VVJS4n/PyZMnz9pC/T6EIADAdgYMGKDc3FxJUl5e\nntLT09WjRw/t27dP5eXlqqqq0u7du9WnT59G12E71JCCHTv17MIXVe3x6Iq2bTVrxhNq26bx/wPB\n5auurk4vZWXrzfc/0HsvL5Q7IUF/2vwXPbd8pRJaxvvfd/fwm3XP8FssrBQX6uNPPtWr776nM3V1\niotprn/75Rhd2S5Zb+Vt0NotW9TQ4FP3Lldr8tj71CyMH5EXIljboZ999pnmzZunY8eOKSwsTLm5\nuXrmmWc0depUZWdnKykpSSNGjFCzZs00efJkjRs3Ti6XSxMmTFBsbGyja/M3bEC1x6PMJ2bo5UXP\n6dquqVq1+i3Nmjtfi597xurSEKDMBc/pms5XnnN8cL8++t2E8RZUBBOKS0s1+9XleunxKeqUnKQ1\nmz7Ugj+u1K9H3aOcDRv06swZah4Vpd+9tEQ5Gzbqn4b/zOqSIem6667TypUrzzm+fPnyc44NHz5c\nw4cPP++12Q41YPuOXWqXnKxru6ZKku6643Zt3bZdVVVVFleGQD04coQeunek1WXAsLDQUM0c/5A6\nJSdJktKuvlrfHivUhzt26ad9+yo2Oloul0u3pd+oD3fssrha+3G5XAE/rHJenWBVVZX/ZGNiYqKi\no6ODWpTdHDp8WO2Sk/3Po6OjFd+ihQ4fPaprUlMtrAyBSuty9fceP/jtIT0y82mVlJapR9dUTbr/\nPjXnvwfbaBkXpxvSrvM/L9i3T9dc2UlHioo08Poe/uPJiYk6fOKEFSXamh3vHdpoCO7bt0+zZ89W\neXm5WrZsKZ/Pp5MnT6pNmzaaMWOGUvkBL0nyeGsUERF+1rGIiAh5PF6LKkIwtL+irdL79lbGL25V\naEiInlq8VM+veEPTH/m/VpeGAOz84j/1Vt4GPf/byXo+602FN2vmfy0ivJm8NTUWVmdPdvx9go2G\n4Jw5czR79mx17tz5rOOff/65nnrqKa1atSqoxdlFVFSkampqzzrm9XoVHRVlUUUIhu6pXdQ9tYv/\n+f0jfqF/nbPAwooQqL/s/kQLV72peZMmqlNykqIiIlR75oz/dW9traIiIiys0J7s2Ak2ek7Q5/Od\nE4CS1K1bN9XX1wetKLvp1DFFR44e9T+vqKxUeUWFOnRob2FVMK2o5JRKy8v9z+saGhQaGmphRQjE\nzs+/0KI3V+vZyf+qrp06SpI6tG2rYydP+t9ztOikOiYlWVMgLqlGQ7BHjx56+OGHlZOTo02bNmnT\npk166623NG7cOPXr1+9S1XjZ69e7twqPn9DuT/dIklZmrdbgGwfSCTYx7+Rt0Nwlr6qurk71DQ3K\n+SBPA3tdb3VZuADemhr9+2srNHvCI+qYdIX/+E/79tGGgh367nS56urr9fb6jRp6Q18LK8Wl4vL9\nyH1lduzYofz8fP9gjNvt1sCBA9WzZ8/z+oLa8lMXX6UN7Ni1W3OffV4ej0cd2rXT009OV+vWCVaX\nFVSV33xtdQlB8V3Zaf3LzKclSYcLjyu5jVuhoaF6YcbjWvrm29r7twMKcbmUlnq1HntgbJMcjKmr\n9FhdQlBs2Fagf39thdq2bn3W8Rem/Fabtu/Qf2zaJPmkPt2u1aSM0Qprgp2+e+CgoK39QP9/Cfiz\nK/JfNljJ+fvRELxYTglBJ2qqIYimG4IIbgj+asAjAX/2ta0vGazk/HGxPADAiCY3HQoAwPlqctOh\nAAA0ZYQgAMCx2A4FABhh5T1AA0UIAgCMsOM5QUIQAGAEnSAAwLHseIkEgzEAAMeiEwQAGBFiv0aQ\nThAA4Fx0ggAAIxiMAQA4FpdIAAAcy46dIOcEAQCORScIADAixIbXCRKCAAAj2A4FAMBG6AQBAEYw\nHQoAcCwbZiDboQAA56ITBAAYwXYoAMCx7PirlAhBAIARXCIBAICN0AkCAIzgnCAAwLFsmIFshwIA\nnItOEABgBNuhAADH4hIJAIBj2bET5JwgAMCx6AQBAEbYsBGkEwQAOBedIADACDveNo0QBAAYEazB\nmKqqKk2ZMkWnT5/WmTNnNGHCBCUmJmrmzJmSpNTUVP3+978PaG1CEABgRLAawTVr1qhTp06aPHmy\nioqKdP/99ysxMVHTpk1T9+7dNXnyZG3ZskWDBw++4LU5JwgAMCLE5Qr40ZiWLVuqrKxMklReXq74\n+HgdO3ZM3bt3lyQNGTJE+fn5gdUc0KcAALhEbrvtNhUWFurmm2/WmDFjlJmZqbi4OP/rCQkJKi4u\nDmhttkMBAJe19957T0lJSXr11Ve1f/9+TZgwQbGxsf7XfT5fwGsTggAAI4J127Tdu3frxhtvlCR1\n7dpVNTU1qqur879eVFQkt9sd0NpshwIAjHC5XAE/GpOSkqI9e/ZIko4dO6aYmBh17txZO3fulCTl\n5eUpPT09oJrpBAEARoQEaTp01KhRmjZtmsaMGaO6ujrNnDlTiYmJmjFjhhoaGtSjRw8NGDAgoLUJ\nQQCAEcG6WD4mJkYLFy4853hWVtZFr812KADAsQhBAIBjsR2KgN10x79ZXQKCZPmkcVaXgCBxDxwU\ntLW5dygAwLGCNRgTTIQgAMAIOkEAgGPZMAMZjAEAOBedIADAiGD9PsFgohMEADgWnSAAwIhg3UA7\nmAhBAIARNtwNJQQBAGZwThAAABuhEwQAGMHF8gAAx7JhBrIdCgBwLjpBAIARbIcCABzLjr9Fgu1Q\nAIBj0QkCAIxgOxQA4Fg2zEBCEABgBneMAQDARugEAQBG2PGcIJ0gAMCx6AQBAEbYsBEkBAEAZthx\nO5QQBAAYYcMMJAQBAGZwiQQAADZCCAIAHIvtUACAETbcDSUEAQBmMB0KAHAsG2YgIQgAMMOOnSCD\nMQAAxyIEAQCOxXYoAMAIG+6GEoIAADPseMcYQhAAYIQNM5AQBACYwXQoAAA2QicIADDCho0gIQgA\nuPytXbtWy5YtU1hYmB599FGlpqYqMzNT9fX1SkxM1IIFCxQeHn7B67IdCgAwwuVyBfxoTGlpqRYv\nXqysrCwtWbJEGzdu1KJFi5SRkaGsrCylpKQoJycnoJoJQQCAES5X4I/G5Ofnq3///mrevLncbrdm\nzZqlgoICDR06VJI0ZMgQ5efnB1QzIWhIwY6dunfMA7p95Cg9NGGSThSdtLokXKCwsFBNnv6I9h7a\nojZtE/3HWyXEa+kbz+r9LavO+cy9Y+7UBx+v1gcfr9bv5kxWWFjopSwZAYrrlKzev/mlwuNiJEnx\nV7VXtwdH6Lpf3aUrfzFYIeHNLK7QnoLVCR49elRer1cPP/ywMjIylJ+fL4/H49/+TEhIUHFxcUA1\nE4IGVHs8ynxihmZOf1zv/0e2bkofqFlz51tdFi7QwmVz5KnynHUsrkWsXntrkQ7+7etz3t+zT5rG\n/vO9yrhjvG4ffJ9imkfr+j5pl6pcBMgVFqp26b1U56mRJIXHNVeHn96gL9ds1GevrVFtRZVaXNnO\n4irxv5WVlenFF1/U3Llz9fjjj8vn8/lf+59/vlABh2B5eXnAX9rUbN+xS+2Sk3Vt11RJ0l133K6t\n27arqqrK4spwIZYu+qNeem75Wcd8Pp8ee+gJbV7/13Pef+e9P1dO1lqVfnda9fX1mvroLO3c9uml\nKhcBSurfQ6e++Fr1tWckSa2u6aTSLw+rpqxCknR0806V7v/GyhJtK1jboQkJCerZs6fCwsLUoUMH\nxcTEKCYmRl6vV5JUVFQkt9sdUM0Bh+Cvf/3rQD/a5Bw6fFjtkpP9z6OjoxXfooUOHz1qYVW4UHt3\nf37OsYrySn379ZHvfX/qNZ0VHR2lFW+/oLWbVurR3z6kkBA2Vy5nka3jFZeSpKLdX/iPRSe2kq++\nQVePHKZuD45Qh6E3yMW2dkCCtR164403atu2bWpoaFBpaamqq6s1YMAA5ebmSpLy8vKUnp4eUM2N\nXiKxatW550D+v6KiooC+sCnyeGsUEXH2aG5ERIQ8Hq9FFeFSiI1rrp590/TIA5kKDw/Xsjef09Ej\nhXpn9Z+sLg0/IGXoT3R403ap4R/bZ6ER4YprFacDb69Xw5k6db7zJl3RL02FW+nqLxdt2rTRz372\nM917772SpOnTpystLU1TpkxRdna2kpKSNGLEiIDWbjQEV6xYof79+39vm1lXVxfQFzZFUVGRqqmp\nPeuY1+tVdFSURRXhUqisqNIHazequsqj6iqP3sv5s/qn9yUEL1Ot066W57vTqio8e2itvrZWVceL\nVfff/9NavOeA2va7jhAMQDAvlh89erRGjx591rHly5f/wLvPX6MhuHjxYj399NOaPn36ORchFhQU\nXPSXNxWdOqYod/1G//OKykqVV1SoQ4f2FlaFYCs8VqTmsc39zxvq69VQ32BhRWhM/FXtFd0mQfFX\n3iNJCouKUNeM23SmslpnKqv97/P5fPI1BD5o4WR2/C0SjZ7A6NKli5YuXaqwsHOzcurUqUErym76\n9e6twuMntPvTPZKklVmrNfjGgXSCTVzu/9ukkf90u5rHxigiIly33XWLtv11p9Vl4Qd8uWaT9i55\nW3uX/v1RW1Gt/Vl/0uGN29SyS0c1ax4tuVxqfd1Vqjh83OpybSlYgzHB9KO3TYv6gR/k3bp1M16M\nXUVGRmjBnKc0e/6z8ng86tCunZ5+crrVZeECtGrdUsuzF/qfv5r9vOrr6vXqS6s07pH7FBkVqdaJ\nrfTexj/qZFGJHsr4jXLf/1Cdu3TSO3kr5PXWaPP6j/Xe23+28N8Cgag6XqLC/D1KHTVcvoYGVR47\nqRPbP7O6LFwiLt/FXGBxHmrLTwVzeVioT9r/sboEBMnySeOsLgFB0vs3vwza2humLgn4s8PmPmyw\nkvPHDbQBAEbY8JQgd4wBADgXnSAAwAhXiP1aQUIQAGAE26EAANgInSAAwIgfuwfo5YgQBAAYYcMM\nJAQBAGbYsRPknCAAwLHoBAEARtiwEaQTBAA4F50gAMAMG7aChCAAwAg7DsYQggAAI2yYgYQgAMAM\nO947lMEYAIBjEYIAAMdiOxQAYATnBAEAjsV0KADAsWyYgYQgAMAMO3aCDMYAAByLEAQAOBbboQAA\nI2y4G0oIAgDMsOM5QUIQAGCGDU+wEYIAACPs2AnaMLcBADCDEAQAOBbboQAAI2y4G0oIAgDMsOM5\nQUIQAGCEDTOQEAQAGGLDFGQwBgDgWHSCAAAjXCF0ggAA2AadIADACBueEiQEAQBm2PESCbZDAQBG\nuFyBP86H1+vVsGHD9M477+j48eMaO3asMjIyNGnSJNXW1gZUMyEIALCFl19+WS1atJAkLVq0SBkZ\nGcrKylJKSopycnICWpMQBACYEcRW8KuvvtKXX36pm266SZJUUFCgoUOHSpKGDBmi/Pz8gEomBAEA\nRrhCXAE/fsy8efM0depU/3OPx6Pw8HBJUkJCgoqLiwOqmRAEAFzW3n33XV1//fVq3779977u8/kC\nXpvpUACAEcEaDt28ebOOHDmizZs368SJEwoPD1d0dLS8Xq8iIyNVVFQkt9sd0NqEIADAjCCl4PPP\nP+//8wsvvKDk5GR98sknys3N1Z133qm8vDylp6cHtDbboQAA25k4caLeffddZWRkqKysTCNGjAho\nHTpBBGzu3fdaXQKC5JNPTlhdAoKkdxDXvhTXyk+cONH/5+XLl1/0eoQgAMAIO95AmxAEABjBbdMA\nALAROkEAgBn2awTpBAEAzkUnCAAwwo7nBAlBAIARhCAAwLlseIKNEAQAGGHHTtCGuQ0AgBmEIADA\nsdgOBQAYYcftUEIQAGCG/TKQEAQAmMENtAEAzmXD7VAGYwAAjkUIAgAci+1QAIARNtwNJQQBAGZw\niQQAwLmYDgUAOJUdO0EGYwAAjkUnCAAww36NIJ0gAMC56AQBAEbY8ZwgIQgAMIJ7hwIAnItOEADg\nVHbcDmUwBgDgWHSCAAAz7NcI0gkCAJyLThAAYATToQAA57LhYAwhCAAwgulQAABshE4QAGAG5wQB\nAE7FdigAADZCJwgAMMN+jSAhCAAwg+1QAABshE4QAGAG06HOVbBjp55d+KKqPR5d0batZs14Qm3b\nuK0uCwGIahmrwY/fp+pT5f5jZYeLtC97k1JvGyD3tSkKDQvTt3/dp282f2JhpbhQHft2UZ+70886\nFp+UoNcfel597klX8nUd5XK5VPjFYW3943r5GnwWVWpPdtwOJQQNqPZ4lPnEDL286Dld2zVVq1a/\npVlz52vxc89YXRoC5D1dpb/MyzrrWIf+3RSf4tbHz2YrJCxUAx4dqbJDJ1T6zXGLqsSF+nbHAX27\n44D/ead+qbryJ13V9ac91OKKVnpn2nJJ0q2Pj1aXQWn62+a9VpVqT0EMwfnz52vXrl2qq6vT+PHj\nlZaWpszMTNXX1ysxMVELFixQeHj4Ba/LOUEDtu/YpXbJybq2a6ok6a47btfWbdtVVVVlcWUwqXWX\n9ircfVANdfWq89bq6I79atu9s9VlIUChzULV5+50bV+9RSf2H1H+yo1qqG9QQ32Dir8+rpbJra0u\nEf9t27ZtOnjwoLKzs7Vs2TLNmTNHixYtUkZGhrKyspSSkqKcnJyA1j6vEPT5zt0SOHHiREBf2BQd\nOnxY7ZKT/c+jo6MV36KFDh89amFVuBhhkeHq9eDPNWhKhvo+dLti3C0lnX2X/LqaM4pp3cKqEnGR\nugzurqKDx1RxskzFX5/Q6ePfSfr733HydR118is6/AvlcrkCfjSmb9++WrhwoSQpLi5OHo9HBQUF\nGjp0qCRpyJAhys/PD6jmRkNw/fr1GjJkiPr3768pU6aosrLS/1pmZmZAX9gUebw1iog4uw2PiIiQ\nx+O1qCJcjLqaWhXuPqD/fPdj/WV+lkoOHFWfX92qU18eU/t+1yosMlzNoiOU3DtVIWGhVpeLQLik\ntJ/31d512895aeADt6jquwp9U7DfgsLwfUJDQxUdHS1JysnJ0aBBg+TxePzbnwkJCSouLg5o7UZD\n8A9/+IPWrFmjrVu3qlevXho3bpwqKiokfX936FRRUZGqqak965jX61V0VJRFFeFinKmu0RdrPpKn\ntELySd9s+VThzaP03deFKjlwRAMm3a1e9/9cJQeO6IynxupyEYA2VyWrzlursmOn/MdcIS4NHn+r\nYlrFasPCd/kZF4gQV+CP87Bhwwbl5ORoxowZZx2/mL+rRgdjQkNDFR8fL0kaNWqUEhISNG7cOC1Z\nssSWU0DB0qljinLXb/Q/r6isVHlFhTp0aG9hVQhUWFSEmkWFy/Ndhf+YKyRE9WfqtP/9rdr//lZJ\n0lU391HFie+sKhMXoX3Pzjqy5+uzjqWPG67Q8DDlPfeOfPUNFlVmb8HMhY8++khLlizRsmXLFBsb\nq+joaHm9XkVGRqqoqEhud2DT+I12gr169dL48ePl9f59W2/YsGGaOHGiHnjgAX377bcBfWFT1K93\nbxUeP6Hdn+6RJK3MWq3BNw6kE7Sp+PZu3fDwCIXHREqS2v/kWnlKKxTfoY2uH3OL5JIi4qLVrm9X\nFe468COr4XKU0CFRZYX/6AI79rla8ckJ+vCl9wnAi+FyBf5oREVFhebPn6+lS5f6G7MBAwYoNzdX\nkpSXl6f09PTGlvhBjXaCmZmZKigoUEREhP9Yenq6evbsqXXr1gX0hU1RZGSEFsx5SrPnPyuPx6MO\n7drp6SenW10WAlRy4IgObf1M/SeOlM/nk/d0lXa//md5yyrUNu1K3fT4WPkaGrT/T9tUfeq01eUi\nADEtY1V9+h/T212HXK/Y1i00cs6D/mNFB4/po2V/tqI823IF6WL5devWqbS0VI899pj/2Ny5czV9\n+nRlZ2crKSlJI0aMCGhtly/IG9+15ad+/E2wpQ2/X211CQiSwpNc3tNU/fPK4A01luzYGvBnW/cd\nYLCS88d1ggAAx+KOMQAAM2w4MEkIAgCMsONVA4QgAMAMQhAA4FTBmg4NJgZjAACORQgCAByL7VAA\ngBmcEwQAOBYhCABwKi6RAAA4F9OhAADYB50gAMAIl8t+fZX9KgYAwBA6QQCAGQzGAACciulQAIBz\nMR0KAIB90AkCAIxgOxQA4Fw2DEG2QwEAjkUnCAAww4YXyxOCAAAj+M3yAADYCJ0gAMAMGw7GEIIA\nACO4RAIA4Fw2HIyxX8UAABhCJwgAMILpUAAAbIROEABgBoMxAACnYjoUAOBcNpwOJQQBAGYwGAMA\ngH0QggAAx2I7FABgBIMxAADnYjAGAOBUdIIAAOeyYSdov4oBADCEEAQAOBbboQAAI4L5WyTmzJmj\nPXv2yOVyadq0aerevbuRdQlBAIAZQRqM2b59uw4dOqTs7Gx99dVXmjZtmrKzs42sTQgCAIxwBWkw\nJj8/X8OGDZMkde7cWadPn1ZlZaWaN29+0WtzThAAYIbLFfijESUlJWrZsqX/eatWrVRcXGyk5KB3\nguFxCcH+Cljk1mcnWF0CgMvIpfp57/P5jK1FJwgAuKy53W6VlJT4n588eVKJiYlG1iYEAQCXtYED\nByo3N1eS9Pnnn8vtdhs5HygxGAMAuMz16tVL3bp10+jRo+VyufTkk08aW9vlM7m5CgCAjbAdCgBw\nLEIQAOBYhKAhc+bM0ahRozR69Gjt3bvX6nJg2IEDBzRs2DC98cYbVpcCw+bPn69Ro0Zp5MiRysvL\ns7ocXGIMxhgQzFv6wHrV1dWaNWuW+vfvb3UpMGzbtm06ePCgsrOzVVpaqrvuuku33HKL1WXhEqIT\nNOCHbumDpiE8PFyvvPKK3G631aXAsL59+2rhwoWSpLi4OHk8HtXX11tcFS4lQtCAYN7SB9YLCwtT\nZGSk1WUgCEJDQxUdHS1JysnJ0aBBgxQaGmpxVbiU2A4NAq46Aexlw4YNysnJ0WuvvWZ1KbjECEED\ngnlLHwDB9dFHH2nJkiVatmyZYmNjrS4HlxjboQYE85Y+AIKnoqJC8+fP19KlSxUfH291ObAAnaAB\nwbylD6z32Wefad68eTp27JjCwsKUm5urF154gR+aTcC6detUWlqqxx57zH9s3rx5SkpKsrAqXErc\nNg0A4FhshwIAHIsQBAA4FiEIAHAsQhAA4FiEIADAsQhBAIBjEYIAAMciBAEAjvVfA/tTFCx6RyIA\nAAAASUVORK5CYII=\n","text/plain":["<Figure size 576x396 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"sJGIjBHrtY5N","colab_type":"code","outputId":"a834fa0f-b943-429d-9ec6-889d0e435bdf","colab":{"base_uri":"https://localhost:8080/","height":377}},"cell_type":"code","source":["optimizer = optimizers.Adam(lr=0.1)\n","loss = 'categorical_crossentropy'\n","epochs = 200\n","batch_size = 54\n","\n","model.compile(optimizer= optimizer,\n","              loss = loss,\n","              metrics=['acc'])\n","\n","hist = model.fit(x_train, y_train,\n","                 epochs=epochs,\n","                 batch_size=batch_size,\n","                 validation_data=(x_val, y_val),\n","                 callbacks = callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 1000 samples, validate on 316 samples\n","Epoch 1/200\n","1000/1000 [==============================] - 2s 2ms/step - loss: 1.1388 - acc: 0.5790 - val_loss: 0.8968 - val_acc: 0.5570\n","Epoch 2/200\n","1000/1000 [==============================] - 0s 112us/step - loss: 0.8377 - acc: 0.6100 - val_loss: 0.8888 - val_acc: 0.5253\n","Epoch 3/200\n","1000/1000 [==============================] - 0s 111us/step - loss: 0.8241 - acc: 0.5940 - val_loss: 0.8954 - val_acc: 0.5222\n","Epoch 4/200\n","1000/1000 [==============================] - 0s 105us/step - loss: 0.8366 - acc: 0.5610 - val_loss: 0.9279 - val_acc: 0.4589\n","Epoch 5/200\n","1000/1000 [==============================] - 0s 120us/step - loss: 0.8284 - acc: 0.5520 - val_loss: 0.8648 - val_acc: 0.5918\n","Epoch 6/200\n","1000/1000 [==============================] - 0s 112us/step - loss: 0.8254 - acc: 0.5610 - val_loss: 0.9199 - val_acc: 0.5285\n","Epoch 7/200\n","1000/1000 [==============================] - 0s 108us/step - loss: 0.8151 - acc: 0.5610 - val_loss: 0.8688 - val_acc: 0.5886\n","Epoch 8/200\n","1000/1000 [==============================] - 0s 110us/step - loss: 0.8076 - acc: 0.5800 - val_loss: 0.8677 - val_acc: 0.5949\n","Epoch 9/200\n","1000/1000 [==============================] - 0s 107us/step - loss: 0.7979 - acc: 0.5940 - val_loss: 0.8922 - val_acc: 0.5981\n","Epoch 00009: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"--9lNCyTUZeg","colab_type":"code","outputId":"41eccb28-ad1c-4bd6-b947-84b751d4c7e2","colab":{"base_uri":"https://localhost:8080/","height":241}},"cell_type":"code","source":["optimizer = optimizers.Adam(lr=0.01)\n","loss = 'categorical_crossentropy'\n","epochs = 200\n","batch_size = 54\n","\n","model.compile(optimizer= optimizer,\n","              loss = loss,\n","              metrics=['acc'])\n","\n","hist = model.fit(x_train, y_train,\n","                 epochs=epochs,\n","                 batch_size=batch_size,\n","                 validation_data=(x_val, y_val),\n","                 callbacks = callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 1000 samples, validate on 316 samples\n","Epoch 1/200\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.7939 - acc: 0.5950 - val_loss: 0.8695 - val_acc: 0.5949\n","Epoch 2/200\n","1000/1000 [==============================] - 0s 142us/step - loss: 0.7876 - acc: 0.5940 - val_loss: 0.8724 - val_acc: 0.5981\n","Epoch 3/200\n","1000/1000 [==============================] - 0s 110us/step - loss: 0.7848 - acc: 0.5970 - val_loss: 0.8774 - val_acc: 0.5981\n","Epoch 4/200\n","1000/1000 [==============================] - 0s 114us/step - loss: 0.7839 - acc: 0.5980 - val_loss: 0.8771 - val_acc: 0.5981\n","Epoch 5/200\n","1000/1000 [==============================] - 0s 110us/step - loss: 0.7817 - acc: 0.5980 - val_loss: 0.8819 - val_acc: 0.5981\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"dzwB6ZBFVwAl","colab_type":"code","outputId":"fad76a38-c57c-4617-f152-0e84c9dbbbcb","colab":{"base_uri":"https://localhost:8080/","height":241}},"cell_type":"code","source":["optimizer = optimizers.Adam(lr=0.001)\n","loss = 'categorical_crossentropy'\n","epochs = 200\n","batch_size = 54\n","\n","model.compile(optimizer= optimizer,\n","              loss = loss,\n","              metrics=['acc'])\n","\n","hist = model.fit(x_train, y_train,\n","                 epochs=epochs,\n","                 batch_size=batch_size,\n","                 validation_data=(x_val, y_val),\n","                 callbacks = callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 1000 samples, validate on 316 samples\n","Epoch 1/200\n","1000/1000 [==============================] - 2s 2ms/step - loss: 0.7803 - acc: 0.5970 - val_loss: 0.8843 - val_acc: 0.5981\n","Epoch 2/200\n","1000/1000 [==============================] - 0s 135us/step - loss: 0.7791 - acc: 0.5980 - val_loss: 0.8835 - val_acc: 0.5981\n","Epoch 3/200\n","1000/1000 [==============================] - 0s 110us/step - loss: 0.7787 - acc: 0.5980 - val_loss: 0.8825 - val_acc: 0.5981\n","Epoch 4/200\n","1000/1000 [==============================] - 0s 112us/step - loss: 0.7784 - acc: 0.5980 - val_loss: 0.8818 - val_acc: 0.5981\n","Epoch 5/200\n","1000/1000 [==============================] - 0s 109us/step - loss: 0.7782 - acc: 0.5980 - val_loss: 0.8815 - val_acc: 0.5981\n","Epoch 00005: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"GLosvLDqGIsV","colab_type":"code","outputId":"29b4533b-de87-4abc-e044-74a05cfd2698","colab":{"base_uri":"https://localhost:8080/","height":748}},"cell_type":"code","source":["model = Sequential()\n","\n","# for layer in base_model.layers[:-1]:\n","model.add(base_model.layers[0])\n","\n","for layer in model.layers:\n","  layer.trainable = False\n","  \n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","optimizer = optimizers.Adam(lr=0.001)\n","\n","#model training\n","hist = model.fit(x_train, \n","                 y_train, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val, y_val),\n","                 shuffle=True, verbose=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_24 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_22 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_11 (MaxPooling (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_23 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_11 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_53 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_54 (Dense)             (None, 3)                 99        \n","=================================================================\n","Total params: 1,075,779\n","Trainable params: 75,779\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Train on 1000 samples, validate on 316 samples\n","Epoch 1/50\n"," - 3s - loss: 1.0489 - acc: 0.4970 - val_loss: 1.0147 - val_acc: 0.4589\n","Epoch 2/50\n"," - 0s - loss: 0.9443 - acc: 0.5560 - val_loss: 0.9436 - val_acc: 0.6044\n","Epoch 3/50\n"," - 0s - loss: 0.8894 - acc: 0.5910 - val_loss: 0.9208 - val_acc: 0.5158\n","Epoch 4/50\n"," - 0s - loss: 0.8526 - acc: 0.6020 - val_loss: 0.8903 - val_acc: 0.6013\n","Epoch 5/50\n"," - 0s - loss: 0.8058 - acc: 0.6290 - val_loss: 0.8569 - val_acc: 0.6171\n","Epoch 6/50\n"," - 0s - loss: 0.7670 - acc: 0.6580 - val_loss: 0.8913 - val_acc: 0.5570\n","Epoch 7/50\n"," - 0s - loss: 0.7303 - acc: 0.6890 - val_loss: 0.8488 - val_acc: 0.5886\n","Epoch 8/50\n"," - 0s - loss: 0.6802 - acc: 0.7060 - val_loss: 0.8528 - val_acc: 0.6171\n","Epoch 9/50\n"," - 0s - loss: 0.6267 - acc: 0.7490 - val_loss: 0.8553 - val_acc: 0.5918\n","Epoch 00009: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"wH5ESNhVHi2E","colab_type":"code","outputId":"a29e48d4-9e48-4752-8b23-fb8947d3065a","colab":{"base_uri":"https://localhost:8080/","height":748}},"cell_type":"code","source":["model = Sequential()\n","\n","# for layer in base_model.layers[:-1]:\n","model.add(base_model.layers[0])\n","\n","for layer in model.layers:\n","  layer.trainable = False\n","  \n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","optimizer = optimizers.Adam(lr=0.01)\n","\n","#model training\n","hist = model.fit(x_train, \n","                 y_train, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val, y_val),\n","                 shuffle=True, verbose=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_24 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_24 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_12 (MaxPooling (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_25 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_12 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_55 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_56 (Dense)             (None, 3)                 99        \n","=================================================================\n","Total params: 1,075,779\n","Trainable params: 75,779\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Train on 1000 samples, validate on 316 samples\n","Epoch 1/50\n"," - 3s - loss: 1.0465 - acc: 0.5130 - val_loss: 0.9665 - val_acc: 0.5728\n","Epoch 2/50\n"," - 0s - loss: 0.9174 - acc: 0.5490 - val_loss: 0.9414 - val_acc: 0.5222\n","Epoch 3/50\n"," - 0s - loss: 0.8734 - acc: 0.5680 - val_loss: 0.8909 - val_acc: 0.5665\n","Epoch 4/50\n"," - 0s - loss: 0.8225 - acc: 0.6220 - val_loss: 0.8699 - val_acc: 0.6013\n","Epoch 5/50\n"," - 0s - loss: 0.7719 - acc: 0.6560 - val_loss: 0.8552 - val_acc: 0.6203\n","Epoch 6/50\n"," - 0s - loss: 0.7395 - acc: 0.6930 - val_loss: 0.8545 - val_acc: 0.6266\n","Epoch 7/50\n"," - 0s - loss: 0.6948 - acc: 0.7160 - val_loss: 0.8521 - val_acc: 0.6203\n","Epoch 8/50\n"," - 0s - loss: 0.6438 - acc: 0.7370 - val_loss: 0.8514 - val_acc: 0.6044\n","Epoch 9/50\n"," - 0s - loss: 0.5844 - acc: 0.7700 - val_loss: 0.8720 - val_acc: 0.6108\n","Epoch 00009: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"AUcyTm1GHoQi","colab_type":"code","outputId":"9e2e8f67-a0df-4212-bf9d-9040483917dd","colab":{"base_uri":"https://localhost:8080/","height":680}},"cell_type":"code","source":["model = Sequential()\n","\n","# for layer in base_model.layers[:-1]:\n","model.add(base_model.layers[0])\n","\n","for layer in model.layers:\n","  layer.trainable = False\n","  \n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","optimizer = optimizers.Adam(lr=0.1)\n","\n","#model training\n","hist = model.fit(x_train, \n","                 y_train, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val, y_val),\n","                 shuffle=True, verbose=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_24 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_26 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_13 (MaxPooling (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_27 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_13 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_57 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_58 (Dense)             (None, 3)                 99        \n","=================================================================\n","Total params: 1,075,779\n","Trainable params: 75,779\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Train on 1000 samples, validate on 316 samples\n","Epoch 1/50\n"," - 3s - loss: 1.0656 - acc: 0.5150 - val_loss: 0.9452 - val_acc: 0.5443\n","Epoch 2/50\n"," - 0s - loss: 0.8839 - acc: 0.5520 - val_loss: 0.8856 - val_acc: 0.5949\n","Epoch 3/50\n"," - 0s - loss: 0.8295 - acc: 0.5980 - val_loss: 0.8724 - val_acc: 0.6108\n","Epoch 4/50\n"," - 0s - loss: 0.7753 - acc: 0.6180 - val_loss: 0.8719 - val_acc: 0.5728\n","Epoch 5/50\n"," - 0s - loss: 0.7181 - acc: 0.6760 - val_loss: 0.9424 - val_acc: 0.5158\n","Epoch 6/50\n"," - 0s - loss: 0.7157 - acc: 0.6810 - val_loss: 0.8835 - val_acc: 0.6013\n","Epoch 7/50\n"," - 0s - loss: 0.6654 - acc: 0.7020 - val_loss: 0.9375 - val_acc: 0.6076\n","Epoch 00007: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"u0tTjd7sHt3l","colab_type":"code","outputId":"3ed56ef9-3840-4e72-ebfe-f4e29164994e","colab":{"base_uri":"https://localhost:8080/","height":1326}},"cell_type":"code","source":["model = Sequential()\n","\n","# for layer in base_model.layers[:-1]:\n","model.add(base_model.layers[0])\n","\n","for layer in model.layers:\n","  layer.trainable = False\n","  \n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","optimizer = optimizers.SGD(lr=0.001)\n","\n","#model training\n","hist = model.fit(x_train, \n","                 y_train, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val, y_val),\n","                 shuffle=True, verbose=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_24 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_34 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_17 (MaxPooling (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_35 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_17 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_65 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_66 (Dense)             (None, 3)                 99        \n","=================================================================\n","Total params: 1,075,779\n","Trainable params: 75,779\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Train on 1000 samples, validate on 316 samples\n","Epoch 1/50\n"," - 3s - loss: 1.0407 - acc: 0.4090 - val_loss: 1.0173 - val_acc: 0.4620\n","Epoch 2/50\n"," - 0s - loss: 0.9975 - acc: 0.4800 - val_loss: 1.0195 - val_acc: 0.4589\n","Epoch 3/50\n"," - 0s - loss: 0.9685 - acc: 0.4900 - val_loss: 1.0103 - val_acc: 0.4589\n","Epoch 4/50\n"," - 0s - loss: 0.9711 - acc: 0.5170 - val_loss: 0.9913 - val_acc: 0.4715\n","Epoch 5/50\n"," - 0s - loss: 0.9508 - acc: 0.5560 - val_loss: 0.9824 - val_acc: 0.5095\n","Epoch 6/50\n"," - 0s - loss: 0.9426 - acc: 0.5450 - val_loss: 0.9750 - val_acc: 0.5348\n","Epoch 7/50\n"," - 0s - loss: 0.9125 - acc: 0.5920 - val_loss: 0.9837 - val_acc: 0.4684\n","Epoch 8/50\n"," - 0s - loss: 0.9299 - acc: 0.5640 - val_loss: 0.9808 - val_acc: 0.4620\n","Epoch 9/50\n"," - 0s - loss: 0.8993 - acc: 0.5810 - val_loss: 0.9573 - val_acc: 0.5411\n","Epoch 10/50\n"," - 0s - loss: 0.9155 - acc: 0.5810 - val_loss: 0.9517 - val_acc: 0.5538\n","Epoch 11/50\n"," - 0s - loss: 0.8931 - acc: 0.5910 - val_loss: 0.9544 - val_acc: 0.5032\n","Epoch 12/50\n"," - 0s - loss: 0.9022 - acc: 0.5700 - val_loss: 0.9466 - val_acc: 0.5190\n","Epoch 13/50\n"," - 0s - loss: 0.8884 - acc: 0.5820 - val_loss: 0.9607 - val_acc: 0.4620\n","Epoch 14/50\n"," - 0s - loss: 0.8718 - acc: 0.5980 - val_loss: 0.9346 - val_acc: 0.5570\n","Epoch 15/50\n"," - 0s - loss: 0.8606 - acc: 0.5990 - val_loss: 0.9327 - val_acc: 0.5411\n","Epoch 16/50\n"," - 0s - loss: 0.8742 - acc: 0.6000 - val_loss: 0.9283 - val_acc: 0.5601\n","Epoch 17/50\n"," - 0s - loss: 0.8514 - acc: 0.6320 - val_loss: 0.9281 - val_acc: 0.5475\n","Epoch 18/50\n"," - 0s - loss: 0.8552 - acc: 0.6000 - val_loss: 0.9187 - val_acc: 0.5728\n","Epoch 19/50\n"," - 0s - loss: 0.8526 - acc: 0.6080 - val_loss: 0.9226 - val_acc: 0.5253\n","Epoch 20/50\n"," - 0s - loss: 0.8282 - acc: 0.6250 - val_loss: 0.9209 - val_acc: 0.5538\n","Epoch 21/50\n"," - 0s - loss: 0.8243 - acc: 0.6230 - val_loss: 0.9271 - val_acc: 0.5000\n","Epoch 22/50\n"," - 0s - loss: 0.8181 - acc: 0.6440 - val_loss: 0.9072 - val_acc: 0.5854\n","Epoch 23/50\n"," - 0s - loss: 0.8139 - acc: 0.6310 - val_loss: 0.9118 - val_acc: 0.5411\n","Epoch 24/50\n"," - 0s - loss: 0.8060 - acc: 0.6450 - val_loss: 0.9285 - val_acc: 0.4873\n","Epoch 25/50\n"," - 0s - loss: 0.8074 - acc: 0.6390 - val_loss: 0.9103 - val_acc: 0.5127\n","Epoch 26/50\n"," - 0s - loss: 0.7938 - acc: 0.6520 - val_loss: 0.8999 - val_acc: 0.5601\n","Epoch 00026: early stopping\n"],"name":"stdout"}]},{"metadata":{"id":"fx_hvPL8H4Qj","colab_type":"code","outputId":"2c90af48-f928-4f5e-ca1a-4b556d53235e","colab":{"base_uri":"https://localhost:8080/","height":714}},"cell_type":"code","source":["model = Sequential()\n","\n","# for layer in base_model.layers[:-1]:\n","model.add(base_model.layers[0])\n","\n","for layer in model.layers:\n","  layer.trainable = False\n","  \n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(MaxPooling1D(2))\n","model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","model.summary()\n","\n","optimizer = optimizers.SGD(lr=0.01)\n","\n","#model training\n","hist = model.fit(x_train, \n","                 y_train, \n","                 batch_size=batch_size, \n","                 epochs=num_epochs, \n","                 callbacks=callbacks_list,\n","                 validation_data=(x_val, y_val),\n","                 shuffle=True, verbose=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_24 (Embedding)     (None, 100, 100)          1000000   \n","_________________________________________________________________\n","conv1d_32 (Conv1D)           (None, 100, 64)           44864     \n","_________________________________________________________________\n","max_pooling1d_16 (MaxPooling (None, 50, 64)            0         \n","_________________________________________________________________\n","conv1d_33 (Conv1D)           (None, 50, 64)            28736     \n","_________________________________________________________________\n","global_max_pooling1d_16 (Glo (None, 64)                0         \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_63 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_64 (Dense)             (None, 3)                 99        \n","=================================================================\n","Total params: 1,075,779\n","Trainable params: 75,779\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Train on 1000 samples, validate on 316 samples\n","Epoch 1/50\n"," - 3s - loss: 1.1230 - acc: 0.4500 - val_loss: 0.9492 - val_acc: 0.4589\n","Epoch 2/50\n"," - 0s - loss: 0.8940 - acc: 0.5420 - val_loss: 0.8821 - val_acc: 0.5854\n","Epoch 3/50\n"," - 0s - loss: 0.8442 - acc: 0.5760 - val_loss: 0.8522 - val_acc: 0.6013\n","Epoch 4/50\n"," - 0s - loss: 0.8142 - acc: 0.6270 - val_loss: 0.8386 - val_acc: 0.6234\n","Epoch 5/50\n"," - 0s - loss: 0.8039 - acc: 0.6080 - val_loss: 0.8735 - val_acc: 0.5981\n","Epoch 6/50\n"," - 0s - loss: 0.7770 - acc: 0.6160 - val_loss: 0.8327 - val_acc: 0.6108\n","Epoch 7/50\n"," - 0s - loss: 0.7296 - acc: 0.6540 - val_loss: 0.9522 - val_acc: 0.5854\n","Epoch 8/50\n"," - 0s - loss: 0.6989 - acc: 0.6870 - val_loss: 0.9122 - val_acc: 0.5886\n","Epoch 00008: early stopping\n"],"name":"stdout"}]}]}