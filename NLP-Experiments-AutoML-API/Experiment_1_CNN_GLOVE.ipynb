{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment-1-CNN-GLOVE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Rsx9iwfj4Ak3",
        "CyWVTaPs2qJm",
        "psNtoKXXoJNA"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Pbw_PwyYjJO1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rsx9iwfj4Ak3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1.Preprocess Data\n"
      ]
    },
    {
      "metadata": {
        "id": "CyWVTaPs2qJm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###1.Load Data"
      ]
    },
    {
      "metadata": {
        "id": "d7wBjICwjQVq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(link):\n",
        "  \n",
        "  text = []\n",
        "  sentiment = []\n",
        "\n",
        "  for filename in os.listdir(link):\n",
        "    if filename != '.ipynb_checkpoints':\n",
        "      file_path = os.path.join(link, filename)\n",
        "      with open(file_path, encoding = 'unicode_escape') as f:\n",
        "        dic = json.load(f)\n",
        "\n",
        "        for k, v in dic['text'].items():\n",
        "          text.append(v)\n",
        "        for k, v in dic['sentiment'].items():\n",
        "          sentiment.append(v)\n",
        "  return text, sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3dJEd10c37c_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_data(text, sentiment):\n",
        "  # 80-20 split\n",
        "  combo = [list(i) for i in zip(text, sentiment)]\n",
        "  \n",
        "  combo_test = []\n",
        "\n",
        "  test_size = int(len(combo)*0.2)\n",
        "  while len(combo_test) < test_size:\n",
        "    index = randrange(len(combo))\n",
        "    combo_test.append(combo.pop(index))\n",
        "  \n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  # x, y split\n",
        "  for line in combo:\n",
        "    x_train.append(line[0])\n",
        "    if line[1] in ['Positive', 'positive', 'postive']:\n",
        "      y_train.append(2)\n",
        "    elif line[1] in ['Neutral', 'neutral', 'neutra', 'neutra;', 'Neural']:\n",
        "      y_train.append(1)\n",
        "    elif line[1] in ['Negative', 'negative', 'Negetive']:\n",
        "      y_train.append(0)\n",
        "    else:\n",
        "      print('error in sentiment label {}'.format(line[1]))\n",
        "  for line in combo_test:\n",
        "    x_test.append(line[0])\n",
        "    if line[1] in ['Positive', 'positive', 'postive']:\n",
        "      y_test.append(2)\n",
        "    elif line[1] in ['Neutral', 'neutral', 'neutra', 'neutra;', 'Neural']:\n",
        "      y_test.append(1)\n",
        "    elif line[1] in ['Negative', 'negative', 'Negetive']:\n",
        "      y_test.append(0)\n",
        "    else:\n",
        "      print('error in sentiment label {}'.format(line[1]))\n",
        "      \n",
        "  return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qufGKe6S204Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "link = 'drive/INFO7374_NeuralNetwork&AI/Assignment_3/data/updated-json-files'\n",
        "text, sentiment = load_data(link)\n",
        "(x_train, y_train), (x_test, y_test) = preprocess_data(text, sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5YZyfWNbd_hA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert to one-hot encoding\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XuMk60uocOoF",
        "colab_type": "code",
        "outputId": "80ea1b29-0d2a-43ba-a546-9f0f65b428a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(x_train), len(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1316, 328)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "E0U1ew2K-L2h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.Tokenize The Data"
      ]
    },
    {
      "metadata": {
        "id": "G5vf1_Cv4V_M",
        "colab_type": "code",
        "outputId": "302f1e50-e5c1-4653-edd5-0b84fc704a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 100  # We will cut reviews after 100 words\n",
        "training_samples = 1000  # We will be training on 1000 samples\n",
        "validation_samples = 316  # We will be validating on 316 samples\n",
        "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "sequences = tokenizer.texts_to_sequences(x_train)\n",
        "\n",
        "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
        "x_test = pad_sequences(sequences_test, maxlen=maxlen)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(y_train)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Split the data into a training set and a validation set\n",
        "# But first, shuffle the data, since we started from data\n",
        "# where sample are ordered (all negative first, then all positive).\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5792 unique tokens.\n",
            "Shape of data tensor: (1316, 100)\n",
            "Shape of label tensor: (1316, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rfz0QkpTGP66"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.Experiment -  Trainig From Scratch\n",
        "\n",
        "Observation: seems not a good idea due to poor accuracy result and the fact that data points is too limited"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EImJrssmGP69",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_dim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3cf92e87-d661-43fa-e6b0-98b445809f7a",
        "id": "ogP9JPU9GP6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.1)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 200\n",
        "batch_size = 54\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_6 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 100, 300)          3000000   \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32)                960032    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 3,960,131\n",
            "Trainable params: 3,960,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 7.3150 - acc: 0.5070 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - 0s 213us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - 0s 214us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - 0s 211us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - 0s 208us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P1GsiX6ygEVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "01vPHPTXk9PF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3.Experiment - Freezed Embedding Layer - GloVe"
      ]
    },
    {
      "metadata": {
        "id": "rhzsYxq38LsD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.1 Embedding_dim = 100"
      ]
    },
    {
      "metadata": {
        "id": "9jGtXFZrDo18",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Training"
      ]
    },
    {
      "metadata": {
        "id": "sQWBwuvdcAM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load Glove data\n",
        "    \n",
        "with zipfile.ZipFile('drive/INFO7374_NeuralNetwork&AI/Assignment_3/data/glove.6B.zip','r') as zip_ref:\n",
        "   zip_ref.extractall('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnBC4QLh4V9E",
        "colab_type": "code",
        "outputId": "8a68797c-6827-4880-ec95-d5226735a26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "with open('glove.6B.100d.txt') as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Aj2dxeEcuVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set dimemsions (# features for each word vector) for embedding layer\n",
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SMMRIlUX8ogr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4pKjY5T4V6r",
        "colab_type": "code",
        "outputId": "6712d130-03a5-4ae8-9896-8950b6ed167d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, weights = [embedding_matrix], trainable = False, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,320,131\n",
            "Trainable params: 320,131\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q2ALuToD8I9Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define callbacks\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "glEFtKOGdMFI",
        "colab_type": "code",
        "outputId": "d720fc9f-e92f-47db-92b8-97a8105a6031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.SGD(lr=0.01, nesterov=True)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_1 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_1.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - 1s 623us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5002 - val_acc: 0.6013\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - 0s 126us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5003 - val_acc: 0.6013\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - 0s 121us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5003 - val_acc: 0.6013\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - 0s 134us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5003 - val_acc: 0.6013\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - 0s 124us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5004 - val_acc: 0.6013\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cwb0pKWLgyK8",
        "colab_type": "code",
        "outputId": "1f5ee89d-02b7-4a53-e8a2-3226dcce482d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.SGD(lr=0.001, nesterov=True)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_2 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list )\n",
        "\n",
        "model.save_weights('model_2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 1s 778us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5006 - val_acc: 0.6013\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 125us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5006 - val_acc: 0.6013\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 123us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5006 - val_acc: 0.6013\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 126us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5007 - val_acc: 0.6013\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 130us/step - loss: 0.0162 - acc: 0.9990 - val_loss: 2.5007 - val_acc: 0.6013\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ognjWcIFhRZ1",
        "colab_type": "code",
        "outputId": "1c36af5e-af66-4961-b1ec-1fedaa89243a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=0.001)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_3 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_3.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 1s 883us/step - loss: 0.0248 - acc: 0.9950 - val_loss: 2.6093 - val_acc: 0.5823\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 0.0600 - acc: 0.9820 - val_loss: 2.4021 - val_acc: 0.6171\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.0219 - acc: 0.9970 - val_loss: 2.6868 - val_acc: 0.6044\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.0295 - acc: 0.9950 - val_loss: 3.0276 - val_acc: 0.6234\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 167us/step - loss: 0.0202 - acc: 0.9980 - val_loss: 2.8011 - val_acc: 0.5823\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 0s 158us/step - loss: 0.0198 - acc: 0.9980 - val_loss: 2.9315 - val_acc: 0.6076\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xeBGKg6Ni77a",
        "colab_type": "code",
        "outputId": "242dd13b-08fe-48aa-feac-bec3d91113e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=0.01)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_4 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_4.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 1s 911us/step - loss: 5.7507 - acc: 0.6190 - val_loss: 6.0806 - val_acc: 0.6139\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 168us/step - loss: 5.8155 - acc: 0.6240 - val_loss: 5.7280 - val_acc: 0.6329\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 5.2341 - acc: 0.6630 - val_loss: 5.8223 - val_acc: 0.6139\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 153us/step - loss: 5.4282 - acc: 0.6460 - val_loss: 5.5876 - val_acc: 0.6456\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 163us/step - loss: 5.3346 - acc: 0.6600 - val_loss: 5.8533 - val_acc: 0.6171\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 0s 152us/step - loss: 5.5716 - acc: 0.6460 - val_loss: 5.2685 - val_acc: 0.6677\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 0s 154us/step - loss: 5.1381 - acc: 0.6730 - val_loss: 6.1230 - val_acc: 0.6076\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 0s 156us/step - loss: 4.9850 - acc: 0.6750 - val_loss: 5.3958 - val_acc: 0.6487\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 0s 149us/step - loss: 4.6946 - acc: 0.6990 - val_loss: 5.6009 - val_acc: 0.6266\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 4.8026 - acc: 0.6950 - val_loss: 5.6278 - val_acc: 0.6297\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JGFdyUWvjTAz",
        "colab_type": "code",
        "outputId": "be135dee-087b-4b10-d4dc-cfd4c3255703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=0.1)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_5 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_5.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 1s 933us/step - loss: 7.1728 - acc: 0.5530 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ib0qbP4vjnAZ",
        "colab_type": "code",
        "outputId": "b7a4c40e-a540-4fd0-dd10-bec9f93d3308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=0.1)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 200\n",
        "batch_size = 54\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_6 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_6.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - 1s 962us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - 0s 110us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - 0s 104us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - 0s 102us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - 0s 103us/step - loss: 7.7528 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "psNtoKXXoJNA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Plot Confusion Matrix\n",
        "\n",
        "Model 4 delivers the best accuracy"
      ]
    },
    {
      "metadata": {
        "id": "NQ6p2CMQeVps",
        "colab_type": "code",
        "outputId": "307c8ac8-7fe8-4f9f-a21c-45078f4832a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('model_4.h5')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "328/328 [==============================] - 0s 77us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.285326236631812, 0.6585365853658537]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "zlsrzOhi-cUv",
        "colab_type": "code",
        "outputId": "7aada713-8f4b-4553-8ce4-e612ddf5cb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "sns.heatmap(matrix,annot=True,fmt='.5g')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f000e7aecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAFKCAYAAABlzOTzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngG0WDHSRjRoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "G7ZusRI8EIdm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1.3 Observation: \n",
        "\n",
        "- For Negative: None were correctory classified\n",
        "- For Positive: Accuracy is high\n",
        "- For Neutral: Ambiguity exists between Nuetral and Positive"
      ]
    },
    {
      "metadata": {
        "id": "ATuu0vXw--up",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2 Embedding_dim = 300"
      ]
    },
    {
      "metadata": {
        "id": "oFa5LAO8D2uF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Training"
      ]
    },
    {
      "metadata": {
        "id": "uizXmIJH_a9j",
        "colab_type": "code",
        "outputId": "74c4e423-4320-480c-b1b5-28e42927953e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "with open('glove.6B.300d.txt') as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BUn_ID9Q_Cng",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set dimemsions (# features for each word vector) for embedding layer\n",
        "embedding_dim = 300\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cbhDW7CH_UwE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8c4dba49-27d2-4fab-d559-e758cf551eef",
        "id": "O6Bz7RQ__UwH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, weights = [embedding_matrix], trainable = False, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 100, 300)          3000000   \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                960032    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 3,960,131\n",
            "Trainable params: 960,131\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "s3lfZ_Vl_UwL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define callbacks\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b9ffce3e-5315-4782-9add-fdcf94421006",
        "id": "1M-SHT4k_UwO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.SGD(lr=0.01, nesterov=True)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_1 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_1.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9821 - acc: 0.5300 - val_loss: 0.9422 - val_acc: 0.6171\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.7840 - acc: 0.6960 - val_loss: 0.8738 - val_acc: 0.6234\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 0.6424 - acc: 0.7720 - val_loss: 0.8597 - val_acc: 0.5981\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.5151 - acc: 0.8610 - val_loss: 0.8901 - val_acc: 0.5854\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 0.3917 - acc: 0.9100 - val_loss: 0.9797 - val_acc: 0.5665\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.3193 - acc: 0.9380 - val_loss: 1.0398 - val_acc: 0.6297\n",
            "Epoch 7/200\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.2509 - acc: 0.9510 - val_loss: 0.9745 - val_acc: 0.5823\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "806e6d04-9335-47fc-bf58-41b729643612",
        "id": "BwjXocMk_UwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.SGD(lr=0.001, nesterov=True)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_2 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list )\n",
        "\n",
        "model.save_weights('model_2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2063 - acc: 0.9750 - val_loss: 0.8802 - val_acc: 0.6392\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.1929 - acc: 0.9770 - val_loss: 0.8845 - val_acc: 0.6297\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1889 - acc: 0.9770 - val_loss: 0.8891 - val_acc: 0.6297\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1856 - acc: 0.9770 - val_loss: 0.8886 - val_acc: 0.6266\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1820 - acc: 0.9780 - val_loss: 0.8901 - val_acc: 0.6203\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4242a537-6d88-4449-ec48-0116cc795280",
        "id": "9mQfLB0K_UwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=0.001)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_3 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_3.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4110 - acc: 0.8500 - val_loss: 1.0829 - val_acc: 0.6234\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 229us/step - loss: 0.0949 - acc: 0.9760 - val_loss: 1.1846 - val_acc: 0.6519\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 216us/step - loss: 0.0326 - acc: 0.9950 - val_loss: 1.3972 - val_acc: 0.6519\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 213us/step - loss: 0.0191 - acc: 0.9960 - val_loss: 1.4071 - val_acc: 0.6487\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 212us/step - loss: 0.0126 - acc: 0.9980 - val_loss: 1.4127 - val_acc: 0.6361\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "ac7c365c-27cc-4472-e566-c3c5840fc276",
        "id": "kJ6NfzfO_UwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=0.01)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_4 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_4.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 7.4520 - acc: 0.5300 - val_loss: 7.5059 - val_acc: 0.5316\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 217us/step - loss: 7.7069 - acc: 0.5210 - val_loss: 7.4992 - val_acc: 0.5316\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 211us/step - loss: 7.7058 - acc: 0.5210 - val_loss: 7.5060 - val_acc: 0.5316\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 228us/step - loss: 7.7056 - acc: 0.5210 - val_loss: 7.5205 - val_acc: 0.5316\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 212us/step - loss: 7.7056 - acc: 0.5210 - val_loss: 7.5207 - val_acc: 0.5316\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "841ce84d-0e87-4db8-9bdb-d0e650468246",
        "id": "rPMKGmcx_Uwb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=0.1)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_5 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_5.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 7.7407 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 227us/step - loss: 7.7376 - acc: 0.5190 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 214us/step - loss: 7.7372 - acc: 0.5200 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 212us/step - loss: 7.7370 - acc: 0.5200 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 208us/step - loss: 7.7369 - acc: 0.5200 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "216d4cf1-63b2-4c74-a30d-1eb2344b133b",
        "id": "peROD8eJ_Uwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optimizers.Adam(lr=0.1)\n",
        "loss = 'categorical_crossentropy'\n",
        "epochs = 200\n",
        "batch_size = 54\n",
        "\n",
        "model.compile(optimizer= optimizer,\n",
        "              loss = loss,\n",
        "              metrics=['acc'])\n",
        "\n",
        "history_6 = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model.save_weights('model_6.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 316 samples\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 7.7368 - acc: 0.5200 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - 0s 157us/step - loss: 7.7367 - acc: 0.5200 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - 0s 140us/step - loss: 7.7367 - acc: 0.5200 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - 0s 139us/step - loss: 7.7367 - acc: 0.5200 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - 0s 138us/step - loss: 7.7367 - acc: 0.5200 - val_loss: 7.5490 - val_acc: 0.5316\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JtiTYerMA133"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Plot Confusion Matrix\n",
        "\n",
        "Model 3 delivers the best accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f7ebd9c4-e611-4858-8a87-4f90199ce43e",
        "id": "9vem8ieFA13-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('model_3.h5')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "328/328 [==============================] - 0s 91us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5599273181543118, 0.6128048780487805]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e1a3c621-2f06-4198-e2f1-f124bab57d94",
        "id": "jSfTDaenA14C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "sns.heatmap(matrix,annot=True,fmt='.5g')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0005850ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAFOCAYAAAD+XablAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njkUIAgAcixAEADgWIQgAcCxCEADgWP8LL5z1ZKhZ3FkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "F-rYwL6nA9Sb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 Observation:\n",
        "\n",
        "- Positive: 67.8% acc\n",
        "- Neutral: 68.4% acc\n",
        "- Negative: 5.5%\n",
        "\n",
        "Most negative are falsely predicted"
      ]
    },
    {
      "metadata": {
        "id": "_5cv7OJNG6T2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4.Experiment - Freezed Embedding Layer + CNN - GloVe"
      ]
    },
    {
      "metadata": {
        "id": "KaXbSolLIGNc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
        "from keras.utils import plot_model\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "import os, re, csv, math, codecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KeTwa-jxTgV2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.1 Embedding_dim = 100"
      ]
    },
    {
      "metadata": {
        "id": "oRtVwMfAMCSK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "cc88e5fe-9e88-4270-9643-1a89ac98e13c",
        "id": "ScnM8GyZIQxV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "with open('glove.6B.100d.txt') as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H8f49YNSIQxd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set dimemsions (# features for each word vector) for embedding layer\n",
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aqE5nnZUHEqZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#training params\n",
        "batch_size = 256 \n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "#model parameters\n",
        "num_filters = 64 \n",
        "embedding_dim = 100 \n",
        "weight_decay = 1e-4\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wf418016HEoU",
        "colab_type": "code",
        "outputId": "d6a100de-de69-4e76-ad7c-a54022a68d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim,\n",
        "          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_23 (Embedding)     (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "conv1d_29 (Conv1D)           (None, 100, 64)           44864     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling (None, 50, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_30 (Conv1D)           (None, 50, 64)            28736     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_15 (Glo (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,075,779\n",
            "Trainable params: 75,779\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aL7Ae8DPHxqI",
        "colab_type": "code",
        "outputId": "361080c7-8b63-4c4f-dca1-53168dcd138a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "#define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]\n",
        "\n",
        "#model training\n",
        "hist = model.fit(x_train, \n",
        "                 y_train, \n",
        "                 batch_size=batch_size, \n",
        "                 epochs=num_epochs, \n",
        "                 callbacks=callbacks_list, \n",
        "                 validation_split=0.1, \n",
        "                 shuffle=True, \n",
        "                 verbose=2)\n",
        "\n",
        "model.save_weights('model_txtCNN_1.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/50\n",
            " - 0s - loss: 0.0525 - acc: 0.9889 - val_loss: 1.0812 - val_acc: 0.7000\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.0464 - acc: 0.9956 - val_loss: 1.1763 - val_acc: 0.6000\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.0493 - acc: 0.9911 - val_loss: 1.1026 - val_acc: 0.7000\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.0485 - acc: 0.9911 - val_loss: 1.1636 - val_acc: 0.6400\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.0402 - acc: 0.9922 - val_loss: 1.1510 - val_acc: 0.7300\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xXV7kPQ3Iz7H",
        "colab_type": "code",
        "outputId": "077c7727-deb8-4aec-ab55-7eea13e50a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "cell_type": "code",
      "source": [
        "#training params\n",
        "batch_size = 256 \n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "#model parameters\n",
        "num_filters = 64 \n",
        "embedding_dim = 100 \n",
        "weight_decay = 1e-4\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.01)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim,\n",
        "          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]\n",
        "\n",
        "#model training\n",
        "hist = model.fit(x_train, \n",
        "                 y_train, \n",
        "                 batch_size=batch_size, \n",
        "                 epochs=num_epochs, \n",
        "                 callbacks=callbacks_list, \n",
        "                 validation_split=0.1, \n",
        "                 shuffle=True, \n",
        "                 verbose=2)\n",
        "\n",
        "model.save_weights('model_txtCNN_2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 100, 64)           44864     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 50, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 50, 64)            28736     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_9 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,075,779\n",
            "Trainable params: 75,779\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/50\n",
            " - 2s - loss: 2.4411 - acc: 0.4678 - val_loss: 1.0066 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.9950 - acc: 0.4844 - val_loss: 0.9807 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.9343 - acc: 0.5000 - val_loss: 0.9269 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.8744 - acc: 0.5556 - val_loss: 0.9152 - val_acc: 0.5700\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.8417 - acc: 0.5611 - val_loss: 0.8861 - val_acc: 0.5900\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.8139 - acc: 0.5889 - val_loss: 0.8729 - val_acc: 0.5800\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.7788 - acc: 0.6111 - val_loss: 0.9089 - val_acc: 0.6100\n",
            "Epoch 8/50\n",
            " - 0s - loss: 0.7483 - acc: 0.6611 - val_loss: 0.9113 - val_acc: 0.6000\n",
            "Epoch 9/50\n",
            " - 0s - loss: 0.7541 - acc: 0.6344 - val_loss: 0.9115 - val_acc: 0.6200\n",
            "Epoch 10/50\n",
            " - 0s - loss: 0.7066 - acc: 0.6778 - val_loss: 0.8971 - val_acc: 0.5900\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ihYb6klSKk-L",
        "colab_type": "code",
        "outputId": "5b5729ff-0af5-4b22-da9e-8b4f8176198e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "#training params\n",
        "batch_size = 256 \n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "#model parameters\n",
        "num_filters = 128 \n",
        "embedding_dim = 100 \n",
        "weight_decay = 1e-4\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim,\n",
        "          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]\n",
        "\n",
        "#model training\n",
        "hist = model.fit(x_train, \n",
        "                 y_train, \n",
        "                 batch_size=batch_size, \n",
        "                 epochs=num_epochs, \n",
        "                 callbacks=callbacks_list, \n",
        "                 validation_split=0.1, \n",
        "                 shuffle=True, \n",
        "                 verbose=2)\n",
        "\n",
        "model.save_weights('model_txtCNN_2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_18 (Embedding)     (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 100, 128)          89728     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 50, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 50, 128)           114816    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_10 (Glo (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,208,771\n",
            "Trainable params: 208,771\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/50\n",
            " - 4s - loss: 1.2569 - acc: 0.4500 - val_loss: 1.0015 - val_acc: 0.5500\n",
            "Epoch 2/50\n",
            " - 0s - loss: 1.0112 - acc: 0.4900 - val_loss: 0.9905 - val_acc: 0.5700\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.9592 - acc: 0.5300 - val_loss: 0.9656 - val_acc: 0.5100\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.9030 - acc: 0.5611 - val_loss: 0.9579 - val_acc: 0.5000\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.8884 - acc: 0.5644 - val_loss: 0.9204 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.8480 - acc: 0.5789 - val_loss: 0.8875 - val_acc: 0.6200\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.8024 - acc: 0.5911 - val_loss: 0.8757 - val_acc: 0.6000\n",
            "Epoch 8/50\n",
            " - 0s - loss: 0.7752 - acc: 0.6378 - val_loss: 0.8413 - val_acc: 0.6500\n",
            "Epoch 9/50\n",
            " - 0s - loss: 0.7696 - acc: 0.6267 - val_loss: 0.8325 - val_acc: 0.6600\n",
            "Epoch 10/50\n",
            " - 0s - loss: 0.7419 - acc: 0.6489 - val_loss: 0.8446 - val_acc: 0.6600\n",
            "Epoch 11/50\n",
            " - 0s - loss: 0.7185 - acc: 0.6456 - val_loss: 0.8223 - val_acc: 0.6700\n",
            "Epoch 12/50\n",
            " - 0s - loss: 0.6966 - acc: 0.6800 - val_loss: 0.8221 - val_acc: 0.7000\n",
            "Epoch 13/50\n",
            " - 0s - loss: 0.6409 - acc: 0.7067 - val_loss: 0.7909 - val_acc: 0.6900\n",
            "Epoch 14/50\n",
            " - 0s - loss: 0.6242 - acc: 0.7344 - val_loss: 0.7986 - val_acc: 0.7000\n",
            "Epoch 15/50\n",
            " - 0s - loss: 0.5894 - acc: 0.7544 - val_loss: 0.8155 - val_acc: 0.7300\n",
            "Epoch 16/50\n",
            " - 0s - loss: 0.5464 - acc: 0.7778 - val_loss: 0.7823 - val_acc: 0.6800\n",
            "Epoch 17/50\n",
            " - 0s - loss: 0.5284 - acc: 0.7867 - val_loss: 0.8012 - val_acc: 0.7100\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Lb2cDQvSLFjO"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1.2 Plot Confusion Matrix\n",
        "\n",
        "Model 1 delivers the best accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "49e43fb8-3e60-4511-89b1-6bba2ea20f09",
        "id": "uwf41mdKLFjQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# model.load_weights('model_txtCNN_1.h5')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "328/328 [==============================] - 0s 347us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1832514274411086, 0.6432926829268293]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8bf5b546-3a21-4498-d5d7-90cf18d11c99",
        "id": "PeqfIrS6LFja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "sns.heatmap(matrix,annot=True,fmt='.5g')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efffa6f11d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAFKCAYAAABlzOTzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMC1CEEAgGv9L1MiIB3DVMSZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eP8vxZ-WLFjd"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1.3 Observation: \n",
        "\n",
        "- For Negative: 2.7% accuracy\n",
        "- For Positive: 79.5% accuracy\n",
        "- For Neutral: 64.4% accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kwZBH41qM4XO"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.2 Embedding_dim = 300"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "X3sHXKMiM4XR"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "bf50daf5-76ce-4a89-aff3-e4da508f3f98",
        "id": "swvmhFYXM4XS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "with open('glove.6B.300d.txt') as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xBh4ziy5M4XV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set dimemsions (# features for each word vector) for embedding layer\n",
        "embedding_dim = 300\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "i3GjK3uaM4XY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#training params\n",
        "batch_size = 256 \n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "#model parameters\n",
        "num_filters = 64 \n",
        "embedding_dim = 300 \n",
        "weight_decay = 1e-4\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "6dc2b20a-c11b-4ea7-9a02-cdbf9b8b39d2",
        "id": "jXaSWrV_M4Xa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim,\n",
        "          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_24 (Embedding)     (None, 100, 300)          3000000   \n",
            "_________________________________________________________________\n",
            "conv1d_31 (Conv1D)           (None, 100, 64)           134464    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 50, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_32 (Conv1D)           (None, 50, 64)            28736     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_16 (Glo (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 3,165,379\n",
            "Trainable params: 165,379\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a51d594e-9b03-4376-a18b-8eaab9255b16",
        "id": "ZvGYbPejM4Xi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "#define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]\n",
        "\n",
        "#model training\n",
        "hist = model.fit(x_train, \n",
        "                 y_train, \n",
        "                 batch_size=batch_size, \n",
        "                 epochs=num_epochs, \n",
        "                 callbacks=callbacks_list, \n",
        "                 validation_split=0.1, \n",
        "                 shuffle=True, \n",
        "                 verbose=2)\n",
        "\n",
        "model.save_weights('model_txtCNN_1.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/50\n",
            " - 4s - loss: 1.0663 - acc: 0.4322 - val_loss: 1.0170 - val_acc: 0.4900\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.9562 - acc: 0.5611 - val_loss: 0.9688 - val_acc: 0.6300\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.9119 - acc: 0.6089 - val_loss: 0.9334 - val_acc: 0.6600\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.8673 - acc: 0.6211 - val_loss: 0.9013 - val_acc: 0.6200\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.8290 - acc: 0.6567 - val_loss: 0.8717 - val_acc: 0.6600\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.7830 - acc: 0.6778 - val_loss: 0.8594 - val_acc: 0.6700\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.7455 - acc: 0.7022 - val_loss: 0.8260 - val_acc: 0.6600\n",
            "Epoch 8/50\n",
            " - 0s - loss: 0.7045 - acc: 0.7233 - val_loss: 0.7938 - val_acc: 0.6900\n",
            "Epoch 9/50\n",
            " - 0s - loss: 0.6646 - acc: 0.7356 - val_loss: 0.7920 - val_acc: 0.6800\n",
            "Epoch 10/50\n",
            " - 0s - loss: 0.6120 - acc: 0.7611 - val_loss: 0.7854 - val_acc: 0.7100\n",
            "Epoch 11/50\n",
            " - 0s - loss: 0.5683 - acc: 0.7844 - val_loss: 0.8244 - val_acc: 0.5600\n",
            "Epoch 12/50\n",
            " - 0s - loss: 0.5245 - acc: 0.8122 - val_loss: 0.7656 - val_acc: 0.6900\n",
            "Epoch 13/50\n",
            " - 0s - loss: 0.4797 - acc: 0.8400 - val_loss: 0.7834 - val_acc: 0.6700\n",
            "Epoch 14/50\n",
            " - 0s - loss: 0.4473 - acc: 0.8467 - val_loss: 0.7976 - val_acc: 0.6500\n",
            "Epoch 15/50\n",
            " - 0s - loss: 0.3973 - acc: 0.8733 - val_loss: 0.7807 - val_acc: 0.6700\n",
            "Epoch 16/50\n",
            " - 0s - loss: 0.3820 - acc: 0.8656 - val_loss: 0.8010 - val_acc: 0.6900\n",
            "Epoch 00016: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "15c69626-1dc9-489b-eefa-d9a957510e28",
        "id": "K_brx_F-M4Xl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "#training params\n",
        "batch_size = 256 \n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "#model parameters\n",
        "num_filters = 64 \n",
        "embedding_dim = 300 \n",
        "weight_decay = 1e-4\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.01)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim,\n",
        "          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]\n",
        "\n",
        "#model training\n",
        "hist = model.fit(x_train, \n",
        "                 y_train, \n",
        "                 batch_size=batch_size, \n",
        "                 epochs=num_epochs, \n",
        "                 callbacks=callbacks_list, \n",
        "                 validation_split=0.1, \n",
        "                 shuffle=True, \n",
        "                 verbose=2)\n",
        "\n",
        "model.save_weights('model_txtCNN_2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_25 (Embedding)     (None, 100, 300)          3000000   \n",
            "_________________________________________________________________\n",
            "conv1d_33 (Conv1D)           (None, 100, 64)           134464    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling (None, 50, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_34 (Conv1D)           (None, 50, 64)            28736     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_17 (Glo (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 3,165,379\n",
            "Trainable params: 165,379\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n",
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/50\n",
            " - 3s - loss: 2.1598 - acc: 0.4367 - val_loss: 0.9808 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.9270 - acc: 0.5222 - val_loss: 0.8659 - val_acc: 0.5600\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.8513 - acc: 0.5711 - val_loss: 0.8536 - val_acc: 0.6000\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.7908 - acc: 0.6067 - val_loss: 0.8712 - val_acc: 0.6100\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.7688 - acc: 0.6378 - val_loss: 0.8652 - val_acc: 0.6100\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.7087 - acc: 0.6889 - val_loss: 0.8507 - val_acc: 0.6500\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.6757 - acc: 0.7000 - val_loss: 0.8562 - val_acc: 0.6600\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "08d0efc6-842f-4cc6-a2ea-090a3ac0b4dc",
        "id": "qX1Rn0ytM4Xo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "#training params\n",
        "batch_size = 256 \n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "#model parameters\n",
        "num_filters = 128 \n",
        "embedding_dim = 300 \n",
        "weight_decay = 1e-4\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim,\n",
        "          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dense(3, activation='softmax'))  #multi-label (k-hot encoding)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]\n",
        "\n",
        "#model training\n",
        "hist = model.fit(x_train, \n",
        "                 y_train, \n",
        "                 batch_size=batch_size, \n",
        "                 epochs=num_epochs, \n",
        "                 callbacks=callbacks_list, \n",
        "                 validation_split=0.1, \n",
        "                 shuffle=True, \n",
        "                 verbose=2)\n",
        "\n",
        "model.save_weights('model_txtCNN_3.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_28 (Embedding)     (None, 100, 300)          3000000   \n",
            "_________________________________________________________________\n",
            "conv1d_37 (Conv1D)           (None, 100, 128)          268928    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 50, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 50, 128)           114816    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_19 (Glo (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 3,387,971\n",
            "Trainable params: 387,971\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n",
            "Train on 900 samples, validate on 100 samples\n",
            "Epoch 1/50\n",
            " - 4s - loss: 1.0398 - acc: 0.4878 - val_loss: 0.9684 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.9074 - acc: 0.5711 - val_loss: 0.9040 - val_acc: 0.6900\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.8500 - acc: 0.6011 - val_loss: 0.8494 - val_acc: 0.6800\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.7754 - acc: 0.6478 - val_loss: 0.8160 - val_acc: 0.6400\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.7290 - acc: 0.6656 - val_loss: 0.7868 - val_acc: 0.6900\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.6719 - acc: 0.7167 - val_loss: 0.7978 - val_acc: 0.6800\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.6294 - acc: 0.7311 - val_loss: 0.7997 - val_acc: 0.7100\n",
            "Epoch 8/50\n",
            " - 0s - loss: 0.5453 - acc: 0.7833 - val_loss: 0.7675 - val_acc: 0.7300\n",
            "Epoch 9/50\n",
            " - 0s - loss: 0.4950 - acc: 0.8256 - val_loss: 0.7564 - val_acc: 0.7100\n",
            "Epoch 10/50\n",
            " - 0s - loss: 0.4608 - acc: 0.8278 - val_loss: 0.7543 - val_acc: 0.7200\n",
            "Epoch 11/50\n",
            " - 0s - loss: 0.4033 - acc: 0.8667 - val_loss: 0.7453 - val_acc: 0.6900\n",
            "Epoch 12/50\n",
            " - 0s - loss: 0.3368 - acc: 0.8833 - val_loss: 0.7673 - val_acc: 0.7400\n",
            "Epoch 13/50\n",
            " - 0s - loss: 0.3034 - acc: 0.9100 - val_loss: 0.7311 - val_acc: 0.7200\n",
            "Epoch 14/50\n",
            " - 0s - loss: 0.2420 - acc: 0.9256 - val_loss: 0.7881 - val_acc: 0.7300\n",
            "Epoch 15/50\n",
            " - 0s - loss: 0.2141 - acc: 0.9422 - val_loss: 0.7505 - val_acc: 0.7200\n",
            "Epoch 16/50\n",
            " - 0s - loss: 0.1772 - acc: 0.9600 - val_loss: 0.8584 - val_acc: 0.7200\n",
            "Epoch 17/50\n",
            " - 0s - loss: 0.1566 - acc: 0.9611 - val_loss: 0.8068 - val_acc: 0.7100\n",
            "Epoch 00017: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bQ9J464KM4Xu"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2.2 Plot Confusion Matrix\n",
        "\n",
        "Model 1 delivers the best accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "378b3992-8d68-491c-dc49-ecb693ccfd34",
        "id": "Wpas_Up0M4Xv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# model.load_weights('model_txtCNN_3.h5')\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "328/328 [==============================] - 0s 229us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8450581896595839, 0.6859756097560976]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4fa1a20c-75a8-4234-fb0a-fc597edb0819",
        "id": "yWe_cOUPM4X3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "sns.heatmap(matrix,annot=True,fmt='.5g')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efff99cd080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAFKCAYAAABlzOTzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0MbMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rf6TDsdNM4X7"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2.3 Observation: \n",
        "\n",
        "- For Negative: 2.7% accuracy\n",
        "- For Positive: 66.4% accuracy\n",
        "- For Neutral: 86.9% accuracy"
      ]
    }
  ]
}