{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RMS_ALEXNET_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ziqlu0722/Info7374-GitHub-repo/blob/master/Assignment_2/RMS_ALEXNET_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JVdK6TLN-P5r",
        "colab_type": "code",
        "outputId": "ac0e823f-9547-4952-a9f6-4cf791b321b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os, zipfile, io, requests\n",
        "URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
        "def download_images(url):\n",
        "    r = requests.get(url, stream=True)\n",
        "    print ('Downloading ' + url )\n",
        "    zip_ref = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    zip_ref.extractall('./')\n",
        "    zip_ref.close()\n",
        "download_images(URL) #To download"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://cs231n.stanford.edu/tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VS47uIFR-isg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from scipy.misc import imread"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDGSTxFQ-naa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_tiny_imagenet(path, wnids_path, resize='false', num_classes=200, dtype=np.float32):\n",
        "  \"\"\"\n",
        "  Load TinyImageNet. Each of TinyImageNet-100-A, TinyImageNet-100-B, and\n",
        "  TinyImageNet-200 have the same directory structure, so this can be used\n",
        "  to load any of them.\n",
        "  Inputs:\n",
        "  - path: String giving path to the directory to load.\n",
        "  - dtype: numpy datatype used to load the data.\n",
        "  Returns: A tuple of\n",
        "  - class_names: A list where class_names[i] is a list of strings giving the\n",
        "    WordNet names for class i in the loaded dataset.\n",
        "  - X_train: (N_tr, 3, 64, 64) array of training images\n",
        "  - y_train: (N_tr,) array of training labels\n",
        "  - X_val: (N_val, 3, 64, 64) array of validation images\n",
        "  - y_val: (N_val,) array of validation labels\n",
        "  - X_test: (N_test, 3, 64, 64) array of testing images.\n",
        "  - y_test: (N_test,) array of test labels; if test labels are not available\n",
        "    (such as in student code) then y_test will be None.\n",
        "  \"\"\"\n",
        "  # First load wnids\n",
        "  wnids_file = os.path.join(wnids_path, 'wnids.txt')\n",
        "  with open(os.path.join(path, wnids_file), 'r') as f:\n",
        "    wnids = [x.strip() for x in f]\n",
        "\n",
        "  # Map wnids to integer labels\n",
        "  wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
        "\n",
        "  # Use words.txt to get names for each class\n",
        "  words_file = os.path.join(wnids_path, 'words.txt')\n",
        "  with open(os.path.join(path, words_file), 'r') as f:\n",
        "    wnid_to_words = dict(line.split('\\t') for line in f)\n",
        "    for wnid, words in wnid_to_words.items():\n",
        "      wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
        "  class_names = [wnid_to_words[wnid] for wnid in wnids]\n",
        "\n",
        "  # Next load training data.\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "  for i, wnid in enumerate(wnids):\n",
        "    if (i + 1) % 20 == 0:\n",
        "      print('loading training data for synset %d / %d' % (i + 1, len(wnids)))\n",
        "    # To figure out the filenames we need to open the boxes file\n",
        "    boxes_file = os.path.join(path, 'train', wnid, '%s_boxes.txt' % wnid)\n",
        "    with open(boxes_file, 'r') as f:\n",
        "      filenames = [x.split('\\t')[0] for x in f]\n",
        "    num_images = len(filenames)\n",
        "    \n",
        "    if resize.lower() == 'true':\n",
        "      X_train_block = np.zeros((num_images, 3, 32, 32), dtype=dtype)\n",
        "    else:\n",
        "      X_train_block = np.zeros((num_images, 3, 64, 64), dtype=dtype)\n",
        "    \n",
        "    y_train_block = wnid_to_label[wnid] * np.ones(num_images, dtype=np.int64)\n",
        "    for j, img_file in enumerate(filenames):\n",
        "      img_file = os.path.join(path, 'train', wnid, 'images', img_file)\n",
        "      img = imread(img_file)\n",
        "      \n",
        "      if resize.lower() == 'true':\n",
        "        img = scipy.misc.imresize(img, (32, 32, 3))\n",
        "      if img.ndim == 2:\n",
        "        ## grayscale file\n",
        "        if resize.lower() == 'true':\n",
        "          img.shape = (32, 32, 1)\n",
        "        else:\n",
        "          img.shape = (64, 64, 1)\n",
        "      X_train_block[j] = img.transpose(2, 0, 1)\n",
        "    X_train.append(X_train_block)\n",
        "    y_train.append(y_train_block)\n",
        "      \n",
        "  # We need to concatenate all training data\n",
        "  X_train = np.concatenate(X_train, axis=0)\n",
        "  y_train = np.concatenate(y_train, axis=0)\n",
        "  \n",
        "  # Next load validation data\n",
        "  with open(os.path.join(path, 'val', 'val_annotations.txt'), 'r') as f:\n",
        "    img_files = []\n",
        "    val_wnids = []\n",
        "    for line in f:\n",
        "      # Select only validation images in chosen wnids set\n",
        "      if line.split()[1] in wnids:\n",
        "        img_file, wnid = line.split('\\t')[:2]\n",
        "        img_files.append(img_file)\n",
        "        val_wnids.append(wnid)\n",
        "    num_val = len(img_files)\n",
        "    y_val = np.array([wnid_to_label[wnid] for wnid in val_wnids])\n",
        "    \n",
        "    if resize.lower() == 'true':\n",
        "      X_val = np.zeros((num_val, 3, 32, 32), dtype=dtype)\n",
        "    else:\n",
        "      X_val = np.zeros((num_val, 3, 64, 64), dtype=dtype)\n",
        " \n",
        "    for i, img_file in enumerate(img_files):\n",
        "      img_file = os.path.join(path, 'val', 'images', img_file)\n",
        "      img = imread(img_file)\n",
        "      if resize.lower() == 'true':\n",
        "        img = scipy.misc.imresize(img, (32, 32, 3))\n",
        "      if img.ndim == 2:\n",
        "        if resize.lower() == 'true':\n",
        "          img.shape = (32, 32, 1)\n",
        "        else:\n",
        "          img.shape = (64, 64, 1)\n",
        "\n",
        "      X_val[i] = img.transpose(2, 0, 1)\n",
        "\n",
        "  \"\"\"\n",
        "  # Next load test images\n",
        "  # Students won't have test labels, so we need to iterate over files in the\n",
        "  # images directory.\n",
        "  img_files = os.listdir(os.path.join(path, 'test', 'images'))\n",
        "  X_test = np.zeros((len(img_files), 3, 64, 64), dtype=dtype)\n",
        "  for i, img_file in enumerate(img_files):\n",
        "    img_file = os.path.join(path, 'test', 'images', img_file)\n",
        "    img = imread(img_file)\n",
        "    if img.ndim == 2:\n",
        "      img.shape = (64, 64, 1)\n",
        "    X_test[i] = img.transpose(2, 0, 1)\n",
        "  y_test = None\n",
        "  y_test_file = os.path.join(path, 'test', 'test_annotations.txt')\n",
        "  if os.path.isfile(y_test_file):\n",
        "    with open(y_test_file, 'r') as f:\n",
        "      img_file_to_wnid = {}\n",
        "      for line in f:\n",
        "        line = line.split('\\t')\n",
        "        img_file_to_wnid[line[0]] = line[1]\n",
        "    y_test = [wnid_to_label[img_file_to_wnid[img_file]] for img_file in img_files]\n",
        "    y_test = np.array(y_test)\n",
        "  \"\"\"\n",
        "  \n",
        "  # Omit x_test and y_test because they're unlabeled\n",
        "  #return class_names, X_train, y_train, X_val, y_val, X_test, y_test\n",
        "  return class_names, X_train, y_train, X_val, y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGYfgxFV-yPB",
        "colab_type": "code",
        "outputId": "b1cf358c-423a-4c91-f5fe-63fe263242bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "class_names,X_train, y_train,X_val,y_val = load_tiny_imagenet('tiny-imagenet-200',\"\",resize='true')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loading training data for synset 20 / 200\n",
            "loading training data for synset 40 / 200\n",
            "loading training data for synset 60 / 200\n",
            "loading training data for synset 80 / 200\n",
            "loading training data for synset 100 / 200\n",
            "loading training data for synset 120 / 200\n",
            "loading training data for synset 140 / 200\n",
            "loading training data for synset 160 / 200\n",
            "loading training data for synset 180 / 200\n",
            "loading training data for synset 200 / 200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3JgRScVl_OJm",
        "colab_type": "code",
        "outputId": "d3fc0127-6714-4070-b2bf-ac3a3d8c0e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "x_train = X_train.astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "x_test = X_val.astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qmqn06I9_YCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train /= 255\n",
        "\n",
        "\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOz4uZjr_aXx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, len(class_names))\n",
        "\n",
        "\n",
        "\n",
        "y_val = keras.utils.to_categorical(y_val, len(class_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVMFce2eAdOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "#import register_converters as _register_converters\n",
        "from keras.preprocessing import image\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
        "Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# # 1st Convolutional Layer\n",
        "# model.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11),\\\n",
        "#  strides=(4,4), padding='valid'))\n",
        "# model.add(Activation('relu'))\n",
        "# # Pooling \n",
        "# model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# # Batch Normalisation before passing it to the next layer\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# # 2nd Convolutional Layer\n",
        "# model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "# model.add(Activation('relu'))\n",
        "# # Pooling\n",
        "# model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# # 3rd Convolutional Layer\n",
        "# model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "# model.add(Activation('relu'))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# # 4th Convolutional Layer\n",
        "# model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "# model.add(Activation('relu'))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# # 5th Convolutional Layer\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "# model.add(Activation('relu'))\n",
        "# # Pooling\n",
        "# model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# # Passing it to a dense layer\n",
        "# model.add(Flatten())\n",
        "# # 1st Dense Layer\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "# model.add(Activation('relu'))\n",
        "# # Add Dropout to prevent overfitting\n",
        "# model.add(Dropout(0.4))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# # 2nd Dense Layer\n",
        "# model.add(Dense(4096))\n",
        "# model.add(Activation('relu'))\n",
        "# # Add Dropout\n",
        "# model.add(Dropout(0.4))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# # 3rd Dense Layer\n",
        "# model.add(Dense(1000))\n",
        "# model.add(Activation('relu'))\n",
        "# # Add Dropout\n",
        "# model.add(Dropout(0.4))\n",
        "# # Batch Normalisation\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# # Output Layer\n",
        "# model.add(Dense(17))\n",
        "# model.add(Activation('softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCnuCfytBrWU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "# Import necessary components to build LeNet\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "\n",
        "img_shape=(32,32, 3)\n",
        "n_classes=10\n",
        "l2_reg=0.\n",
        "weights=None\n",
        "\n",
        "\t# Initialize model\n",
        "alexnet = Sequential()\n",
        "\n",
        "\t# Layer 1\n",
        "alexnet.add(Conv2D(96, (11, 11), input_shape=img_shape,\n",
        "padding='same',kernel_regularizer=l2(l2_reg)))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 2\n",
        "alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 3\n",
        "alexnet.add(ZeroPadding2D((1, 1)))\n",
        "alexnet.add(Conv2D(512, (3, 3), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 4\n",
        "alexnet.add(ZeroPadding2D((1, 1)))\n",
        "alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "\n",
        "\t# Layer 5\n",
        "alexnet.add(ZeroPadding2D((1, 1)))\n",
        "alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 6\n",
        "alexnet.add(Flatten())\n",
        "alexnet.add(Dense(3072))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(Dropout(0.5))\n",
        "\n",
        "\t# Layer 7\n",
        "alexnet.add(Dense(4096))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(Dropout(0.5))\n",
        "\n",
        "\t# Layer 8\n",
        "alexnet.add(Dense(200))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ulwET-ips1l",
        "colab_type": "code",
        "outputId": "3c288446-3196-453d-c854-19b1d8d87b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1292
        }
      },
      "cell_type": "code",
      "source": [
        "alexnet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 16, 16, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPaddin (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 10, 10, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 10, 10, 512)       2048      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPaddin (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPaddin (None, 9, 9, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 9, 9, 1024)        9438208   \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 9, 9, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 9, 9, 1024)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3072)              50334720  \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 3072)              12288     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4096)              12587008  \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               819400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 200)               0         \n",
            "=================================================================\n",
            "Total params: 79,769,832\n",
            "Trainable params: 79,749,272\n",
            "Non-trainable params: 20,560\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IAPD81bJp4is",
        "colab_type": "code",
        "outputId": "a570508b-90c2-4407-fa6e-701d993d92b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "alexnet.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = alexnet.fit(np.array(X_train.transpose(0,3,2,1)),np.array(y_train),\n",
        "                    epochs=10,\n",
        "                    batch_size=256,\n",
        "                    verbose=1,\n",
        "                    validation_data=(np.array(X_val.transpose(0,3,2,1)),np.array(y_val)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "100000/100000 [==============================] - 257s 3ms/step - loss: 3.3422 - acc: 0.2645 - val_loss: 3.7753 - val_acc: 0.1908\n",
            "Epoch 2/10\n",
            "100000/100000 [==============================] - 254s 3ms/step - loss: 3.1061 - acc: 0.3091 - val_loss: 3.6504 - val_acc: 0.2045\n",
            "Epoch 3/10\n",
            "100000/100000 [==============================] - 254s 3ms/step - loss: 2.8830 - acc: 0.3507 - val_loss: 4.0501 - val_acc: 0.1581\n",
            "Epoch 4/10\n",
            "100000/100000 [==============================] - 254s 3ms/step - loss: 2.6412 - acc: 0.3983 - val_loss: 3.8745 - val_acc: 0.1952\n",
            "Epoch 5/10\n",
            "100000/100000 [==============================] - 254s 3ms/step - loss: 2.3813 - acc: 0.4557 - val_loss: 3.3533 - val_acc: 0.2591\n",
            "Epoch 6/10\n",
            "100000/100000 [==============================] - 254s 3ms/step - loss: 2.0837 - acc: 0.5198 - val_loss: 3.3448 - val_acc: 0.2670\n",
            "Epoch 7/10\n",
            "100000/100000 [==============================] - 255s 3ms/step - loss: 1.7668 - acc: 0.5970 - val_loss: 3.2495 - val_acc: 0.2856\n",
            "Epoch 8/10\n",
            "100000/100000 [==============================] - 255s 3ms/step - loss: 1.4373 - acc: 0.6779 - val_loss: 3.5017 - val_acc: 0.2524\n",
            "Epoch 9/10\n",
            "100000/100000 [==============================] - 255s 3ms/step - loss: 1.1118 - acc: 0.7555 - val_loss: 3.6379 - val_acc: 0.2393\n",
            "Epoch 10/10\n",
            "100000/100000 [==============================] - 255s 3ms/step - loss: 0.8241 - acc: 0.8295 - val_loss: 4.1859 - val_acc: 0.1800\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}