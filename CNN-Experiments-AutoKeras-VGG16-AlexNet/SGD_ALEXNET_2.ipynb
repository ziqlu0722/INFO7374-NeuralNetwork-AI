{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD_ALEXNET_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ziqlu0722/Info7374-GitHub-repo/blob/master/Assignment_2/SGD_ALEXNET_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2IitslBChc9d",
        "colab_type": "code",
        "outputId": "04ea3a3a-4efd-4ce1-d70b-0c4e43a80004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os, zipfile, io, requests\n",
        "URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
        "def download_images(url):\n",
        "    r = requests.get(url, stream=True)\n",
        "    print ('Downloading ' + url )\n",
        "    zip_ref = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    zip_ref.extractall('./')\n",
        "    zip_ref.close()\n",
        "download_images(URL) #To download"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://cs231n.stanford.edu/tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-mW7rsDOhd61",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from scipy.misc import imread"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ui6woZRahgN7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_tiny_imagenet(path, wnids_path, resize='false', num_classes=200, dtype=np.float32):\n",
        "  \"\"\"\n",
        "  Load TinyImageNet. Each of TinyImageNet-100-A, TinyImageNet-100-B, and\n",
        "  TinyImageNet-200 have the same directory structure, so this can be used\n",
        "  to load any of them.\n",
        "  Inputs:\n",
        "  - path: String giving path to the directory to load.\n",
        "  - dtype: numpy datatype used to load the data.\n",
        "  Returns: A tuple of\n",
        "  - class_names: A list where class_names[i] is a list of strings giving the\n",
        "    WordNet names for class i in the loaded dataset.\n",
        "  - X_train: (N_tr, 3, 64, 64) array of training images\n",
        "  - y_train: (N_tr,) array of training labels\n",
        "  - X_val: (N_val, 3, 64, 64) array of validation images\n",
        "  - y_val: (N_val,) array of validation labels\n",
        "  - X_test: (N_test, 3, 64, 64) array of testing images.\n",
        "  - y_test: (N_test,) array of test labels; if test labels are not available\n",
        "    (such as in student code) then y_test will be None.\n",
        "  \"\"\"\n",
        "  # First load wnids\n",
        "  wnids_file = os.path.join(wnids_path, 'wnids.txt')\n",
        "  with open(os.path.join(path, wnids_file), 'r') as f:\n",
        "    wnids = [x.strip() for x in f]\n",
        "\n",
        "  # Map wnids to integer labels\n",
        "  wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
        "\n",
        "  # Use words.txt to get names for each class\n",
        "  words_file = os.path.join(wnids_path, 'words.txt')\n",
        "  with open(os.path.join(path, words_file), 'r') as f:\n",
        "    wnid_to_words = dict(line.split('\\t') for line in f)\n",
        "    for wnid, words in wnid_to_words.items():\n",
        "      wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
        "  class_names = [wnid_to_words[wnid] for wnid in wnids]\n",
        "\n",
        "  # Next load training data.\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "  for i, wnid in enumerate(wnids):\n",
        "    if (i + 1) % 20 == 0:\n",
        "      print('loading training data for synset %d / %d' % (i + 1, len(wnids)))\n",
        "    # To figure out the filenames we need to open the boxes file\n",
        "    boxes_file = os.path.join(path, 'train', wnid, '%s_boxes.txt' % wnid)\n",
        "    with open(boxes_file, 'r') as f:\n",
        "      filenames = [x.split('\\t')[0] for x in f]\n",
        "    num_images = len(filenames)\n",
        "    \n",
        "    if resize.lower() == 'true':\n",
        "      X_train_block = np.zeros((num_images, 3, 32, 32), dtype=dtype)\n",
        "    else:\n",
        "      X_train_block = np.zeros((num_images, 3, 64, 64), dtype=dtype)\n",
        "    \n",
        "    y_train_block = wnid_to_label[wnid] * np.ones(num_images, dtype=np.int64)\n",
        "    for j, img_file in enumerate(filenames):\n",
        "      img_file = os.path.join(path, 'train', wnid, 'images', img_file)\n",
        "      img = imread(img_file)\n",
        "      \n",
        "      if resize.lower() == 'true':\n",
        "        img = scipy.misc.imresize(img, (32, 32, 3))\n",
        "      if img.ndim == 2:\n",
        "        ## grayscale file\n",
        "        if resize.lower() == 'true':\n",
        "          img.shape = (32, 32, 1)\n",
        "        else:\n",
        "          img.shape = (64, 64, 1)\n",
        "      X_train_block[j] = img.transpose(2, 0, 1)\n",
        "    X_train.append(X_train_block)\n",
        "    y_train.append(y_train_block)\n",
        "      \n",
        "  # We need to concatenate all training data\n",
        "  X_train = np.concatenate(X_train, axis=0)\n",
        "  y_train = np.concatenate(y_train, axis=0)\n",
        "  \n",
        "  # Next load validation data\n",
        "  with open(os.path.join(path, 'val', 'val_annotations.txt'), 'r') as f:\n",
        "    img_files = []\n",
        "    val_wnids = []\n",
        "    for line in f:\n",
        "      # Select only validation images in chosen wnids set\n",
        "      if line.split()[1] in wnids:\n",
        "        img_file, wnid = line.split('\\t')[:2]\n",
        "        img_files.append(img_file)\n",
        "        val_wnids.append(wnid)\n",
        "    num_val = len(img_files)\n",
        "    y_val = np.array([wnid_to_label[wnid] for wnid in val_wnids])\n",
        "    \n",
        "    if resize.lower() == 'true':\n",
        "      X_val = np.zeros((num_val, 3, 32, 32), dtype=dtype)\n",
        "    else:\n",
        "      X_val = np.zeros((num_val, 3, 64, 64), dtype=dtype)\n",
        " \n",
        "    for i, img_file in enumerate(img_files):\n",
        "      img_file = os.path.join(path, 'val', 'images', img_file)\n",
        "      img = imread(img_file)\n",
        "      if resize.lower() == 'true':\n",
        "        img = scipy.misc.imresize(img, (32, 32, 3))\n",
        "      if img.ndim == 2:\n",
        "        if resize.lower() == 'true':\n",
        "          img.shape = (32, 32, 1)\n",
        "        else:\n",
        "          img.shape = (64, 64, 1)\n",
        "\n",
        "      X_val[i] = img.transpose(2, 0, 1)\n",
        "\n",
        "  \"\"\"\n",
        "  # Next load test images\n",
        "  # Students won't have test labels, so we need to iterate over files in the\n",
        "  # images directory.\n",
        "  img_files = os.listdir(os.path.join(path, 'test', 'images'))\n",
        "  X_test = np.zeros((len(img_files), 3, 64, 64), dtype=dtype)\n",
        "  for i, img_file in enumerate(img_files):\n",
        "    img_file = os.path.join(path, 'test', 'images', img_file)\n",
        "    img = imread(img_file)\n",
        "    if img.ndim == 2:\n",
        "      img.shape = (64, 64, 1)\n",
        "    X_test[i] = img.transpose(2, 0, 1)\n",
        "  y_test = None\n",
        "  y_test_file = os.path.join(path, 'test', 'test_annotations.txt')\n",
        "  if os.path.isfile(y_test_file):\n",
        "    with open(y_test_file, 'r') as f:\n",
        "      img_file_to_wnid = {}\n",
        "      for line in f:\n",
        "        line = line.split('\\t')\n",
        "        img_file_to_wnid[line[0]] = line[1]\n",
        "    y_test = [wnid_to_label[img_file_to_wnid[img_file]] for img_file in img_files]\n",
        "    y_test = np.array(y_test)\n",
        "  \"\"\"\n",
        "  \n",
        "  # Omit x_test and y_test because they're unlabeled\n",
        "  #return class_names, X_train, y_train, X_val, y_val, X_test, y_test\n",
        "  return class_names, X_train, y_train, X_val, y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x6wq89U8hjFp",
        "colab_type": "code",
        "outputId": "d3019c59-edd9-4b2d-c6cd-0dc6a1dc6a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "class_names,X_train, y_train,X_val,y_val = load_tiny_imagenet('tiny-imagenet-200',\"\",resize='true')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loading training data for synset 20 / 200\n",
            "loading training data for synset 40 / 200\n",
            "loading training data for synset 60 / 200\n",
            "loading training data for synset 80 / 200\n",
            "loading training data for synset 100 / 200\n",
            "loading training data for synset 120 / 200\n",
            "loading training data for synset 140 / 200\n",
            "loading training data for synset 160 / 200\n",
            "loading training data for synset 180 / 200\n",
            "loading training data for synset 200 / 200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vqxloEeihorE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "x_train = X_train.astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "x_test = X_val.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BaXaA7x-hsLd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train /= 255\n",
        "\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cZ8mFMkQhvT1",
        "colab_type": "code",
        "outputId": "9383caff-ecd3-4a50-9c41-880020fc8fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, len(class_names))\n",
        "\n",
        "\n",
        "\n",
        "y_val = keras.utils.to_categorical(y_val, len(class_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0msZ-QPWhyAf",
        "colab_type": "code",
        "outputId": "26803817-17e9-4879-89c6-68ee0f77cf91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "# Import necessary components to build LeNet\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "\n",
        "img_shape=(32,32, 3)\n",
        "n_classes=10\n",
        "l2_reg=0.\n",
        "weights=None\n",
        "\n",
        "\t# Initialize model\n",
        "alexnet = Sequential()\n",
        "\n",
        "\t# Layer 1\n",
        "alexnet.add(Conv2D(96, (11, 11), input_shape=img_shape,\n",
        "padding='same',kernel_regularizer=l2(l2_reg)))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 2\n",
        "alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 3\n",
        "alexnet.add(ZeroPadding2D((1, 1)))\n",
        "alexnet.add(Conv2D(512, (3, 3), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 4\n",
        "alexnet.add(ZeroPadding2D((1, 1)))\n",
        "alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "\n",
        "\t# Layer 5\n",
        "alexnet.add(ZeroPadding2D((1, 1)))\n",
        "alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# Layer 6\n",
        "alexnet.add(Flatten())\n",
        "alexnet.add(Dense(3072))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(Dropout(0.5))\n",
        "\n",
        "\t# Layer 7\n",
        "alexnet.add(Dense(4096))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(Dropout(0.5))\n",
        "\n",
        "\t# Layer 8\n",
        "alexnet.add(Dense(200))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('softmax'))\n",
        "\n",
        "alexnet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 512)       2048      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 9, 9, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 1024)        9438208   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 9, 9, 1024)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3072)              50334720  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 3072)              12288     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              12587008  \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               819400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 200)               0         \n",
            "=================================================================\n",
            "Total params: 79,769,832\n",
            "Trainable params: 79,749,272\n",
            "Non-trainable params: 20,560\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ffX3tNMRh7m_",
        "colab_type": "code",
        "outputId": "f830eb4c-7512-439c-d830-bf9778f0b257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1805
        }
      },
      "cell_type": "code",
      "source": [
        "alexnet.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.5, decay=0.001, nesterov=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = alexnet.fit(np.array(X_train.transpose(0,3,2,1)),np.array(y_train),\n",
        "                    epochs=50,\n",
        "                    batch_size=256,\n",
        "                    verbose=1,\n",
        "                    validation_data=(np.array(X_val.transpose(0,3,2,1)),np.array(y_val)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 100000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "100000/100000 [==============================] - 262s 3ms/step - loss: 5.1123 - acc: 0.0281 - val_loss: 4.7740 - val_acc: 0.0580\n",
            "Epoch 2/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 4.7247 - acc: 0.0579 - val_loss: 4.5979 - val_acc: 0.0827\n",
            "Epoch 3/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 4.5531 - acc: 0.0803 - val_loss: 4.5055 - val_acc: 0.0926\n",
            "Epoch 4/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 4.4326 - acc: 0.0970 - val_loss: 4.3268 - val_acc: 0.1232\n",
            "Epoch 5/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 4.3421 - acc: 0.1110 - val_loss: 4.2798 - val_acc: 0.1275\n",
            "Epoch 6/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 4.2649 - acc: 0.1239 - val_loss: 4.4912 - val_acc: 0.0919\n",
            "Epoch 7/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 4.1966 - acc: 0.1332 - val_loss: 4.1534 - val_acc: 0.1448\n",
            "Epoch 8/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 4.1395 - acc: 0.1421 - val_loss: 4.1272 - val_acc: 0.1507\n",
            "Epoch 9/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 4.0870 - acc: 0.1528 - val_loss: 4.2607 - val_acc: 0.1167\n",
            "Epoch 10/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 4.0424 - acc: 0.1595 - val_loss: 4.0602 - val_acc: 0.1583\n",
            "Epoch 11/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.9962 - acc: 0.1663 - val_loss: 4.2400 - val_acc: 0.1382\n",
            "Epoch 12/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 3.9579 - acc: 0.1734 - val_loss: 4.0439 - val_acc: 0.1688\n",
            "Epoch 13/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 3.9234 - acc: 0.1794 - val_loss: 3.9381 - val_acc: 0.1836\n",
            "Epoch 14/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 3.8894 - acc: 0.1850 - val_loss: 4.0570 - val_acc: 0.1635\n",
            "Epoch 15/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.8543 - acc: 0.1907 - val_loss: 3.9590 - val_acc: 0.1722\n",
            "Epoch 16/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.8285 - acc: 0.1960 - val_loss: 4.0193 - val_acc: 0.1746\n",
            "Epoch 17/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.7982 - acc: 0.2010 - val_loss: 4.0012 - val_acc: 0.1728\n",
            "Epoch 18/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.7720 - acc: 0.2059 - val_loss: 4.0454 - val_acc: 0.1506\n",
            "Epoch 19/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.7448 - acc: 0.2115 - val_loss: 3.8491 - val_acc: 0.1986\n",
            "Epoch 20/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.7227 - acc: 0.2145 - val_loss: 3.7847 - val_acc: 0.2128\n",
            "Epoch 21/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.7022 - acc: 0.2191 - val_loss: 4.0385 - val_acc: 0.1602\n",
            "Epoch 22/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.6769 - acc: 0.2243 - val_loss: 3.8363 - val_acc: 0.1983\n",
            "Epoch 23/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.6535 - acc: 0.2265 - val_loss: 3.9109 - val_acc: 0.1810\n",
            "Epoch 24/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 3.6337 - acc: 0.2314 - val_loss: 3.8564 - val_acc: 0.1890\n",
            "Epoch 25/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.6143 - acc: 0.2370 - val_loss: 3.8026 - val_acc: 0.2009\n",
            "Epoch 26/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 3.5981 - acc: 0.2385 - val_loss: 3.8491 - val_acc: 0.1925\n",
            "Epoch 27/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 3.5783 - acc: 0.2441 - val_loss: 3.8520 - val_acc: 0.2022\n",
            "Epoch 28/50\n",
            "100000/100000 [==============================] - 245s 2ms/step - loss: 3.5593 - acc: 0.2452 - val_loss: 3.7134 - val_acc: 0.2212\n",
            "Epoch 29/50\n",
            "100000/100000 [==============================] - 244s 2ms/step - loss: 3.5361 - acc: 0.2508 - val_loss: 3.7642 - val_acc: 0.2097\n",
            "Epoch 30/50\n",
            "100000/100000 [==============================] - 243s 2ms/step - loss: 3.5228 - acc: 0.2540 - val_loss: 3.7465 - val_acc: 0.2151\n",
            "Epoch 31/50\n",
            "100000/100000 [==============================] - 243s 2ms/step - loss: 3.5064 - acc: 0.2568 - val_loss: 3.7163 - val_acc: 0.2159\n",
            "Epoch 32/50\n",
            "100000/100000 [==============================] - 243s 2ms/step - loss: 3.4887 - acc: 0.2609 - val_loss: 3.7908 - val_acc: 0.2057\n",
            "Epoch 33/50\n",
            "100000/100000 [==============================] - 243s 2ms/step - loss: 3.4740 - acc: 0.2633 - val_loss: 3.9593 - val_acc: 0.1786\n",
            "Epoch 34/50\n",
            "100000/100000 [==============================] - 243s 2ms/step - loss: 3.4583 - acc: 0.2656 - val_loss: 3.8087 - val_acc: 0.1972\n",
            "Epoch 35/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.4424 - acc: 0.2689 - val_loss: 3.7445 - val_acc: 0.2213\n",
            "Epoch 36/50\n",
            "100000/100000 [==============================] - 243s 2ms/step - loss: 3.4304 - acc: 0.2727 - val_loss: 3.8102 - val_acc: 0.1952\n",
            "Epoch 37/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.4147 - acc: 0.2744 - val_loss: 3.7662 - val_acc: 0.2059\n",
            "Epoch 38/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.3978 - acc: 0.2764 - val_loss: 3.7656 - val_acc: 0.2071\n",
            "Epoch 39/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.3826 - acc: 0.2826 - val_loss: 3.6698 - val_acc: 0.2311\n",
            "Epoch 40/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.3708 - acc: 0.2829 - val_loss: 3.7616 - val_acc: 0.2137\n",
            "Epoch 41/50\n",
            "100000/100000 [==============================] - 243s 2ms/step - loss: 3.3534 - acc: 0.2860 - val_loss: 3.7003 - val_acc: 0.2244\n",
            "Epoch 42/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.3383 - acc: 0.2912 - val_loss: 3.6369 - val_acc: 0.2277\n",
            "Epoch 43/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.3254 - acc: 0.2919 - val_loss: 3.6354 - val_acc: 0.2350\n",
            "Epoch 44/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.3109 - acc: 0.2957 - val_loss: 3.6006 - val_acc: 0.2393\n",
            "Epoch 45/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.2994 - acc: 0.2972 - val_loss: 3.6920 - val_acc: 0.2319\n",
            "Epoch 46/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.2901 - acc: 0.3023 - val_loss: 3.6536 - val_acc: 0.2331\n",
            "Epoch 47/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.2766 - acc: 0.3021 - val_loss: 3.6403 - val_acc: 0.2296\n",
            "Epoch 48/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.2616 - acc: 0.3064 - val_loss: 3.7889 - val_acc: 0.2037\n",
            "Epoch 49/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.2496 - acc: 0.3099 - val_loss: 3.6039 - val_acc: 0.2433\n",
            "Epoch 50/50\n",
            "100000/100000 [==============================] - 242s 2ms/step - loss: 3.2381 - acc: 0.3098 - val_loss: 3.5983 - val_acc: 0.2443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eNdFk9BQh14Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}