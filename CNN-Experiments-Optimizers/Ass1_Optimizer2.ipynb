{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass1_Optimizer2",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ziqlu0722/CNN-Classifier/blob/master/Ass1_Optimizer2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WJsvCVkLccCV",
        "colab_type": "code",
        "outputId": "46cb65af-c504-4b4d-c1e7-1b5cb72798d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BdV0ZTj4cdcD",
        "colab_type": "code",
        "outputId": "e497f199-82b7-46c3-93b0-b473556d947f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I1Tz493vcgtD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dqs-bBU7cklC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.adamax(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "daU25qyKcqRL",
        "colab_type": "code",
        "outputId": "1d124e33-75b4-4310-d2db-a54a8e970b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BoC8V166craG",
        "colab_type": "code",
        "outputId": "0d3c7849-cc89-4585-d14a-105061a5ebcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3485
        }
      },
      "cell_type": "code",
      "source": [
        "datagen.fit(x_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=len(x_train) / 32, epochs=100,validation_data=(x_test, y_test))\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1562 [==============================] - 79s 51ms/step - loss: 0.6742 - acc: 0.7657 - val_loss: 0.5947 - val_acc: 0.7961\n",
            "Epoch 2/100\n",
            "1563/1562 [==============================] - 79s 51ms/step - loss: 0.6778 - acc: 0.7622 - val_loss: 0.5930 - val_acc: 0.7977\n",
            "Epoch 3/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6683 - acc: 0.7677 - val_loss: 0.5977 - val_acc: 0.7980\n",
            "Epoch 4/100\n",
            "1563/1562 [==============================] - 77s 50ms/step - loss: 0.6695 - acc: 0.7662 - val_loss: 0.5835 - val_acc: 0.7998\n",
            "Epoch 5/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6703 - acc: 0.7665 - val_loss: 0.6241 - val_acc: 0.7888\n",
            "Epoch 6/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6678 - acc: 0.7680 - val_loss: 0.5975 - val_acc: 0.7944\n",
            "Epoch 7/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6649 - acc: 0.7682 - val_loss: 0.5807 - val_acc: 0.8034\n",
            "Epoch 8/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6636 - acc: 0.7686 - val_loss: 0.5995 - val_acc: 0.7952\n",
            "Epoch 9/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6612 - acc: 0.7703 - val_loss: 0.5936 - val_acc: 0.7968\n",
            "Epoch 10/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6620 - acc: 0.7696 - val_loss: 0.5750 - val_acc: 0.8038\n",
            "Epoch 11/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6636 - acc: 0.7695 - val_loss: 0.5844 - val_acc: 0.8018\n",
            "Epoch 12/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6568 - acc: 0.7713 - val_loss: 0.5832 - val_acc: 0.8028\n",
            "Epoch 13/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6623 - acc: 0.7695 - val_loss: 0.6003 - val_acc: 0.7982\n",
            "Epoch 14/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6609 - acc: 0.7697 - val_loss: 0.5826 - val_acc: 0.8016\n",
            "Epoch 15/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6636 - acc: 0.7698 - val_loss: 0.5738 - val_acc: 0.8032\n",
            "Epoch 16/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6541 - acc: 0.7716 - val_loss: 0.5991 - val_acc: 0.7977\n",
            "Epoch 17/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6489 - acc: 0.7762 - val_loss: 0.5758 - val_acc: 0.8034\n",
            "Epoch 18/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6528 - acc: 0.7718 - val_loss: 0.5849 - val_acc: 0.8017\n",
            "Epoch 19/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6530 - acc: 0.7730 - val_loss: 0.5927 - val_acc: 0.7976\n",
            "Epoch 20/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6490 - acc: 0.7753 - val_loss: 0.5929 - val_acc: 0.7978\n",
            "Epoch 21/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6554 - acc: 0.7727 - val_loss: 0.5908 - val_acc: 0.7976\n",
            "Epoch 22/100\n",
            "1563/1562 [==============================] - 77s 50ms/step - loss: 0.6480 - acc: 0.7747 - val_loss: 0.5697 - val_acc: 0.8059\n",
            "Epoch 23/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6450 - acc: 0.7740 - val_loss: 0.5736 - val_acc: 0.8044\n",
            "Epoch 24/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6507 - acc: 0.7718 - val_loss: 0.5760 - val_acc: 0.8052\n",
            "Epoch 25/100\n",
            "1563/1562 [==============================] - 77s 50ms/step - loss: 0.6463 - acc: 0.7745 - val_loss: 0.5827 - val_acc: 0.8010\n",
            "Epoch 26/100\n",
            "1563/1562 [==============================] - 76s 49ms/step - loss: 0.6424 - acc: 0.7759 - val_loss: 0.5956 - val_acc: 0.7987\n",
            "Epoch 27/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6428 - acc: 0.7758 - val_loss: 0.5810 - val_acc: 0.8019\n",
            "Epoch 28/100\n",
            "1563/1562 [==============================] - 77s 50ms/step - loss: 0.6431 - acc: 0.7748 - val_loss: 0.5817 - val_acc: 0.8019\n",
            "Epoch 29/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6412 - acc: 0.7753 - val_loss: 0.5682 - val_acc: 0.8066\n",
            "Epoch 30/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6426 - acc: 0.7743 - val_loss: 0.5831 - val_acc: 0.8017\n",
            "Epoch 31/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6422 - acc: 0.7757 - val_loss: 0.5853 - val_acc: 0.8003\n",
            "Epoch 32/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6401 - acc: 0.7774 - val_loss: 0.5706 - val_acc: 0.8060\n",
            "Epoch 33/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6418 - acc: 0.7769 - val_loss: 0.5657 - val_acc: 0.8068\n",
            "Epoch 34/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6369 - acc: 0.7802 - val_loss: 0.5725 - val_acc: 0.8053\n",
            "Epoch 35/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6383 - acc: 0.7775 - val_loss: 0.5703 - val_acc: 0.8055\n",
            "Epoch 36/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6354 - acc: 0.7786 - val_loss: 0.5648 - val_acc: 0.8060\n",
            "Epoch 37/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6331 - acc: 0.7791 - val_loss: 0.5567 - val_acc: 0.8119\n",
            "Epoch 38/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6340 - acc: 0.7801 - val_loss: 0.5664 - val_acc: 0.8076\n",
            "Epoch 39/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6355 - acc: 0.7799 - val_loss: 0.5611 - val_acc: 0.8087\n",
            "Epoch 40/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6366 - acc: 0.7755 - val_loss: 0.5657 - val_acc: 0.8081\n",
            "Epoch 41/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6341 - acc: 0.7794 - val_loss: 0.5710 - val_acc: 0.8056\n",
            "Epoch 42/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6246 - acc: 0.7819 - val_loss: 0.5632 - val_acc: 0.8106\n",
            "Epoch 43/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6287 - acc: 0.7798 - val_loss: 0.5501 - val_acc: 0.8120\n",
            "Epoch 44/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6191 - acc: 0.7861 - val_loss: 0.5596 - val_acc: 0.8117\n",
            "Epoch 45/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6253 - acc: 0.7809 - val_loss: 0.5747 - val_acc: 0.8062\n",
            "Epoch 46/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6315 - acc: 0.7799 - val_loss: 0.5646 - val_acc: 0.8073\n",
            "Epoch 47/100\n",
            "1563/1562 [==============================] - 77s 50ms/step - loss: 0.6290 - acc: 0.7817 - val_loss: 0.5647 - val_acc: 0.8084\n",
            "Epoch 48/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6280 - acc: 0.7825 - val_loss: 0.5653 - val_acc: 0.8083\n",
            "Epoch 49/100\n",
            "1563/1562 [==============================] - 77s 50ms/step - loss: 0.6170 - acc: 0.7842 - val_loss: 0.5573 - val_acc: 0.8105\n",
            "Epoch 50/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6253 - acc: 0.7814 - val_loss: 0.5733 - val_acc: 0.8039\n",
            "Epoch 51/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6183 - acc: 0.7834 - val_loss: 0.5598 - val_acc: 0.8108\n",
            "Epoch 52/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6223 - acc: 0.7838 - val_loss: 0.5622 - val_acc: 0.8098\n",
            "Epoch 53/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6197 - acc: 0.7839 - val_loss: 0.5687 - val_acc: 0.8071\n",
            "Epoch 54/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6180 - acc: 0.7844 - val_loss: 0.5488 - val_acc: 0.8155\n",
            "Epoch 55/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6169 - acc: 0.7875 - val_loss: 0.5665 - val_acc: 0.8082\n",
            "Epoch 56/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6198 - acc: 0.7837 - val_loss: 0.5713 - val_acc: 0.8054\n",
            "Epoch 57/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6140 - acc: 0.7859 - val_loss: 0.5560 - val_acc: 0.8121\n",
            "Epoch 58/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6172 - acc: 0.7867 - val_loss: 0.5595 - val_acc: 0.8104\n",
            "Epoch 59/100\n",
            "1563/1562 [==============================] - 78s 50ms/step - loss: 0.6200 - acc: 0.7844 - val_loss: 0.5416 - val_acc: 0.8153\n",
            "Epoch 60/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6093 - acc: 0.7881 - val_loss: 0.5456 - val_acc: 0.8157\n",
            "Epoch 61/100\n",
            "1563/1562 [==============================] - 77s 49ms/step - loss: 0.6106 - acc: 0.7863 - val_loss: 0.5503 - val_acc: 0.8122\n",
            "Epoch 62/100\n",
            "1563/1562 [==============================] - 79s 50ms/step - loss: 0.6116 - acc: 0.7855 - val_loss: 0.5495 - val_acc: 0.8113\n",
            "Epoch 63/100\n",
            "1563/1562 [==============================] - 56s 36ms/step - loss: 0.6159 - acc: 0.7870 - val_loss: 0.5411 - val_acc: 0.8186\n",
            "Epoch 64/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6128 - acc: 0.7850 - val_loss: 0.5492 - val_acc: 0.8126\n",
            "Epoch 65/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6100 - acc: 0.7867 - val_loss: 0.5514 - val_acc: 0.8135\n",
            "Epoch 66/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6108 - acc: 0.7859 - val_loss: 0.5544 - val_acc: 0.8139\n",
            "Epoch 67/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6075 - acc: 0.7885 - val_loss: 0.5574 - val_acc: 0.8122\n",
            "Epoch 68/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6096 - acc: 0.7891 - val_loss: 0.5537 - val_acc: 0.8140\n",
            "Epoch 69/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6100 - acc: 0.7859 - val_loss: 0.5477 - val_acc: 0.8153\n",
            "Epoch 70/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6038 - acc: 0.7902 - val_loss: 0.5501 - val_acc: 0.8125\n",
            "Epoch 71/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.6038 - acc: 0.7882 - val_loss: 0.5426 - val_acc: 0.8167\n",
            "Epoch 72/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.6070 - acc: 0.7885 - val_loss: 0.5445 - val_acc: 0.8159\n",
            "Epoch 73/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6062 - acc: 0.7880 - val_loss: 0.5301 - val_acc: 0.8200\n",
            "Epoch 74/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.6038 - acc: 0.7909 - val_loss: 0.5487 - val_acc: 0.8149\n",
            "Epoch 75/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.6025 - acc: 0.7927 - val_loss: 0.5393 - val_acc: 0.8192\n",
            "Epoch 76/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.6065 - acc: 0.7896 - val_loss: 0.5647 - val_acc: 0.8099\n",
            "Epoch 77/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5945 - acc: 0.7934 - val_loss: 0.5477 - val_acc: 0.8148\n",
            "Epoch 78/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.6021 - acc: 0.7901 - val_loss: 0.5471 - val_acc: 0.8154\n",
            "Epoch 79/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.6028 - acc: 0.7895 - val_loss: 0.5491 - val_acc: 0.8154\n",
            "Epoch 80/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5957 - acc: 0.7922 - val_loss: 0.5352 - val_acc: 0.8183\n",
            "Epoch 81/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5997 - acc: 0.7912 - val_loss: 0.5342 - val_acc: 0.8224\n",
            "Epoch 82/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.5967 - acc: 0.7910 - val_loss: 0.5395 - val_acc: 0.8179\n",
            "Epoch 83/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5931 - acc: 0.7935 - val_loss: 0.5375 - val_acc: 0.8205\n",
            "Epoch 84/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5958 - acc: 0.7916 - val_loss: 0.5360 - val_acc: 0.8158\n",
            "Epoch 85/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5935 - acc: 0.7916 - val_loss: 0.5207 - val_acc: 0.8245\n",
            "Epoch 86/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5894 - acc: 0.7935 - val_loss: 0.5222 - val_acc: 0.8234\n",
            "Epoch 87/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5924 - acc: 0.7931 - val_loss: 0.5527 - val_acc: 0.8145\n",
            "Epoch 88/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.5912 - acc: 0.7943 - val_loss: 0.5265 - val_acc: 0.8228\n",
            "Epoch 89/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5972 - acc: 0.7900 - val_loss: 0.5330 - val_acc: 0.8194\n",
            "Epoch 90/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5943 - acc: 0.7929 - val_loss: 0.5428 - val_acc: 0.8145\n",
            "Epoch 91/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.5944 - acc: 0.7944 - val_loss: 0.5244 - val_acc: 0.8240\n",
            "Epoch 92/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5880 - acc: 0.7974 - val_loss: 0.5414 - val_acc: 0.8153\n",
            "Epoch 93/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5912 - acc: 0.7914 - val_loss: 0.5519 - val_acc: 0.8130\n",
            "Epoch 94/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.5880 - acc: 0.7936 - val_loss: 0.5322 - val_acc: 0.8187\n",
            "Epoch 95/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5855 - acc: 0.7944 - val_loss: 0.5201 - val_acc: 0.8239\n",
            "Epoch 96/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.5888 - acc: 0.7962 - val_loss: 0.5356 - val_acc: 0.8176\n",
            "Epoch 97/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.5870 - acc: 0.7956 - val_loss: 0.5249 - val_acc: 0.8220\n",
            "Epoch 98/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5852 - acc: 0.7967 - val_loss: 0.5348 - val_acc: 0.8183\n",
            "Epoch 99/100\n",
            "1563/1562 [==============================] - 41s 26ms/step - loss: 0.5868 - acc: 0.7954 - val_loss: 0.5330 - val_acc: 0.8177\n",
            "Epoch 100/100\n",
            "1563/1562 [==============================] - 40s 26ms/step - loss: 0.5850 - acc: 0.7973 - val_loss: 0.5338 - val_acc: 0.8196\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "10000/10000 [==============================] - 1s 145us/step\n",
            "Test loss: 0.5338134934902191\n",
            "Test accuracy: 0.8196\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}